{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": [
     "remove-cell"
    ]
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "if \"jbook\" in os.getcwd():\n",
    "    os.chdir(os.path.abspath(os.path.join(\"../..\")))\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "FORCE = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AppVoCAI Dataset Preprocessing\n",
    "---\n",
    "In this section, we unbox and preprocess the AppVoCAI dataset, survey its key characteristics, and profile its structure, format, and data types, in advance of downstream data quality assessment, cleaning, analysis and feature engineering. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": [
     "hide-cell"
    ]
   },
   "outputs": [],
   "source": [
    "from genailab.setup import auto_wire_container\n",
    "from genailab.asset.dataset.config import DatasetConfig\n",
    "from genailab.core.dtypes import DFType\n",
    "from genailab.core.flow import PhaseDef, StageDef\n",
    "from genailab.infra.utils.file.fileset import FileFormat\n",
    "from genailab.flow.dataprep.preprocess.builder import PreprocessStageBuilder\n",
    "\n",
    "container = auto_wire_container()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing Pipeline\n",
    "---\n",
    "\n",
    "The `PreprocessingStage` ensures that the data are in a structure and format suitable for downstream processing and analysis. This involves verifying UTF-8 encoding, casting data to appropriate types, converting datetimes to millisecond precision (for Spark) and removing any extraneous newlines from the review text. \n",
    "\n",
    "Next, we'll define the configurations for the raw and preprocessed datasets, construct the PreprocessStage pipeline, the run it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Raw Datas Configuration\n",
    "source = DatasetConfig(phase=PhaseDef.DATAPREP, stage=StageDef.RAW, name=\"review\", file_format=FileFormat.PARQUET, dftype=DFType.PANDAS)\n",
    "# Target Dataset Configuration\n",
    "target = DatasetConfig(phase=PhaseDef.DATAPREP, stage=StageDef.PREPROCESS, name=\"review\", file_format=FileFormat.PARQUET, dftype=DFType.PANDAS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "# ============================================================================== #\n",
      "#               Data Preprocessing Stage Sun, 09 Feb 2025 00:24:12               #\n",
      "# ============================================================================== #\n",
      "\n",
      "\n",
      "Task                                    Start       End         Runtime      Note                   \n",
      "----------------------------------------------------------------------------------------------------\n",
      "VerifyEncodingTask                      00:24:12    00:24:12    0.01 seconds                        \n",
      "CastDataTypeTask                        00:24:12    00:24:12    0.01 seconds                        \n",
      "RemoveNewlinesTask                      00:24:12    00:24:12    0.0 seconds                         \n",
      "ConvertDateTimetoMS                     00:24:12    00:24:12    0.0 seconds                         \n",
      "____________________________________________________________________________________________________\n",
      "Data Preprocessing Stage                00:24:12    00:24:12    0.18 seconds                        \n",
      "\n",
      "\n",
      "# ============================================================================ #\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Create the preprocess stage builder\n",
    "builder = PreprocessStageBuilder()\n",
    "# Add preprocess tasks to the builder and return the stage object.\n",
    "stage = (builder\n",
    "    .encoding()  # Verifies UTF-8 Encoding\n",
    "    .datatypes()  # Casts appropriate datatypes, i.e. category, int, float, and datetime variables.\n",
    "    .newlines()  # Removes newlines from text\n",
    "    .datetime()  # Converts datatime to millisecond precision (for pyspark)\n",
    "    .build(source_config=source, target_config=target)  # Constructs the pipeline and returns the stage\n",
    ")\n",
    "# Run the stage pipeline\n",
    "dataset = stage.run(force=FORCE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AppVoCAI Dataset Structure\n",
    "Let's examine the dataset structure, data types, completeness, uniqueness, and size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": [
     "hide-cell"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Column</th>\n",
       "      <th>DataType</th>\n",
       "      <th>Complete</th>\n",
       "      <th>Null</th>\n",
       "      <th>Completeness</th>\n",
       "      <th>Unique</th>\n",
       "      <th>Duplicate</th>\n",
       "      <th>Uniqueness</th>\n",
       "      <th>Size (Bytes)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>id</td>\n",
       "      <td>string[python]</td>\n",
       "      <td>5904</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5904</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>396128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>app_id</td>\n",
       "      <td>string[python]</td>\n",
       "      <td>5904</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2157</td>\n",
       "      <td>3747</td>\n",
       "      <td>0.365346</td>\n",
       "      <td>392750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>app_name</td>\n",
       "      <td>string[python]</td>\n",
       "      <td>5904</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2157</td>\n",
       "      <td>3747</td>\n",
       "      <td>0.365346</td>\n",
       "      <td>478086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>category_id</td>\n",
       "      <td>category</td>\n",
       "      <td>5904</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>14</td>\n",
       "      <td>5890</td>\n",
       "      <td>0.002371</td>\n",
       "      <td>7314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>author</td>\n",
       "      <td>string[python]</td>\n",
       "      <td>5904</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5902</td>\n",
       "      <td>2</td>\n",
       "      <td>0.999661</td>\n",
       "      <td>454608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>rating</td>\n",
       "      <td>int16</td>\n",
       "      <td>5904</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5</td>\n",
       "      <td>5899</td>\n",
       "      <td>0.000847</td>\n",
       "      <td>11808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>content</td>\n",
       "      <td>string[python]</td>\n",
       "      <td>5904</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5732</td>\n",
       "      <td>172</td>\n",
       "      <td>0.970867</td>\n",
       "      <td>2910420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>vote_sum</td>\n",
       "      <td>int64</td>\n",
       "      <td>5904</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>14</td>\n",
       "      <td>5890</td>\n",
       "      <td>0.002371</td>\n",
       "      <td>47232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>vote_count</td>\n",
       "      <td>int64</td>\n",
       "      <td>5904</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>18</td>\n",
       "      <td>5886</td>\n",
       "      <td>0.003049</td>\n",
       "      <td>47232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>date</td>\n",
       "      <td>datetime64[ms]</td>\n",
       "      <td>5904</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5904</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>47232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>category</td>\n",
       "      <td>category</td>\n",
       "      <td>5904</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>14</td>\n",
       "      <td>5890</td>\n",
       "      <td>0.002371</td>\n",
       "      <td>7403</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Column        DataType  Complete  Null  Completeness  Unique  \\\n",
       "0            id  string[python]      5904     0           1.0    5904   \n",
       "1        app_id  string[python]      5904     0           1.0    2157   \n",
       "2      app_name  string[python]      5904     0           1.0    2157   \n",
       "3   category_id        category      5904     0           1.0      14   \n",
       "4        author  string[python]      5904     0           1.0    5902   \n",
       "5        rating           int16      5904     0           1.0       5   \n",
       "6       content  string[python]      5904     0           1.0    5732   \n",
       "7      vote_sum           int64      5904     0           1.0      14   \n",
       "8    vote_count           int64      5904     0           1.0      18   \n",
       "9          date  datetime64[ms]      5904     0           1.0    5904   \n",
       "10     category        category      5904     0           1.0      14   \n",
       "\n",
       "    Duplicate  Uniqueness  Size (Bytes)  \n",
       "0           0    1.000000        396128  \n",
       "1        3747    0.365346        392750  \n",
       "2        3747    0.365346        478086  \n",
       "3        5890    0.002371          7314  \n",
       "4           2    0.999661        454608  \n",
       "5        5899    0.000847         11808  \n",
       "6         172    0.970867       2910420  \n",
       "7        5890    0.002371         47232  \n",
       "8        5886    0.003049         47232  \n",
       "9           0    1.000000         47232  \n",
       "10       5890    0.002371          7403  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.profile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset comprises 22,166,591 fully complete records, with no missing values, and a well-structured variety of data types. Key interpretations include:\n",
    "\n",
    "- **Data Types**: The dataset employs a thoughtful mix of data types, such as strings for identifiers and text fields, `int16` and `int64` for numerical columns like `Rating`, `Vote Sum`, and `Vote Count`, and `datetime64[ms]` for precise date tracking. This combination ensures both efficiency and accuracy in data handling.\n",
    "\n",
    "- **Duplicate Review IDs**: There are 117 duplicate `ID` values, indicating potential duplicate reviews. This suggests the need for a deduplication process to ensure data integrity and prevent biases in analysis due to repeated entries.\n",
    "\n",
    "- **Categorical Insights**: The dataset features 14 unique `Category` values, reflecting the breadth of application categories, and 5 unique `Rating` values, consistent with a standard 5-point rating scale. These are critical for categorical analyses and aggregating review sentiment.\n",
    "\n",
    "- **Duplicate Content**: The `Content` column shows high uniqueness overall but also includes significant duplicate entries. This could indicate commonly used phrases or templated responses in short reviews, which may require special handling during text analysis to differentiate between genuine user feedback and repetitive content.\n",
    "\n",
    "- **High Uniqueness in Key Columns**: Columns like `ID`, `Content`, and `Date` demonstrate high uniqueness, essential for detailed individual review analysis and time-series studies.\n",
    "\n",
    "- **Memory Efficiency**: Despite the large volume, efficient use of data types—particularly categorical and numerical fields—helps manage the dataset's memory footprint. The `Content` field, being text-heavy, dominates memory usage but is critical for in-depth textual analysis.\n",
    "\n",
    "Overall, the dataset is ready for a more robust quality analysis, with attention to duplication, relevance, validity, and privacy concerns. \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AppVoCAI Dataset Summary\n",
    "Here, we summarize the dataset contents in terms of reviews, apps, reviewer engagement, influence, app, and categorical breadth."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "PySparkTypeError",
     "evalue": "[NOT_COLUMN_OR_STR] Argument `col` should be a Column or str, got float.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPySparkTypeError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mdataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msummary\u001b[49m\n",
      "File \u001b[0;32m~/projects/genailab/genailab/asset/dataset/dataset.py:160\u001b[0m, in \u001b[0;36mDataset.summary\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    158\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_summary \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    159\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_set_summarizer()\n\u001b[0;32m--> 160\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_summary \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_summarizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msummarize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataframe\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataframe\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mprint\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    161\u001b[0m title \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAppVoCAI Dataset Summary\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_passport\u001b[38;5;241m.\u001b[39mphase\u001b[38;5;241m.\u001b[39mlabel\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_passport\u001b[38;5;241m.\u001b[39mstage\u001b[38;5;241m.\u001b[39mlabel\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    162\u001b[0m Printer()\u001b[38;5;241m.\u001b[39mprint_dict(title\u001b[38;5;241m=\u001b[39mtitle, data\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_summary)\n",
      "File \u001b[0;32m~/projects/genailab/genailab/analytics/summary.py:124\u001b[0m, in \u001b[0;36mPandasSummarizer.summarize\u001b[0;34m(self, dataframe, print)\u001b[0m\n\u001b[1;32m    122\u001b[0m n_auth \u001b[38;5;241m=\u001b[39m dataframe[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mauthor\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mnunique()\n\u001b[1;32m    123\u001b[0m n_auth_inf \u001b[38;5;241m=\u001b[39m dataframe\u001b[38;5;241m.\u001b[39mloc[dataframe[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvote_count\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mauthor\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mnunique()\n\u001b[0;32m--> 124\u001b[0m p_auth_inf \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mround\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mn_auth_inf\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mn_auth\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mif\u001b[39;00m n_auth \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;241m0.0\u001b[39m\n\u001b[1;32m    125\u001b[0m n_repeat_auth \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m((dataframe[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mauthor\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mvalue_counts() \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39msum())\n\u001b[1;32m    126\u001b[0m p_repeat_auth \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mround\u001b[39m(n_repeat_auth \u001b[38;5;241m/\u001b[39m n_auth \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m100\u001b[39m, \u001b[38;5;241m2\u001b[39m) \u001b[38;5;28;01mif\u001b[39;00m n_auth \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;241m0.0\u001b[39m\n",
      "File \u001b[0;32m~/miniconda3/envs/genai/lib/python3.10/site-packages/pyspark/sql/utils.py:174\u001b[0m, in \u001b[0;36mtry_remote_functions.<locals>.wrapped\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    172\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(functions, f\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m)(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    173\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 174\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/genai/lib/python3.10/site-packages/pyspark/sql/functions.py:4827\u001b[0m, in \u001b[0;36mround\u001b[0;34m(col, scale)\u001b[0m\n\u001b[1;32m   4799\u001b[0m \u001b[38;5;129m@try_remote_functions\u001b[39m\n\u001b[1;32m   4800\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mround\u001b[39m(col: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mColumnOrName\u001b[39m\u001b[38;5;124m\"\u001b[39m, scale: \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Column:\n\u001b[1;32m   4801\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   4802\u001b[0m \u001b[38;5;124;03m    Round the given value to `scale` decimal places using HALF_UP rounding mode if `scale` >= 0\u001b[39;00m\n\u001b[1;32m   4803\u001b[0m \u001b[38;5;124;03m    or at integral part when `scale` < 0.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4825\u001b[0m \u001b[38;5;124;03m    [Row(r=3.0)]\u001b[39;00m\n\u001b[1;32m   4826\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 4827\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _invoke_function(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mround\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[43m_to_java_column\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcol\u001b[49m\u001b[43m)\u001b[49m, scale)\n",
      "File \u001b[0;32m~/miniconda3/envs/genai/lib/python3.10/site-packages/pyspark/sql/column.py:65\u001b[0m, in \u001b[0;36m_to_java_column\u001b[0;34m(col)\u001b[0m\n\u001b[1;32m     63\u001b[0m     jcol \u001b[38;5;241m=\u001b[39m _create_column_from_name(col)\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m PySparkTypeError(\n\u001b[1;32m     66\u001b[0m         error_class\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNOT_COLUMN_OR_STR\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     67\u001b[0m         message_parameters\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marg_name\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcol\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marg_type\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mtype\u001b[39m(col)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m},\n\u001b[1;32m     68\u001b[0m     )\n\u001b[1;32m     69\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m jcol\n",
      "\u001b[0;31mPySparkTypeError\u001b[0m: [NOT_COLUMN_OR_STR] Argument `col` should be a Column or str, got float."
     ]
    }
   ],
   "source": [
    "dataset.summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Key Observations\n",
    "\n",
    "- **Volume and Scale**: The dataset contains a substantial number of reviews (22.17 million) and reviewers (15.71 million), indicating a broad and diverse user engagement across a wide range of applications.\n",
    "\n",
    "- **Repeat Reviewers**: Approximately 22.9% of reviewers have submitted more than one review, suggesting a significant proportion of engaged users who consistently contribute feedback. This can provide valuable longitudinal insights into user experiences and loyalty.\n",
    "\n",
    "- **Influential Reviewers**: With 6.6% of reviewers deemed influential (based on vote sum and counts), their contributions could play a pivotal role in shaping app perceptions and rankings.\n",
    "\n",
    "- **App Diversity**: The dataset covers 36,377 unique apps across 14 categories, indicating a wide-ranging scope of applications. This diversity is beneficial for conducting category-specific analyses and identifying trends within various app domains.\n",
    "\n",
    "- **Review Distribution**: On average, each app has approximately 609 reviews. This high level of engagement per app supports detailed app-level performance and sentiment analysis.\n",
    "\n",
    "- **Temporal Range**: The dataset spans over 15 years, from July 2008 to September 2023. This extensive timeframe allows for robust historical analysis, capturing the evolution of user feedback and app development trends over time.\n",
    "\n",
    "- **Memory Usage**: The dataset's size is significant, with a memory footprint of approximately 14.51 GB. This underscores the need for efficient data handling and processing strategies, particularly for large-scale analyses.\n",
    "\n",
    "- **Feature Richness**: With 11 distinct app, reviewer, and review features, the dataset enables both qualitative (review) and quantitative (rating, review_count, vote metrics) analysis of app performance and user sentiment.\n",
    "\n",
    "---\n",
    "\n",
    "### Observations\n",
    "This initial data profiling reveals a substantial and diverse dataset with significant potential for evaluating the performance of LLMs and SLMs, particularly in the context of fine-tuning foundation models. Transformer models require large volumes of data, and the volume of reviews, the extensive 15 year temporal span, and categorical coverage provide a solid foundation for LLM model training and evaluation. Yet, the data quality analysis to follow will evince dataset validity, relevance, completeness, and uniqueness, providing a more nuanced understanding of its suitability for training and evaluating LLMs and SLMs for specific tasks, such as Aspect-Based Sentiment Analysis (ABSA)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "genai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
