{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": [
     "remove-cell"
    ]
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import os\n",
    "\n",
    "if \"jbook\" in os.getcwd():\n",
    "    os.chdir(os.path.abspath(os.path.join(\"../..\")))\n",
    "FORCE = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Quality Analysis (TQA) for Aspect-Based Sentiment Analysis (ABSA)\n",
    "---\n",
    "In **Aspect-Based Sentiment Analysis (ABSA)**, the primary goal is to extract sentiment for specific aspects within a text, such as products, services, or features. To ensure accurate sentiment extraction, the text must be of sufficient quality. Text quality directly influences the effectiveness of ABSA models, and assessing text quality is crucial to improve aspect-level sentiment predictions.\n",
    "\n",
    "The **Text Quality Analysis (TQA)** process evaluates various features of the text that may affect ABSA performance. It focuses on syntactic and lexical features that help determine the relevance, richness, and clarity of the content in relation to specific aspects.\n",
    "\n",
    "Key **requirements for ABSA-based text quality** are:\n",
    "\n",
    "- **Aspect Identification**: Clear identification of aspects (e.g., product features or services).\n",
    "- **Aspect-Verb Pairing**: The relationship between aspects and verbs (actions related to aspects).\n",
    "- **Text Coherence and Complexity**: Well-formed sentences with a manageable level of complexity.\n",
    "- **Lexical Density and Content Richness**: The degree to which the content reflects substantive, content-rich words.\n",
    "\n",
    "These requirements are captured by **syntactic measures** like noun phrases, verb phrases, aspect-verb pairs, and additional features like review length, lexical density, and dependency depth. Together, these features inform the quality of text in the context of ABSA tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Measures of Text Quality and Their Weights\n",
    "---\n",
    "The following **syntactic features** and their **weights** quantify the quality of a given text for ABSA. Each measure contributes to the overall **Text Quality Analysis (TQA)** score, which is a weighted sum of these features.\n",
    "\n",
    "$$\n",
    "\\text{TQA Score}=\\sum_{i} \\left( \\text{Measure Score}_i \\times \\text{Weight}_i \\right)\n",
    "$$\n",
    "\n",
    "Here’s the run-through of each measure, its weight, and its impact on the overall TQA score:\n",
    "\n",
    "- **Aspect-Verb Pairs**: This measure identifies the relationship between **aspects** (e.g., product features) and **verbs** (actions related to those aspects). A higher number of aspect-verb pairs indicates that the text is highly relevant to ABSA, making it the most heavily weighted feature in TQA with a weight of **4**.    \n",
    "- **Noun Phrases**: Noun phrases help identify **key entities** and aspects in the text. The weight of **2.5** reflects the importance of rich, aspect-relevant content in generating accurate sentiment scores.    \n",
    "- **Verb Phrases**: Verb phrases identify the **actions or states** related to aspects. This has a weight of **2**, highlighting the importance of these phrases for understanding sentiment.    \n",
    "- **Adjective Count**: Adjectives capture **descriptive sentiment**, reflecting the **quality and intensity** of the sentiments expressed. It is weighted at **1.5**, indicating its moderate to high importance in sentiment analysis.    \n",
    "- **Lexical Density**: This measure quantifies the amount of **content-rich vocabulary** used in the text. High lexical density indicates that the text contains more **substantive content**, making it more informative for sentiment analysis. It is weighted at **1.5**.    \n",
    "- **Noun Count**: The count of **nouns** provides insights into the **syntactic structure** and **content** of the text. It is weighted at **1**, reflecting its importance in the analysis of textual richness.    \n",
    "- **Verb Count**: The count of **verbs** helps capture the **action-oriented components** of the text. Like the noun count, it is weighted at **1**.    \n",
    "- **Review Length**: Longer reviews generally provide more context for sentiment analysis, but excessive length can introduce noise. It is weighted at **1**, reflecting its moderate importance in sentiment prediction.    \n",
    "- **Dependency Depth**: This measure indicates the **complexity** of sentence structure. Although sentence complexity can affect sentiment extraction, it plays a secondary role in ABSA and is weighted at **1**.    \n",
    "- **Adverb Count**: Adverbs modify verbs or adjectives, helping capture nuances in sentiment. With a weight of **0.75**, it plays a supportive role in sentiment analysis.    \n",
    "- **Adverbial Phrases**: These phrases provide additional **modification** of actions, aspects, and sentiments. They are weighted at **0.5**, as they are considered less important than noun and verb phrases in ABSA tasks.\n",
    "\n",
    "**Summary of Weights:**\n",
    "\n",
    "| Measure           | Weight |\n",
    "|-------------------|--------|\n",
    "| Aspect-Verb Pairs | 4      |\n",
    "| Noun Phrases      | 2.5    |\n",
    "| Verb Phrases      | 2      |\n",
    "| Adjective Count   | 1.5    |\n",
    "| Lexical Density   | 1.5    |\n",
    "| Noun Count        | 1      |\n",
    "| Verb Count        | 1      |\n",
    "| Review Length     | 1      |\n",
    "| Dependency Depth  | 1      |\n",
    "| Adverb Count      | 0.75   |\n",
    "| Adverbial Phrases | 0.5    |\n",
    "\n",
    "## Text Quality Analysis Pipeline\n",
    "With that, the text quality analysis (TQA) processing pipeline computes these text quality metrics at scale.\n",
    "\n",
    "The pipeline leverages:     \n",
    "- Dask for distributed data processing, enabling efficient computation over large text datasets.\n",
    "- spaCy for NLP tasks, including dependency parsing and part-of-speech (POS) tagging.\n",
    "\n",
    "The pipeline follows these steps:    \n",
    "- Dataset Configuration: Define the source and target dataset configurations.\n",
    "- Pipeline Construction: Instantiate the TQAStageBuilder and configure it for Dask processing.\n",
    "- Execution: Run the TQAStage, applying text analysis and feature extraction.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "hide-cell"
    ]
   },
   "source": [
    "### Import Libraries\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": [
     "hide-cell"
    ]
   },
   "outputs": [],
   "source": [
    "\n",
    "from genailab.setup import auto_wire_container\n",
    "from genailab.core.dtypes import DFType\n",
    "from genailab.infra.utils.file.fileset import FileFormat\n",
    "from genailab.asset.dataset.config import DatasetConfig\n",
    "from genailab.flow.dataprep.tqa.builder import TQAStageBuilder\n",
    "from genailab.asset.dataset.config import DatasetConfig\n",
    "from genailab.core.flow import PhaseDef, StageDef\n",
    "\n",
    "\n",
    "# Wire container\n",
    "container = auto_wire_container()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the Source and Target Dataset Configurations\n",
    "---\n",
    "The source dataset represents the cleaned text data, while the target dataset will store the extracted text quality features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Source Dataset Configuration\n",
    "source_config = DatasetConfig(\n",
    "    phase=PhaseDef.DATAPREP,\n",
    "    stage=StageDef.CLEAN,\n",
    "    name=\"review\",\n",
    "    file_format=FileFormat.PARQUET,\n",
    "    asset_type=\"dataset\",\n",
    "    dftype=DFType.PANDAS,\n",
    ")\n",
    "\n",
    "# Target Dataset Configuration\n",
    "target_config = DatasetConfig(\n",
    "    phase=PhaseDef.DATAPREP,\n",
    "    stage=StageDef.TQA,\n",
    "    name=\"review\",\n",
    "    file_format=FileFormat.PARQUET,\n",
    "    asset_type=\"dataset\",\n",
    "    dftype=DFType.PANDAS,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Construct the TQA Pipeline\n",
    "---\n",
    "We use the TQAStageBuilder to configure a Dask-powered text quality analysis pipeline with:\n",
    "\n",
    "- Normalization enabled (ensures robust feature scaling).\n",
    "- Batch processing (improves efficiency for large datasets)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stage = (\n",
    "    TQAStageBuilder()\n",
    "        .with_dask(normalized=True, batched=True)\n",
    "        .build(source_config=source_config, target_config=target_config))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run the Pipeline\n",
    "---\n",
    "Once the pipeline is built, we execute it to compute text quality features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = stage.run(force=FORCE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validate the Dataset\n",
    "---\n",
    "Let's ensure that the text quality measures have been added and the dataset is in the repository."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dataset Profile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.profile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dataset Sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.dataframe.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dataset Repository"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "repo = container.io.repo()\n",
    "ds = repo.get(asset_id=dataset.asset_id)\n",
    "assert ds == dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great! Now that we've confirmed the dataset has been successfully processed, we have a set of **text quality analysis** metrics that we can use for instance selection during the feature engineering stage.\n",
    "Next, we transition to **sentiment analysis at the review level**. In this phase, we will analyze the overall **sentiment** of each review."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "genai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
