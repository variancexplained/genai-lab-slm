{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": [
     "remove-cell"
    ]
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import os\n",
    "\n",
    "if \"jbook\" in os.getcwd():\n",
    "    os.chdir(os.path.abspath(os.path.join(\"../..\")))\n",
    "FORCE = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Quality Analysis (TQA) for Aspect-Based Sentiment Analysis (ABSA)\n",
    "---\n",
    "In the upcoming **Aspect-Based Sentiment Analysis (ABSA)** modeling phase, we evaluate the cost-performance tradeoffs between custom LLMs and fine-tuned foundational models for identifying, extracting, and classifying sentiments associated with product and service aspects in the AppVoCAI Dataset. A consistent trend in ABSA literature underscores the primacy of text quality over sheer volume, where high-quality input data improves the granularity and reliability of extracted sentiment signals.\n",
    "\n",
    "This Text Quality Analysis (TQA) effort assesses review suitability for ABSA model development, emphasizing syntactic and lexical features that influence the clarity, richness, and relevance of aspects, opinions and sentiment signals. Our weighted text quality scoring method described below will guide instance selection for ABSA model training and fine-tuning. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Measures of Text Quality and Their Weights\n",
    "---\n",
    "The following **syntactic features** and their **weights** quantify the quality of a given text for ABSA. Each measure contributes to the overall **Text Quality Analysis (TQA)** score, which is a weighted sum of these features.\n",
    "\n",
    "$$\n",
    "\\text{TQAÂ Score}=\\sum_{i} \\left( \\text{Measure Score}_i \\times \\text{Weight}_i \\right)\n",
    "$$\n",
    "\n",
    "### High Importance (Coefficients 3.0 and above):    \n",
    "- **aspect_verb_pairs (4.0)**: These pairs directly link an aspect (noun or noun phrase) with an action or state (verb) related to that aspect. This is highly informative for understanding how users feel about specific aspects. \"The battery drains quickly\" clearly links \"battery\" (aspect) with a negative sentiment via \"drains quickly\" (verb phrase).\n",
    "- **noun_adjective_pairs (3.0)**: As discussed, these pairs are strong indicators of sentiment towards an aspect. \"Excellent screen\" directly expresses positive sentiment towards \"screen.\" While slightly less direct than aspect-verb pairs, they are still highly valuable.\n",
    "\n",
    "### Medium Importance (Coefficients between 1.5 and 2.5):    \n",
    "- **noun_phrases (2.5)**: Noun phrases often represent aspects themselves, even without an accompanying adjective or verb. \"The camera quality\" is a clear aspect, even if the sentiment is expressed elsewhere in the sentence.\n",
    "- **verb_phrases (2.0)**: Verb phrases can provide context and nuance to the sentiment. \"The phone performs well\" is more informative than just \"phone\" or \"performs.\"\n",
    "- **adjective_count (1.5)**: The sheer number of adjectives can give a general indication of the sentiment's intensity. A review with many positive adjectives is likely more positive overall. However, individual adjectives within noun-adjective pairs are more informative.\n",
    "- **lexical_density (1.5)**: Lexical density (the proportion of content words) can be a proxy for the information content of a review. Higher lexical density might suggest more specific and detailed feedback, which could be useful for ABSA.\n",
    "\n",
    "### Lower Importance (Coefficients below 1.5):   \n",
    "- **adverb_count (0.75)**: Adverbs can modify adjectives or verbs, adding nuance. However, their contribution to ABSA might be less direct compared to adjectives or verbs themselves.\n",
    "- **noun_count (1.0)**: The raw count of nouns is less informative than noun phrases or nouns in noun-adjective pairs. It's more of a general indicator of review length and complexity.\n",
    "- **verb_count (1.0)**: Similar to noun count, the raw count of verbs is less directly related to ABSA than verb phrases or verbs in aspect-verb pairs.\n",
    "- **adverbial_phrases (0.5)**: Similar to adverbs, adverbial phrases can add detail but are less directly related to aspect-based sentiment.\n",
    "- **review_length (1.0)**: Review length is a general metric and doesn't directly contribute to ABSA. Longer reviews might contain more information, but they can also be rambling.\n",
    "- **dependency_depth (1.0)**: Dependency depth can be a measure of syntactic complexity, but its relationship to ABSA is not as clear. Complex sentences aren't necessarily more or less sentiment-bearing than simpler ones.\n",
    "\n",
    "**Summary of Weights:**\n",
    "\n",
    "| Measure              | Weight |\n",
    "|----------------------|--------|\n",
    "| aspect_verb_pairs    | 4      |\n",
    "| noun_adjective_pairs | 3      |\n",
    "| noun_phrases         | 2.5    |\n",
    "| verb_phrases         | 2      |\n",
    "| adjective_count      | 1.5    |\n",
    "| lexical_density      | 1.5    |\n",
    "| noun_count           | 1      |\n",
    "| verb_count           | 1      |\n",
    "| review_length        | 1      |\n",
    "| dependency_depth     | 1      |\n",
    "| adverb_count         | 0.75   |\n",
    "| adverbial_phrases    | 0.5    |\n",
    "\n",
    "**Important Note:** These weights represent a starting hypothesis. The TQA Exploratory Data Analysis will evaluate the degree to which this weighting regime reflects the quality of reviews for the ABSA task.\n",
    "\n",
    "## Text Quality Analysis Pipeline\n",
    "With that, the text quality analysis (TQA) processing pipeline computes these text quality metrics at scale.\n",
    "\n",
    "The pipeline leverages:     \n",
    "- Dask for distributed data processing, enabling efficient computation over large text datasets.\n",
    "- spaCy for NLP tasks, including dependency parsing and part-of-speech (POS) tagging.\n",
    "\n",
    "The pipeline follows these steps:    \n",
    "- Dataset Configuration: Define the source and target dataset configurations.\n",
    "- Pipeline Construction: Instantiate the TQAStageBuilder and configure it for Dask processing.\n",
    "- Execution: Run the TQAStage, applying text analysis and feature extraction.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "hide-cell"
    ]
   },
   "source": [
    "### Import Libraries\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": [
     "hide-cell"
    ]
   },
   "outputs": [],
   "source": [
    "\n",
    "from genailab.setup import auto_wire_container\n",
    "from genailab.core.dtypes import DFType\n",
    "from genailab.infra.utils.file.fileset import FileFormat\n",
    "from genailab.asset.dataset.config import DatasetConfig\n",
    "from genailab.flow.dataprep.tqa.builder import TQAStageBuilder\n",
    "from genailab.asset.dataset.config import DatasetConfig\n",
    "from genailab.core.flow import PhaseDef, StageDef\n",
    "\n",
    "\n",
    "# Wire container\n",
    "container = auto_wire_container()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the Source and Target Dataset Configurations\n",
    "---\n",
    "The source dataset represents the cleaned text data, while the target dataset will store the extracted text quality features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Source Dataset Configuration\n",
    "source_config = DatasetConfig(\n",
    "    phase=PhaseDef.DATAPREP,\n",
    "    stage=StageDef.CLEAN,\n",
    "    name=\"review\",\n",
    "    file_format=FileFormat.PARQUET,\n",
    "    asset_type=\"dataset\",\n",
    "    dftype=DFType.PANDAS,\n",
    ")\n",
    "\n",
    "# Target Dataset Configuration\n",
    "target_config = DatasetConfig(\n",
    "    phase=PhaseDef.DATAPREP,\n",
    "    stage=StageDef.TQA,\n",
    "    name=\"review\",\n",
    "    file_format=FileFormat.PARQUET,\n",
    "    asset_type=\"dataset\",\n",
    "    dftype=DFType.PANDAS,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Construct the TQA Pipeline\n",
    "---\n",
    "We use the TQAStageBuilder to configure a Dask-powered text quality analysis pipeline with:\n",
    "\n",
    "- Normalization enabled (ensures robust feature scaling).\n",
    "- Batch processing (improves efficiency for large datasets)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "stage = (\n",
    "    TQAStageBuilder()\n",
    "        .analyze_text()\n",
    "        .build(source_config=source_config, target_config=target_config))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run the Pipeline\n",
    "---\n",
    "Once the pipeline is built, we execute it to compute text quality features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "# ============================================================================== #\n",
      "#             Text Quality Analysis Stage Sun, 09 Feb 2025 20:23:34              #\n",
      "# ============================================================================== #\n",
      "\n",
      "____________________________________________________________________________________________________\n",
      "Text Quality Analysis Stage             20:23:34    20:25:16    1.0 minute and 41.91 seconds                       \n",
      "\n",
      "\n",
      "# ============================================================================ #\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dataset = stage.run(force=FORCE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TQA Scoring Evaluation\n",
    "---\n",
    "Does `tqa_score` and `tqa_rating` adequately reflect the quality of review text for ABSA? Let's inspect samples stratified by `tqa_rating`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = dataset.dataframe\n",
    "cols = [\"content\",\n",
    "\"noun_count\",\n",
    "\"verb_count\",\n",
    "\"adjective_count\",\n",
    "\"adverb_count\",\n",
    "\"aspect_verb_pairs\",\n",
    "\"noun_adjective_pairs\",\n",
    "\"noun_phrases\",\n",
    "\"verb_phrases\",\n",
    "\"adverbial_phrases\",\n",
    "\"review_length\",\n",
    "\"lexical_density\",\n",
    "\"dependency_depth\",\n",
    "\"tqa_score\",\n",
    "\"tqa_rating\",\n",
    "]\n",
    "tqa5 = df.loc[df['tqa_rating']==5,cols].sample(n=10)\n",
    "tqa4 = df.loc[df['tqa_rating']==4,cols].sample(n=10)\n",
    "tqa3 = df.loc[df['tqa_rating']==3,cols].sample(n=10)\n",
    "tqa2 = df.loc[df['tqa_rating']==2,cols].sample(n=10)\n",
    "tqa1 = df.loc[df['tqa_rating']==1,cols].sample(n=10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Highest Quality Reviews (TQA Rating = 5)\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great! Now that we've confirmed the dataset has been successfully processed, we have a set of **text quality analysis** metrics that we can use for instance selection during the feature engineering stage.\n",
    "Next, we transition to **sentiment analysis at the review level**. In this phase, we will analyze the overall **sentiment** of each review."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>noun_count</th>\n",
       "      <th>verb_count</th>\n",
       "      <th>adjective_count</th>\n",
       "      <th>adverb_count</th>\n",
       "      <th>aspect_verb_pairs</th>\n",
       "      <th>noun_adjective_pairs</th>\n",
       "      <th>noun_phrases</th>\n",
       "      <th>verb_phrases</th>\n",
       "      <th>adverbial_phrases</th>\n",
       "      <th>review_length</th>\n",
       "      <th>lexical_density</th>\n",
       "      <th>dependency_depth</th>\n",
       "      <th>tqa_score</th>\n",
       "      <th>tqa_rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1339</th>\n",
       "      <td>i have only had this happen twice but this las...</td>\n",
       "      <td>4.682131</td>\n",
       "      <td>1.386294</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.098612</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.718499</td>\n",
       "      <td>4.615121</td>\n",
       "      <td>4.718499</td>\n",
       "      <td>28.208848</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1049</th>\n",
       "      <td>i used to really like this app but recently it...</td>\n",
       "      <td>4.219508</td>\n",
       "      <td>1.098612</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.26268</td>\n",
       "      <td>4.615121</td>\n",
       "      <td>4.26268</td>\n",
       "      <td>22.499028</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1643</th>\n",
       "      <td>is time for my new years resolutions and becom...</td>\n",
       "      <td>4.356709</td>\n",
       "      <td>1.386294</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.406719</td>\n",
       "      <td>4.615121</td>\n",
       "      <td>4.406719</td>\n",
       "      <td>23.21199</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4242</th>\n",
       "      <td>it is very shameful for myanmar military terro...</td>\n",
       "      <td>4.488636</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.49981</td>\n",
       "      <td>4.615121</td>\n",
       "      <td>4.49981</td>\n",
       "      <td>22.143804</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>649</th>\n",
       "      <td>the inapp menu does not match the pamphlet the...</td>\n",
       "      <td>3.044522</td>\n",
       "      <td>1.098612</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.135494</td>\n",
       "      <td>4.615121</td>\n",
       "      <td>3.135494</td>\n",
       "      <td>21.842261</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>953</th>\n",
       "      <td>hilarious content i dont know what youre doing...</td>\n",
       "      <td>2.944439</td>\n",
       "      <td>1.386294</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.091042</td>\n",
       "      <td>4.615121</td>\n",
       "      <td>3.091042</td>\n",
       "      <td>21.940956</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1722</th>\n",
       "      <td>ive been on ww many times in my life starting ...</td>\n",
       "      <td>4.189655</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.204693</td>\n",
       "      <td>4.615121</td>\n",
       "      <td>4.204693</td>\n",
       "      <td>21.947736</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1779</th>\n",
       "      <td>i absolutely love this app it has reps sets an...</td>\n",
       "      <td>5.105945</td>\n",
       "      <td>2.079442</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.159055</td>\n",
       "      <td>4.615121</td>\n",
       "      <td>5.159055</td>\n",
       "      <td>26.159046</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1577</th>\n",
       "      <td>okay so i have adhd and i need to play with st...</td>\n",
       "      <td>4.304065</td>\n",
       "      <td>1.098612</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.343805</td>\n",
       "      <td>4.615121</td>\n",
       "      <td>4.343805</td>\n",
       "      <td>25.518426</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3456</th>\n",
       "      <td>i have for years been somewhat skeptical of ai...</td>\n",
       "      <td>4.219508</td>\n",
       "      <td>1.609438</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.276666</td>\n",
       "      <td>4.615121</td>\n",
       "      <td>4.276666</td>\n",
       "      <td>25.463842</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                content noun_count verb_count  \\\n",
       "1339  i have only had this happen twice but this las...   4.682131   1.386294   \n",
       "1049  i used to really like this app but recently it...   4.219508   1.098612   \n",
       "1643  is time for my new years resolutions and becom...   4.356709   1.386294   \n",
       "4242  it is very shameful for myanmar military terro...   4.488636        0.0   \n",
       "649   the inapp menu does not match the pamphlet the...   3.044522   1.098612   \n",
       "953   hilarious content i dont know what youre doing...   2.944439   1.386294   \n",
       "1722  ive been on ww many times in my life starting ...   4.189655   0.693147   \n",
       "1779  i absolutely love this app it has reps sets an...   5.105945   2.079442   \n",
       "1577  okay so i have adhd and i need to play with st...   4.304065   1.098612   \n",
       "3456  i have for years been somewhat skeptical of ai...   4.219508   1.609438   \n",
       "\n",
       "     adjective_count adverb_count aspect_verb_pairs noun_adjective_pairs  \\\n",
       "1339             0.0          0.0          1.098612                  0.0   \n",
       "1049             0.0          0.0               0.0                  0.0   \n",
       "1643             0.0          0.0               0.0                  0.0   \n",
       "4242             0.0          0.0               0.0                  0.0   \n",
       "649              0.0          0.0          0.693147                  0.0   \n",
       "953              0.0          0.0          0.693147                  0.0   \n",
       "1722             0.0          0.0               0.0                  0.0   \n",
       "1779             0.0          0.0               0.0                  0.0   \n",
       "1577             0.0          0.0          0.693147                  0.0   \n",
       "3456             0.0          0.0          0.693147                  0.0   \n",
       "\n",
       "     noun_phrases verb_phrases adverbial_phrases review_length  \\\n",
       "1339          0.0     0.693147               0.0      4.718499   \n",
       "1049     0.693147          0.0               0.0       4.26268   \n",
       "1643     0.693147          0.0               0.0      4.406719   \n",
       "4242     0.693147          0.0               0.0       4.49981   \n",
       "649      0.693147          0.0               0.0      3.135494   \n",
       "953      0.693147          0.0               0.0      3.091042   \n",
       "1722     0.693147          0.0               0.0      4.204693   \n",
       "1779     0.693147          0.0               0.0      5.159055   \n",
       "1577     0.693147          0.0               0.0      4.343805   \n",
       "3456          0.0     0.693147               0.0      4.276666   \n",
       "\n",
       "     lexical_density dependency_depth  tqa_score tqa_rating  \n",
       "1339        4.615121         4.718499  28.208848          5  \n",
       "1049        4.615121          4.26268  22.499028          5  \n",
       "1643        4.615121         4.406719   23.21199          5  \n",
       "4242        4.615121          4.49981  22.143804          5  \n",
       "649         4.615121         3.135494  21.842261          5  \n",
       "953         4.615121         3.091042  21.940956          5  \n",
       "1722        4.615121         4.204693  21.947736          5  \n",
       "1779        4.615121         5.159055  26.159046          5  \n",
       "1577        4.615121         4.343805  25.518426          5  \n",
       "3456        4.615121         4.276666  25.463842          5  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tqa5"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "genai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
