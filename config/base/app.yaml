#!/usr/bin/env python3
# -*- coding:utf-8 -*-
# ================================================================================================ #
# Project    : GenAI-Lab-SLM                                                                       #
# Version    : 0.1.0                                                                               #
# Python     : 3.10.14                                                                             #
# Filename   : /config/base/app.yaml                                                               #
# ------------------------------------------------------------------------------------------------ #
# Author     : John James                                                                          #
# Email      : john@variancexplained.com                                                           #
# URL        : https://github.com/variancexplained/genai-lab-slm                                   #
# ------------------------------------------------------------------------------------------------ #
# Created    : Monday September 9th 2024 11:24:51 am                                               #
# Modified   : Monday February 3rd 2025 10:24:46 pm                                                #
# ------------------------------------------------------------------------------------------------ #
# License    : MIT License                                                                         #
# Copyright  : (c) 2024 John James                                                                 #
# ================================================================================================ #
# ------------------------------------------------------------------------------------------------ #
#                                          LOGGING                                                 #
# ------------------------------------------------------------------------------------------------ #
logging:
  disable_existing_loggers: false
  formatters:
    console:
      datefmt: '%m/%d/%Y %I:%M:%S %p'
      format: '[%(asctime)s] [%(levelname)s] [%(name)s] [%(funcName)s] : %(message)s'
    file:
      datefmt: '%m/%d/%Y %I:%M:%S %p'
      format: '[%(asctime)s] [%(levelname)s] [%(name)s] [%(module)s] [%(funcName)s]
        : %(message)s'
  handlers:
    console:
      class: logging.StreamHandler
      formatter: console
      level: INFO # Default, possibly overridden in environment config
      stream: ext://sys.stderr
    file:
      backupCount: 0
      class: logging.handlers.TimedRotatingFileHandler
      filename: TBD # Override in environment specific configurations
      formatter: file
      interval: 1
      level: DEBUG # Default, possibly overridden in environment config
      when: midnight
  loggers:
    py4j:  # Add this block to suppress py4j logging
      level: ERROR
      handlers:
        - console
        - file
      propagate: false  # Prevent py4j logs from being propagated to the root logger
  root:
    handlers:
    - console
    - file
    level: DEBUG # Default, possibly overridden in environment config
  version: 1
# ------------------------------------------------------------------------------------------------ #
#                                DATA PROCESSING ENGINE                                            #
# ------------------------------------------------------------------------------------------------ #
spark:
  memory:
    driver: "32g"
    executor: "96g"
  retries: 3
  executor_cores: "4"  # Adjust as needed
  parquet_block_size: 1073741824 # 1 GB Default
# To compute memory limit, allocate 60%-70% of available memory and divide by nworkers to get
# memory_limit for each worker
dask:
  npartitions: 72
  nworkers: 18
  memory_limit: "5GiB"
  threads_per_worker: 1
  processes: False
# ------------------------------------------------------------------------------------------------ #
#                                       IO CONFIG                                                  #
# ------------------------------------------------------------------------------------------------ #
io:
  format: parquet
  dask:
    parquet:
      read_kwargs:
        filesystem: arrow
        parquet_file_extension: .parquet
      write_kwargs:
        append: False
        overwrite: False
        partition_on: category
        compute: True
        schema: infer
        filesystem: arrow
  pandas:
    csv:
      read_kwargs:
        dtype:
          id: string
          app_id: string
          app_name: string
          category_id: category
          category: category
          author: string
          rating: int16
          content: string
          vote_count: int64
          vote_sum: int64
        encoding: utf-8
        index_col: False
        lineterminator: "\n"
        parse_dates:
         - date
      write_kwargs:
        index: False
        mode: x
    parquet:
      read_kwargs:
        engine: pyarrow
      write_kwargs:
        engine: pyarrow
        compression: snappy
        index: False
        existing_data_behavior: delete_matching
        row_group_size: 1073741824 # 1 GB
        partition_cols:
          - category
  spark:
    csv:
      read_kwargs:
        encoding: UTF-8
        header: True
        inferSchema: True
      write_kwargs:
        header: True
        mode: error
    parquet:
      read_kwargs:
        encoding: UTF-8
        header: True
        inferSchema: True
      write_kwargs:
        mode: error
        partitionBy:
          - category
  sparknlp:
    csv:
      read_kwargs:
        encoding: UTF-8
        header: True
        inferSchema: True
      write_kwargs:
        header: True
        mode: error
    parquet:
      read_kwargs:
        encoding: UTF-8
        header: True
        inferSchema: True
      write_kwargs:
        mode: error
        partitionBy:
          - category

# ------------------------------------------------------------------------------------------------ #
#                                      OPERATORS                                                   #
# ------------------------------------------------------------------------------------------------ #
ops:
  convert:
    to_pandas_threshold: 1073741824  # 1 GB
    to_spark_threshold: 10737418240 # 10 GB

# ------------------------------------------------------------------------------------------------ #
#                                         DQA                                                      #
# ------------------------------------------------------------------------------------------------ #
dqa:
  dqs:
    weights:
      completeness: 0.25
      validity: 0.25
      relevance: 0.2
      uniqueness: 0.15
      privacy: 0.15
  validity:
    weights:
      rating: 0.2
      category: 0.1
      review: 0.6
      date: 0.1
    columns:
      rating_validity: dqa_validity_invalid_rating
      category_validity: dqa_validity_invalid_category
      date_validity: dqa_validity_invalid_review_date
      review_validity:
      - dqa_validity_contains_ctrl_chars
      - dqa_validity_contains_accents
      - dqa_validity_contains_html_chars
      - dqa_validity_contains_excess_whitespace
      - dqa_validity_contains_irrelevant_special_chars
      - dqa_validity_contains_excess_special_chars
      - dqa_validity_contains_elongation
      - dqa_validity_contains_excess_sequence_repetition
      - dqa_validity_contains_excess_word_repetition
      - dqa_validity_contains_excess_phrase_repetition
  relevance:
    weights:
      language: 0.4
      review_length: 0.6
    columns:
      language:
      - dqa_relevance_contains_non_english_app_name
      - dqa_relevance_contains_non_english_text
      review_length: dqa_relevance_short_review
  uniqueness:
    weights:
      row: 0.3
      review_id: 0.2
      review: 0.5
    columns:
      row: dqa_uniqueness_duplicate_row
      review_id:  dqa_uniqueness_duplicate_review_id
      review: dqa_uniqueness_duplicate_review
  privacy:
    columns:
      - dqa_privacy_contains_url
      - dqa_privacy_contains_email
      - dqa_privacy_contains_phone







