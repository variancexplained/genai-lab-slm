{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": [
     "remove-cell"
    ]
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "if \"jbook\" in os.getcwd():\n",
    "    os.chdir(os.path.abspath(os.path.join(\"../..\")))\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "FORCE = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AppVoCAI Dataset Preprocessing\n",
    "---\n",
    "In this section, we unbox and preprocess the AppVoCAI dataset, survey its key characteristics, and profile its structure, format, and data types, in advance of downstream data quality assessment, cleaning, analysis and feature engineering. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": [
     "hide-cell"
    ]
   },
   "outputs": [],
   "source": [
    "from genailab.setup import auto_wire_container\n",
    "from genailab.asset.dataset.config import DatasetConfig\n",
    "from genailab.core.dtypes import DFType\n",
    "from genailab.core.flow import PhaseDef, StageDef\n",
    "from genailab.infra.utils.file.fileset import FileFormat\n",
    "from genailab.flow.dataprep.preprocess.builder import PreprocessStageBuilder\n",
    "\n",
    "container = auto_wire_container()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing Pipeline\n",
    "---\n",
    "\n",
    "The `PreprocessingStage` ensures that the data are in a structure and format suitable for downstream processing and analysis. This involves verifying UTF-8 encoding, casting data to appropriate types, converting datetimes to millisecond precision (for Spark) and removing any extraneous newlines from the review text. \n",
    "\n",
    "Next, we'll define the configurations for the raw and preprocessed datasets, construct the PreprocessStage pipeline, the run it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Raw Datas Configuration\n",
    "source = DatasetConfig(phase=PhaseDef.DATAPREP, stage=StageDef.RAW, name=\"review\", file_format=FileFormat.PARQUET, dftype=DFType.PANDAS)\n",
    "# Target Dataset Configuration\n",
    "target = DatasetConfig(phase=PhaseDef.DATAPREP, stage=StageDef.PREPROCESS, name=\"review\", file_format=FileFormat.PARQUET, dftype=DFType.PANDAS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "# ============================================================================== #\n",
      "#               Data Preprocessing Stage Tue, 04 Feb 2025 12:50:56               #\n",
      "# ============================================================================== #\n",
      "\n",
      "\n",
      "Task                                    Start       End         Runtime     \n",
      "----------------------------------------------------------------------------\n",
      "VerifyEncodingTask                      12:50:56    12:50:56    0.19 seconds\n",
      "CastDataTypeTask                        12:50:56    12:50:56    0.04 seconds\n",
      "RemoveNewlinesTask                      12:50:56    12:50:56    0.07 seconds\n",
      "ConvertDateTimetoMS                     12:50:56    12:50:56    0.0 seconds \n",
      "____________________________________________________________________________\n",
      "Data Preprocessing Stage                12:50:56    12:50:57    1.08 seconds\n",
      "\n",
      "\n",
      "# ============================================================================ #\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Create the preprocess stage builder\n",
    "builder = PreprocessStageBuilder()\n",
    "# Add preprocess tasks to the builder and return the stage object.\n",
    "stage = (builder\n",
    "    .encoding()  # Verifies UTF-8 Encoding\n",
    "    .datatypes()  # Casts appropriate datatypes, i.e. category, int, float, and datetime variables.\n",
    "    .newlines()  # Removes newlines from text\n",
    "    .datetime()  # Converts datatime to millisecond precision (for pyspark)\n",
    "    .build(source_config=source, target_config=target)  # Constructs the pipeline and returns the stage\n",
    ")\n",
    "# Run the stage pipeline\n",
    "dataset = stage.run(force=FORCE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AppVoCAI Dataset Structure\n",
    "Let's examine the dataset structure, data types, completeness, uniqueness, and size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": [
     "hide-cell"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Column</th>\n",
       "      <th>DataType</th>\n",
       "      <th>Complete</th>\n",
       "      <th>Null</th>\n",
       "      <th>Completeness</th>\n",
       "      <th>Unique</th>\n",
       "      <th>Duplicate</th>\n",
       "      <th>Uniqueness</th>\n",
       "      <th>Size (Bytes)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>id</td>\n",
       "      <td>string[python]</td>\n",
       "      <td>86705</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>86705</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>5815037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>app_id</td>\n",
       "      <td>string[python]</td>\n",
       "      <td>86705</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9715</td>\n",
       "      <td>76990</td>\n",
       "      <td>0.112047</td>\n",
       "      <td>5763531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>app_name</td>\n",
       "      <td>string[python]</td>\n",
       "      <td>86705</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9712</td>\n",
       "      <td>76993</td>\n",
       "      <td>0.112012</td>\n",
       "      <td>7046269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>category_id</td>\n",
       "      <td>category</td>\n",
       "      <td>86705</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>14</td>\n",
       "      <td>86691</td>\n",
       "      <td>0.000161</td>\n",
       "      <td>88115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>author</td>\n",
       "      <td>string[python]</td>\n",
       "      <td>86705</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>86444</td>\n",
       "      <td>261</td>\n",
       "      <td>0.996990</td>\n",
       "      <td>6676285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>rating</td>\n",
       "      <td>Int16</td>\n",
       "      <td>86705</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5</td>\n",
       "      <td>86700</td>\n",
       "      <td>0.000058</td>\n",
       "      <td>260115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>content</td>\n",
       "      <td>string[python]</td>\n",
       "      <td>86705</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>81343</td>\n",
       "      <td>5362</td>\n",
       "      <td>0.938158</td>\n",
       "      <td>42464673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>vote_sum</td>\n",
       "      <td>Int64</td>\n",
       "      <td>86705</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>56</td>\n",
       "      <td>86649</td>\n",
       "      <td>0.000646</td>\n",
       "      <td>780345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>vote_count</td>\n",
       "      <td>Int64</td>\n",
       "      <td>86705</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>70</td>\n",
       "      <td>86635</td>\n",
       "      <td>0.000807</td>\n",
       "      <td>780345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>date</td>\n",
       "      <td>datetime64[ms]</td>\n",
       "      <td>86705</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>86643</td>\n",
       "      <td>62</td>\n",
       "      <td>0.999285</td>\n",
       "      <td>693640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>category</td>\n",
       "      <td>category</td>\n",
       "      <td>86705</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>14</td>\n",
       "      <td>86691</td>\n",
       "      <td>0.000161</td>\n",
       "      <td>88204</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Column        DataType  Complete  Null  Completeness  Unique  \\\n",
       "0            id  string[python]     86705     0           1.0   86705   \n",
       "1        app_id  string[python]     86705     0           1.0    9715   \n",
       "2      app_name  string[python]     86705     0           1.0    9712   \n",
       "3   category_id        category     86705     0           1.0      14   \n",
       "4        author  string[python]     86705     0           1.0   86444   \n",
       "5        rating           Int16     86705     0           1.0       5   \n",
       "6       content  string[python]     86705     0           1.0   81343   \n",
       "7      vote_sum           Int64     86705     0           1.0      56   \n",
       "8    vote_count           Int64     86705     0           1.0      70   \n",
       "9          date  datetime64[ms]     86705     0           1.0   86643   \n",
       "10     category        category     86705     0           1.0      14   \n",
       "\n",
       "    Duplicate  Uniqueness  Size (Bytes)  \n",
       "0           0    1.000000       5815037  \n",
       "1       76990    0.112047       5763531  \n",
       "2       76993    0.112012       7046269  \n",
       "3       86691    0.000161         88115  \n",
       "4         261    0.996990       6676285  \n",
       "5       86700    0.000058        260115  \n",
       "6        5362    0.938158      42464673  \n",
       "7       86649    0.000646        780345  \n",
       "8       86635    0.000807        780345  \n",
       "9          62    0.999285        693640  \n",
       "10      86691    0.000161         88204  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.profile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset comprises 22,166,591 fully complete records, with no missing values, and a well-structured variety of data types. Key interpretations include:\n",
    "\n",
    "- **Data Types**: The dataset employs a thoughtful mix of data types, such as strings for identifiers and text fields, `int16` and `int64` for numerical columns like `Rating`, `Vote Sum`, and `Vote Count`, and `datetime64[ms]` for precise date tracking. This combination ensures both efficiency and accuracy in data handling.\n",
    "\n",
    "- **Duplicate Review IDs**: There are 117 duplicate `ID` values, indicating potential duplicate reviews. This suggests the need for a deduplication process to ensure data integrity and prevent biases in analysis due to repeated entries.\n",
    "\n",
    "- **Categorical Insights**: The dataset features 14 unique `Category` values, reflecting the breadth of application categories, and 5 unique `Rating` values, consistent with a standard 5-point rating scale. These are critical for categorical analyses and aggregating review sentiment.\n",
    "\n",
    "- **Duplicate Content**: The `Content` column shows high uniqueness overall but also includes significant duplicate entries. This could indicate commonly used phrases or templated responses in short reviews, which may require special handling during text analysis to differentiate between genuine user feedback and repetitive content.\n",
    "\n",
    "- **High Uniqueness in Key Columns**: Columns like `ID`, `Content`, and `Date` demonstrate high uniqueness, essential for detailed individual review analysis and time-series studies.\n",
    "\n",
    "- **Memory Efficiency**: Despite the large volume, efficient use of data types—particularly categorical and numerical fields—helps manage the dataset's memory footprint. The `Content` field, being text-heavy, dominates memory usage but is critical for in-depth textual analysis.\n",
    "\n",
    "Overall, the dataset is ready for a more robust quality analysis, with attention to duplication, relevance, validity, and privacy concerns. \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AppVoCAI Dataset Summary\n",
    "Here, we summarize the dataset contents in terms of reviews, apps, reviewer engagement, influence, app, and categorical breadth."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "                            AppVoCAI Dataset Summary                            \n",
      "                             Data Preparation Phase                             \n",
      "                            Data Preprocessing Stage                            \n",
      "                       Number of Reviews | 86,705\n",
      "                     Number of Reviewers | 86,444\n",
      "              Number of Repeat Reviewers | 251 (0.3%)\n",
      "         Number of Influential Reviewers | 5,549 (6.4%)\n",
      "                          Number of Apps | 9,715\n",
      "                 Average Reviews per App | 8.9\n",
      "                    Number of Categories | 14\n",
      "                                Features | 11\n",
      "                       Min Review Length | 1\n",
      "                       Max Review Length | 1016\n",
      "                   Average Review Length | 31.93\n",
      "                        Memory Size (Mb) | 67.19\n",
      "                    Date of First Review | 2020-01-01 00:23:01\n",
      "                     Date of Last Review | 2023-09-03 00:48:59\n"
     ]
    }
   ],
   "source": [
    "dataset.summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Key Observations\n",
    "\n",
    "- **Volume and Scale**: The dataset contains a substantial number of reviews (22.17 million) and reviewers (15.71 million), indicating a broad and diverse user engagement across a wide range of applications.\n",
    "\n",
    "- **Repeat Reviewers**: Approximately 22.9% of reviewers have submitted more than one review, suggesting a significant proportion of engaged users who consistently contribute feedback. This can provide valuable longitudinal insights into user experiences and loyalty.\n",
    "\n",
    "- **Influential Reviewers**: With 6.6% of reviewers deemed influential (based on vote sum and counts), their contributions could play a pivotal role in shaping app perceptions and rankings.\n",
    "\n",
    "- **App Diversity**: The dataset covers 36,377 unique apps across 14 categories, indicating a wide-ranging scope of applications. This diversity is beneficial for conducting category-specific analyses and identifying trends within various app domains.\n",
    "\n",
    "- **Review Distribution**: On average, each app has approximately 609 reviews. This high level of engagement per app supports detailed app-level performance and sentiment analysis.\n",
    "\n",
    "- **Temporal Range**: The dataset spans over 15 years, from July 2008 to September 2023. This extensive timeframe allows for robust historical analysis, capturing the evolution of user feedback and app development trends over time.\n",
    "\n",
    "- **Memory Usage**: The dataset's size is significant, with a memory footprint of approximately 14.51 GB. This underscores the need for efficient data handling and processing strategies, particularly for large-scale analyses.\n",
    "\n",
    "- **Feature Richness**: With 11 distinct app, reviewer, and review features, the dataset enables both qualitative (review) and quantitative (rating, review_count, vote metrics) analysis of app performance and user sentiment.\n",
    "\n",
    "---\n",
    "\n",
    "### Observations\n",
    "This initial data profiling reveals a substantial and diverse dataset with significant potential for evaluating the performance of LLMs and SLMs, particularly in the context of fine-tuning foundation models. Transformer models require large volumes of data, and the volume of reviews, the extensive 15 year temporal span, and categorical coverage provide a solid foundation for LLM model training and evaluation. Yet, the data quality analysis to follow will evince dataset validity, relevance, completeness, and uniqueness, providing a more nuanced understanding of its suitability for training and evaluating LLMs and SLMs for specific tasks, such as Aspect-Based Sentiment Analysis (ABSA)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "genai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
