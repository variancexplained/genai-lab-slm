{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": [
     "remove-cell"
    ]
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import os\n",
    "\n",
    "if \"jbook\" in os.getcwd():\n",
    "    os.chdir(os.path.abspath(os.path.join(\"../..\")))\n",
    "FORCE = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Quality Analysis (TQA) for Aspect-Based Sentiment Analysis (ABSA)\n",
    "---\n",
    "In **Aspect-Based Sentiment Analysis (ABSA)**, the primary goal is to extract sentiment for specific aspects within a text, such as products, services, or features. To ensure accurate sentiment extraction, the text must be of sufficient quality. Text quality directly influences the effectiveness of ABSA models, and assessing text quality is crucial to improve aspect-level sentiment predictions.\n",
    "\n",
    "The **Text Quality Analysis (TQA)** process evaluates various features of the text that may affect ABSA performance. It focuses on syntactic and lexical features that help determine the relevance, richness, and clarity of the content in relation to specific aspects.\n",
    "\n",
    "Key **requirements for ABSA-based text quality** are:\n",
    "\n",
    "- **Aspect Identification**: Clear identification of aspects (e.g., product features or services).\n",
    "- **Aspect-Verb Pairing**: The relationship between aspects and verbs (actions related to aspects).\n",
    "- **Text Coherence and Complexity**: Well-formed sentences with a manageable level of complexity.\n",
    "- **Lexical Density and Content Richness**: The degree to which the content reflects substantive, content-rich words.\n",
    "\n",
    "These requirements are captured by **syntactic measures** like noun phrases, verb phrases, aspect-verb pairs, and additional features like review length, lexical density, and dependency depth. Together, these features inform the quality of text in the context of ABSA tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Measures of Text Quality and Their Weights\n",
    "---\n",
    "The following **syntactic features** and their **weights** quantify the quality of a given text for ABSA. Each measure contributes to the overall **Text Quality Analysis (TQA)** score, which is a weighted sum of these features.\n",
    "\n",
    "$$\n",
    "\\text{TQA Score}=\\sum_{i} \\left( \\text{Measure Score}_i \\times \\text{Weight}_i \\right)\n",
    "$$\n",
    "\n",
    "Here’s the run-through of each measure, its weight, and its impact on the overall TQA score:\n",
    "\n",
    "### High Importance (Coefficients 3.0 and above):    \n",
    "- **aspect_verb_pairs (4.0)**: These pairs directly link an aspect (noun or noun phrase) with an action or state (verb) related to that aspect. This is highly informative for understanding how users feel about specific aspects. \"The battery drains quickly\" clearly links \"battery\" (aspect) with a negative sentiment via \"drains quickly\" (verb phrase).\n",
    "- **noun_adjective_pairs (3.0)**: As discussed, these pairs are strong indicators of sentiment towards an aspect. \"Excellent screen\" directly expresses positive sentiment towards \"screen.\" While slightly less direct than aspect-verb pairs, they are still highly valuable.\n",
    "\n",
    "### Medium Importance (Coefficients between 1.5 and 2.5):    \n",
    "- **noun_phrases (2.5)**: Noun phrases often represent aspects themselves, even without an accompanying adjective or verb. \"The camera quality\" is a clear aspect, even if the sentiment is expressed elsewhere in the sentence.\n",
    "- **verb_phrases (2.0)**: Verb phrases can provide context and nuance to the sentiment. \"The phone performs well\" is more informative than just \"phone\" or \"performs.\"\n",
    "- **adjective_count (1.5)**: The sheer number of adjectives can give a general indication of the sentiment's intensity. A review with many positive adjectives is likely more positive overall. However, individual adjectives within noun-adjective pairs are more informative.\n",
    "- **lexical_density (1.5)**: Lexical density (the proportion of content words) can be a proxy for the information content of a review. Higher lexical density might suggest more specific and detailed feedback, which could be useful for ABSA.\n",
    "\n",
    "### Lower Importance (Coefficients below 1.5):   \n",
    "- **adverb_count (0.75)**: Adverbs can modify adjectives or verbs, adding nuance. However, their contribution to ABSA might be less direct compared to adjectives or verbs themselves.\n",
    "- **noun_count (1.0)**: The raw count of nouns is less informative than noun phrases or nouns in noun-adjective pairs. It's more of a general indicator of review length and complexity.\n",
    "- **verb_count (1.0)**: Similar to noun count, the raw count of verbs is less directly related to ABSA than verb phrases or verbs in aspect-verb pairs.\n",
    "- **adverbial_phrases (0.5)**: Similar to adverbs, adverbial phrases can add detail but are less directly related to aspect-based sentiment.\n",
    "- **review_length (1.0)**: Review length is a general metric and doesn't directly contribute to ABSA. Longer reviews might contain more information, but they can also be rambling.\n",
    "- **dependency_depth (1.0)**: Dependency depth can be a measure of syntactic complexity, but its relationship to ABSA is not as clear. Complex sentences aren't necessarily more or less sentiment-bearing than simpler ones.\n",
    "\n",
    "**Summary of Weights:**\n",
    "\n",
    "| Measure              | Weight |\n",
    "|----------------------|--------|\n",
    "| aspect_verb_pairs    | 4      |\n",
    "| noun_adjective_pairs | 3      |\n",
    "| noun_phrases         | 2.5    |\n",
    "| verb_phrases         | 2      |\n",
    "| adjective_count      | 1.5    |\n",
    "| lexical_density      | 1.5    |\n",
    "| noun_count           | 1      |\n",
    "| verb_count           | 1      |\n",
    "| review_length        | 1      |\n",
    "| dependency_depth     | 1      |\n",
    "| adverb_count         | 0.75   |\n",
    "| adverbial_phrases    | 0.5    |\n",
    "\n",
    "**Important Note:** These weights are a starting hypothesis. The TQA Exploratory Data Analysis will evaluate the degree to which this weighting regime reflects the quality of reviews for the ABSA task.\n",
    "\n",
    "## Text Quality Analysis Pipeline\n",
    "With that, the text quality analysis (TQA) processing pipeline computes these text quality metrics at scale.\n",
    "\n",
    "The pipeline leverages:     \n",
    "- Dask for distributed data processing, enabling efficient computation over large text datasets.\n",
    "- spaCy for NLP tasks, including dependency parsing and part-of-speech (POS) tagging.\n",
    "\n",
    "The pipeline follows these steps:    \n",
    "- Dataset Configuration: Define the source and target dataset configurations.\n",
    "- Pipeline Construction: Instantiate the TQAStageBuilder and configure it for Dask processing.\n",
    "- Execution: Run the TQAStage, applying text analysis and feature extraction.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "hide-cell"
    ]
   },
   "source": [
    "### Import Libraries\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": [
     "hide-cell"
    ]
   },
   "outputs": [],
   "source": [
    "\n",
    "from genailab.setup import auto_wire_container\n",
    "from genailab.core.dtypes import DFType\n",
    "from genailab.infra.utils.file.fileset import FileFormat\n",
    "from genailab.asset.dataset.config import DatasetConfig\n",
    "from genailab.flow.dataprep.tqa.builder import TQAStageBuilder\n",
    "from genailab.asset.dataset.config import DatasetConfig\n",
    "from genailab.core.flow import PhaseDef, StageDef\n",
    "\n",
    "\n",
    "# Wire container\n",
    "container = auto_wire_container()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the Source and Target Dataset Configurations\n",
    "---\n",
    "The source dataset represents the cleaned text data, while the target dataset will store the extracted text quality features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Source Dataset Configuration\n",
    "source_config = DatasetConfig(\n",
    "    phase=PhaseDef.DATAPREP,\n",
    "    stage=StageDef.CLEAN,\n",
    "    name=\"review\",\n",
    "    file_format=FileFormat.PARQUET,\n",
    "    asset_type=\"dataset\",\n",
    "    dftype=DFType.PANDAS,\n",
    ")\n",
    "\n",
    "# Target Dataset Configuration\n",
    "target_config = DatasetConfig(\n",
    "    phase=PhaseDef.DATAPREP,\n",
    "    stage=StageDef.TQA,\n",
    "    name=\"review\",\n",
    "    file_format=FileFormat.PARQUET,\n",
    "    asset_type=\"dataset\",\n",
    "    dftype=DFType.PANDAS,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Construct the TQA Pipeline\n",
    "---\n",
    "We use the TQAStageBuilder to configure a Dask-powered text quality analysis pipeline with:\n",
    "\n",
    "- Normalization enabled (ensures robust feature scaling).\n",
    "- Batch processing (improves efficiency for large datasets)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "stage = (\n",
    "    TQAStageBuilder()\n",
    "        .analyze_text()\n",
    "        .build(source_config=source_config, target_config=target_config))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run the Pipeline\n",
    "---\n",
    "Once the pipeline is built, we execute it to compute text quality features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "# ============================================================================== #\n",
      "#             Text Quality Analysis Stage Sun, 09 Feb 2025 00:28:11              #\n",
      "# ============================================================================== #\n",
      "\n",
      "____________________________________________________________________________________________________\n",
      "Text Quality Analysis Stage             00:28:11    00:29:51    1.0 minute and 40.04 seconds                       \n",
      "\n",
      "\n",
      "# ============================================================================ #\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dataset = stage.run(force=FORCE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validate the Dataset\n",
    "---\n",
    "Let's ensure that the text quality measures have been added and the dataset is in the repository."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dataset Profile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Column</th>\n",
       "      <th>DataType</th>\n",
       "      <th>Complete</th>\n",
       "      <th>Null</th>\n",
       "      <th>Completeness</th>\n",
       "      <th>Unique</th>\n",
       "      <th>Duplicate</th>\n",
       "      <th>Uniqueness</th>\n",
       "      <th>Size (Bytes)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>id</td>\n",
       "      <td>object</td>\n",
       "      <td>4939</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4939</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>331387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>app_id</td>\n",
       "      <td>object</td>\n",
       "      <td>4939</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1930</td>\n",
       "      <td>3009</td>\n",
       "      <td>0.390767</td>\n",
       "      <td>328454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>app_name</td>\n",
       "      <td>object</td>\n",
       "      <td>4939</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1930</td>\n",
       "      <td>3009</td>\n",
       "      <td>0.390767</td>\n",
       "      <td>394959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>category_id</td>\n",
       "      <td>object</td>\n",
       "      <td>4939</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>14</td>\n",
       "      <td>4925</td>\n",
       "      <td>0.002835</td>\n",
       "      <td>301279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>author</td>\n",
       "      <td>object</td>\n",
       "      <td>4939</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4937</td>\n",
       "      <td>2</td>\n",
       "      <td>0.999595</td>\n",
       "      <td>380303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>rating</td>\n",
       "      <td>object</td>\n",
       "      <td>4939</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5</td>\n",
       "      <td>4934</td>\n",
       "      <td>0.001012</td>\n",
       "      <td>177804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>content</td>\n",
       "      <td>object</td>\n",
       "      <td>4939</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4936</td>\n",
       "      <td>3</td>\n",
       "      <td>0.999393</td>\n",
       "      <td>1237730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>vote_sum</td>\n",
       "      <td>object</td>\n",
       "      <td>4939</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>14</td>\n",
       "      <td>4925</td>\n",
       "      <td>0.002835</td>\n",
       "      <td>159020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>vote_count</td>\n",
       "      <td>object</td>\n",
       "      <td>4939</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>18</td>\n",
       "      <td>4921</td>\n",
       "      <td>0.003644</td>\n",
       "      <td>159272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>date</td>\n",
       "      <td>datetime64[ns]</td>\n",
       "      <td>4939</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4939</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>39512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>category</td>\n",
       "      <td>object</td>\n",
       "      <td>4939</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>14</td>\n",
       "      <td>4925</td>\n",
       "      <td>0.002835</td>\n",
       "      <td>338139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>noun_count</td>\n",
       "      <td>object</td>\n",
       "      <td>4939</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>211</td>\n",
       "      <td>4728</td>\n",
       "      <td>0.042721</td>\n",
       "      <td>158048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>verb_count</td>\n",
       "      <td>object</td>\n",
       "      <td>4939</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>15</td>\n",
       "      <td>4924</td>\n",
       "      <td>0.003037</td>\n",
       "      <td>158048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>adjective_count</td>\n",
       "      <td>object</td>\n",
       "      <td>4939</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>4938</td>\n",
       "      <td>0.000202</td>\n",
       "      <td>158048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>adverb_count</td>\n",
       "      <td>object</td>\n",
       "      <td>4939</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>4938</td>\n",
       "      <td>0.000202</td>\n",
       "      <td>158048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>aspect_verb_pairs</td>\n",
       "      <td>object</td>\n",
       "      <td>4939</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "      <td>4936</td>\n",
       "      <td>0.000607</td>\n",
       "      <td>158048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>noun_adjective_pairs</td>\n",
       "      <td>object</td>\n",
       "      <td>4939</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>4938</td>\n",
       "      <td>0.000202</td>\n",
       "      <td>158048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>noun_phrases</td>\n",
       "      <td>object</td>\n",
       "      <td>4939</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>4937</td>\n",
       "      <td>0.000405</td>\n",
       "      <td>158048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>verb_phrases</td>\n",
       "      <td>object</td>\n",
       "      <td>4939</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>4937</td>\n",
       "      <td>0.000405</td>\n",
       "      <td>158048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>adverbial_phrases</td>\n",
       "      <td>object</td>\n",
       "      <td>4939</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>4938</td>\n",
       "      <td>0.000202</td>\n",
       "      <td>158048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>review_length</td>\n",
       "      <td>object</td>\n",
       "      <td>4939</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>222</td>\n",
       "      <td>4717</td>\n",
       "      <td>0.044948</td>\n",
       "      <td>158048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>lexical_density</td>\n",
       "      <td>object</td>\n",
       "      <td>4939</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>4938</td>\n",
       "      <td>0.000202</td>\n",
       "      <td>158048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>dependency_depth</td>\n",
       "      <td>object</td>\n",
       "      <td>4939</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>222</td>\n",
       "      <td>4717</td>\n",
       "      <td>0.044948</td>\n",
       "      <td>158048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>tqa_score</td>\n",
       "      <td>object</td>\n",
       "      <td>4939</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1172</td>\n",
       "      <td>3767</td>\n",
       "      <td>0.237295</td>\n",
       "      <td>158048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>tqa_rating</td>\n",
       "      <td>object</td>\n",
       "      <td>4939</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5</td>\n",
       "      <td>4934</td>\n",
       "      <td>0.001012</td>\n",
       "      <td>177804</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Column        DataType  Complete  Null  Completeness  \\\n",
       "0                     id          object      4939     0           1.0   \n",
       "1                 app_id          object      4939     0           1.0   \n",
       "2               app_name          object      4939     0           1.0   \n",
       "3            category_id          object      4939     0           1.0   \n",
       "4                 author          object      4939     0           1.0   \n",
       "5                 rating          object      4939     0           1.0   \n",
       "6                content          object      4939     0           1.0   \n",
       "7               vote_sum          object      4939     0           1.0   \n",
       "8             vote_count          object      4939     0           1.0   \n",
       "9                   date  datetime64[ns]      4939     0           1.0   \n",
       "10              category          object      4939     0           1.0   \n",
       "11            noun_count          object      4939     0           1.0   \n",
       "12            verb_count          object      4939     0           1.0   \n",
       "13       adjective_count          object      4939     0           1.0   \n",
       "14          adverb_count          object      4939     0           1.0   \n",
       "15     aspect_verb_pairs          object      4939     0           1.0   \n",
       "16  noun_adjective_pairs          object      4939     0           1.0   \n",
       "17          noun_phrases          object      4939     0           1.0   \n",
       "18          verb_phrases          object      4939     0           1.0   \n",
       "19     adverbial_phrases          object      4939     0           1.0   \n",
       "20         review_length          object      4939     0           1.0   \n",
       "21       lexical_density          object      4939     0           1.0   \n",
       "22      dependency_depth          object      4939     0           1.0   \n",
       "23             tqa_score          object      4939     0           1.0   \n",
       "24            tqa_rating          object      4939     0           1.0   \n",
       "\n",
       "    Unique  Duplicate  Uniqueness  Size (Bytes)  \n",
       "0     4939          0    1.000000        331387  \n",
       "1     1930       3009    0.390767        328454  \n",
       "2     1930       3009    0.390767        394959  \n",
       "3       14       4925    0.002835        301279  \n",
       "4     4937          2    0.999595        380303  \n",
       "5        5       4934    0.001012        177804  \n",
       "6     4936          3    0.999393       1237730  \n",
       "7       14       4925    0.002835        159020  \n",
       "8       18       4921    0.003644        159272  \n",
       "9     4939          0    1.000000         39512  \n",
       "10      14       4925    0.002835        338139  \n",
       "11     211       4728    0.042721        158048  \n",
       "12      15       4924    0.003037        158048  \n",
       "13       1       4938    0.000202        158048  \n",
       "14       1       4938    0.000202        158048  \n",
       "15       3       4936    0.000607        158048  \n",
       "16       1       4938    0.000202        158048  \n",
       "17       2       4937    0.000405        158048  \n",
       "18       2       4937    0.000405        158048  \n",
       "19       1       4938    0.000202        158048  \n",
       "20     222       4717    0.044948        158048  \n",
       "21       1       4938    0.000202        158048  \n",
       "22     222       4717    0.044948        158048  \n",
       "23    1172       3767    0.237295        158048  \n",
       "24       5       4934    0.001012        177804  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.profile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dataset Sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>app_id</th>\n",
       "      <th>app_name</th>\n",
       "      <th>category_id</th>\n",
       "      <th>author</th>\n",
       "      <th>rating</th>\n",
       "      <th>content</th>\n",
       "      <th>vote_sum</th>\n",
       "      <th>vote_count</th>\n",
       "      <th>date</th>\n",
       "      <th>...</th>\n",
       "      <th>aspect_verb_pairs</th>\n",
       "      <th>noun_adjective_pairs</th>\n",
       "      <th>noun_phrases</th>\n",
       "      <th>verb_phrases</th>\n",
       "      <th>adverbial_phrases</th>\n",
       "      <th>review_length</th>\n",
       "      <th>lexical_density</th>\n",
       "      <th>dependency_depth</th>\n",
       "      <th>tqa_score</th>\n",
       "      <th>tqa_rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10019409512</td>\n",
       "      <td>1380362212</td>\n",
       "      <td>GALATEA: Novels &amp; Audiobooks</td>\n",
       "      <td>6018</td>\n",
       "      <td>c011c66aae3e668b150e</td>\n",
       "      <td>5</td>\n",
       "      <td>i love it but the chapter and waiting hours fo...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2023-06-10 15:09:00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.70805</td>\n",
       "      <td>4.615121</td>\n",
       "      <td>2.70805</td>\n",
       "      <td>16.779699</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10027124164</td>\n",
       "      <td>1380362212</td>\n",
       "      <td>GALATEA: Novels &amp; Audiobooks</td>\n",
       "      <td>6018</td>\n",
       "      <td>5a2741393dd20358b609</td>\n",
       "      <td>5</td>\n",
       "      <td>i like the books that i have read so far if th...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2023-06-12 20:14:00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.931826</td>\n",
       "      <td>4.615121</td>\n",
       "      <td>3.931826</td>\n",
       "      <td>21.776695</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10036938913</td>\n",
       "      <td>1076402606</td>\n",
       "      <td>Libby, by OverDrive</td>\n",
       "      <td>6018</td>\n",
       "      <td>46117640263dddac9294</td>\n",
       "      <td>5</td>\n",
       "      <td>i have read dozens upon dozens of books after ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2023-06-15 17:01:00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.850148</td>\n",
       "      <td>4.615121</td>\n",
       "      <td>3.850148</td>\n",
       "      <td>23.259196</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10047764706</td>\n",
       "      <td>1076402606</td>\n",
       "      <td>Libby, by OverDrive</td>\n",
       "      <td>6018</td>\n",
       "      <td>a0e95f8868233439444d</td>\n",
       "      <td>5</td>\n",
       "      <td>happy with the app i use it primarily for audi...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2023-06-18 19:40:00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.583519</td>\n",
       "      <td>4.615121</td>\n",
       "      <td>3.583519</td>\n",
       "      <td>20.447559</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10064456025</td>\n",
       "      <td>1535748732</td>\n",
       "      <td>Storyroom - Webnovel &amp; Story</td>\n",
       "      <td>6018</td>\n",
       "      <td>bb43c451a876165c2abf</td>\n",
       "      <td>1</td>\n",
       "      <td>im going to be honest the books are really gre...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2023-06-23 15:23:00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.477337</td>\n",
       "      <td>4.615121</td>\n",
       "      <td>4.477337</td>\n",
       "      <td>23.163182</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            id      app_id                      app_name category_id  \\\n",
       "0  10019409512  1380362212  GALATEA: Novels & Audiobooks        6018   \n",
       "1  10027124164  1380362212  GALATEA: Novels & Audiobooks        6018   \n",
       "2  10036938913  1076402606           Libby, by OverDrive        6018   \n",
       "3  10047764706  1076402606           Libby, by OverDrive        6018   \n",
       "4  10064456025  1535748732  Storyroom - Webnovel & Story        6018   \n",
       "\n",
       "                 author rating  \\\n",
       "0  c011c66aae3e668b150e      5   \n",
       "1  5a2741393dd20358b609      5   \n",
       "2  46117640263dddac9294      5   \n",
       "3  a0e95f8868233439444d      5   \n",
       "4  bb43c451a876165c2abf      1   \n",
       "\n",
       "                                             content vote_sum vote_count  \\\n",
       "0  i love it but the chapter and waiting hours fo...        0          0   \n",
       "1  i like the books that i have read so far if th...        0          0   \n",
       "2  i have read dozens upon dozens of books after ...        0          0   \n",
       "3  happy with the app i use it primarily for audi...        0          0   \n",
       "4  im going to be honest the books are really gre...        0          0   \n",
       "\n",
       "                 date  ... aspect_verb_pairs noun_adjective_pairs  \\\n",
       "0 2023-06-10 15:09:00  ...               0.0                  0.0   \n",
       "1 2023-06-12 20:14:00  ...               0.0                  0.0   \n",
       "2 2023-06-15 17:01:00  ...          0.693147                  0.0   \n",
       "3 2023-06-18 19:40:00  ...               0.0                  0.0   \n",
       "4 2023-06-23 15:23:00  ...               0.0                  0.0   \n",
       "\n",
       "  noun_phrases verb_phrases adverbial_phrases review_length lexical_density  \\\n",
       "0     0.693147          0.0               0.0       2.70805        4.615121   \n",
       "1     0.693147          0.0               0.0      3.931826        4.615121   \n",
       "2          0.0     0.693147               0.0      3.850148        4.615121   \n",
       "3     0.693147          0.0               0.0      3.583519        4.615121   \n",
       "4     0.693147          0.0               0.0      4.477337        4.615121   \n",
       "\n",
       "  dependency_depth  tqa_score tqa_rating  \n",
       "0          2.70805  16.779699          2  \n",
       "1         3.931826  21.776695          4  \n",
       "2         3.850148  23.259196          5  \n",
       "3         3.583519  20.447559          4  \n",
       "4         4.477337  23.163182          5  \n",
       "\n",
       "[5 rows x 25 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.dataframe.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dataset Repository"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "repo = container.io.repo()\n",
    "ds = repo.get(asset_id=dataset.asset_id)\n",
    "assert ds == dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great! Now that we've confirmed the dataset has been successfully processed, we have a set of **text quality analysis** metrics that we can use for instance selection during the feature engineering stage.\n",
    "Next, we transition to **sentiment analysis at the review level**. In this phase, we will analyze the overall **sentiment** of each review."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "genai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
