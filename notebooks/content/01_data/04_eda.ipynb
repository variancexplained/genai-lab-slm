{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": [
     "remove-cell"
    ]
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "if \"jbook\" in os.getcwd():\n",
    "    os.chdir(os.path.abspath(os.path.join(\"../..\")))\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "FORCE = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploring the AppVoCAI Dataset\n",
    "\n",
    "### Market Landscape and Positioning\n",
    "1. **Market Size and Trends**: \n",
    "   - What is the size and growth rate of the app market by category?\n",
    "   - Are there emerging categories showing significant growth or decline?\n",
    "   - How do download and usage trends differ across categories?\n",
    "\n",
    "2. **Competitive Landscape**: \n",
    "   - Who are the top competitors in each category, and what are their strengths?\n",
    "   - How does user sentiment toward competing apps compare across categories?\n",
    "   - What unique features or aspects are highly rated or disliked across top-performing apps?\n",
    "\n",
    "3. **Product-Market Fit and Differentiation**:\n",
    "   - What unmet needs or pain points do users consistently mention?\n",
    "   - What unique value propositions stand out among top apps, and how well are they aligned with user needs?\n",
    "   - Are there gaps in the market (e.g., underserved user segments or feature needs)?\n",
    "\n",
    "### Economic Factors and Monetization\n",
    "4. **Revenue Potential**:\n",
    "   - What monetization strategies (e.g., freemium, ads, in-app purchases) are most effective in each category?\n",
    "   - What revenue models align best with user expectations and app engagement patterns?\n",
    "   - How does user sentiment differ between free and paid versions of similar apps?\n",
    "\n",
    "5. **User Acquisition Cost and Lifetime Value**:\n",
    "   - What is the acquisition cost across different channels, and how does it impact profitability?\n",
    "   - How does user lifetime value (LTV) vary by category and monetization strategy?\n",
    "   - Are there identifiable patterns in reviews that could suggest high churn rates or low LTV?\n",
    "\n",
    "6. **App Retention and Engagement**:\n",
    "   - What factors (e.g., UI/UX, features, reliability) are most correlated with high retention and engagement?\n",
    "   - How does engagement evolve over time (e.g., early adoption vs. long-term loyalty)?\n",
    "   - Are there common points of user dissatisfaction that could indicate barriers to retention?\n",
    "\n",
    "### Customer Insights and Marketing Strategies\n",
    "7. **Audience Segmentation**:\n",
    "   - Who are the primary user demographics (e.g., age, geography, preferences), and how do they differ by app category?\n",
    "   - What feedback patterns emerge from different user segments, especially power users vs. casual users?\n",
    "   - Are there particular segments more likely to engage with or advocate for the app?\n",
    "\n",
    "8. **Brand Loyalty and Advocacy**:\n",
    "   - How many users actively promote the app (e.g., high ratings, positive reviews)?\n",
    "   - What features or experiences inspire brand loyalty, and what triggers dissatisfaction or churn?\n",
    "   - Are there specific brand associations (e.g., innovation, reliability) that influence user perceptions?\n",
    "\n",
    "9. **Growth Opportunities and Market Entry**:\n",
    "   - Are there high-potential markets (geographic or demographic) that are currently underserved?\n",
    "   - What feature requests or trends suggest opportunities for innovation?\n",
    "   - How does timing impact the success of similar apps (e.g., entry into emerging markets)?\n",
    "\n",
    "10. **Product Messaging and Positioning**:\n",
    "    - How do users perceive the app’s brand, and how does this compare to competitors?\n",
    "    - What messaging resonates most with different segments, based on sentiment analysis?\n",
    "    - Are there specific keywords or phrases that correlate with positive or negative perceptions?\n",
    "\n",
    "This approach helps build a comprehensive picture of the market, user expectations, competitive landscape, and economic drivers. By aligning these insights with strategic goals, decision-makers can make informed choices about market positioning, growth opportunities, and user engagement tactics.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-cell"
    ]
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from discover.app.analyzer import Analyzer\n",
    "from discover.assets.idgen import AssetIDGen\n",
    "from discover.container import DiscoverContainer\n",
    "from discover.core.flow import EnrichmentStageDef, PhaseDef\n",
    "from discover.infra.utils.visual.print import Printer\n",
    "\n",
    "pd.options.display.max_rows = 999"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": [
     "remove-cell"
    ]
   },
   "outputs": [],
   "source": [
    "container = DiscoverContainer()\n",
    "container.init_resources()\n",
    "container.wire(\n",
    "    modules=[\n",
    "        \"discover.flow.data_prep.stage\",\n",
    "        \"discover.app.base\",\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['id', 'app_id', 'app_name', 'category_id', 'author', 'rating', 'content', 'vote_sum', 'vote_count', 'date', 'enrichment_meta_review_age', 'enrichment_meta_review_length', 'enrichment_sentiment', 'enrichment_tqa_score1', 'enrichment_tqa_score2', 'enrichment_tqa_score_final', 'enrichment_pct_deviation_rating', 'enrichment_pct_deviation_review_length', 'enrichment_pct_deviation_sentiment', 'enrichment_pct_deviation_tqa_score_final', 'category']\n"
     ]
    }
   ],
   "source": [
    "idg = AssetIDGen()\n",
    "asset_id = idg.get_asset_id(\n",
    "    asset_type=\"dataset\",\n",
    "    phase=PhaseDef.ENRICHMENT,\n",
    "    stage=EnrichmentStageDef.DEVIATION,\n",
    "    name=\"review\",\n",
    ")\n",
    "\n",
    "# Instantiate the repository\n",
    "repo = container.repo.dataset_repo()\n",
    "# Load the dataset from the repository\n",
    "df = repo.get(asset_id, distributed=False).content\n",
    "# Select columns\n",
    "columns = [\n",
    "    col for col in df.columns if not col.startswith((\"stats\", \"pos\", \"tqf\", \"tqm\"))\n",
    "]\n",
    "df = df[columns]\n",
    "# Instantiate the Review object for analysis.\n",
    "analyzer = Analyzer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AppVoCAI Dataset Overview\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": [
     "hide-cell"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Column</th>\n",
       "      <th>DataType</th>\n",
       "      <th>Complete</th>\n",
       "      <th>Null</th>\n",
       "      <th>Completeness</th>\n",
       "      <th>Unique</th>\n",
       "      <th>Duplicate</th>\n",
       "      <th>Uniqueness</th>\n",
       "      <th>Size (Bytes)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>id</td>\n",
       "      <td>object</td>\n",
       "      <td>81594</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>81594</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>5472144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>app_id</td>\n",
       "      <td>object</td>\n",
       "      <td>81594</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8944</td>\n",
       "      <td>72650</td>\n",
       "      <td>0.109616</td>\n",
       "      <td>5423467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>app_name</td>\n",
       "      <td>object</td>\n",
       "      <td>81594</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8940</td>\n",
       "      <td>72654</td>\n",
       "      <td>0.109567</td>\n",
       "      <td>6609661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>category_id</td>\n",
       "      <td>object</td>\n",
       "      <td>81594</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>14</td>\n",
       "      <td>81580</td>\n",
       "      <td>0.000172</td>\n",
       "      <td>4977234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>author</td>\n",
       "      <td>object</td>\n",
       "      <td>81594</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>81399</td>\n",
       "      <td>195</td>\n",
       "      <td>0.997610</td>\n",
       "      <td>6282738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>rating</td>\n",
       "      <td>int16</td>\n",
       "      <td>81594</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5</td>\n",
       "      <td>81589</td>\n",
       "      <td>0.000061</td>\n",
       "      <td>163188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>content</td>\n",
       "      <td>object</td>\n",
       "      <td>81594</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>76737</td>\n",
       "      <td>4857</td>\n",
       "      <td>0.940474</td>\n",
       "      <td>18655099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>vote_sum</td>\n",
       "      <td>int64</td>\n",
       "      <td>81594</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>59</td>\n",
       "      <td>81535</td>\n",
       "      <td>0.000723</td>\n",
       "      <td>652752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>vote_count</td>\n",
       "      <td>int64</td>\n",
       "      <td>81594</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>73</td>\n",
       "      <td>81521</td>\n",
       "      <td>0.000895</td>\n",
       "      <td>652752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>date</td>\n",
       "      <td>datetime64[us]</td>\n",
       "      <td>81594</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>81533</td>\n",
       "      <td>61</td>\n",
       "      <td>0.999252</td>\n",
       "      <td>652752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>enrichment_meta_review_age</td>\n",
       "      <td>int32</td>\n",
       "      <td>81594</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1342</td>\n",
       "      <td>80252</td>\n",
       "      <td>0.016447</td>\n",
       "      <td>326376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>enrichment_meta_review_length</td>\n",
       "      <td>int32</td>\n",
       "      <td>81594</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>425</td>\n",
       "      <td>81169</td>\n",
       "      <td>0.005209</td>\n",
       "      <td>326376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>enrichment_sentiment</td>\n",
       "      <td>float64</td>\n",
       "      <td>81594</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>81593</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>652752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>enrichment_tqa_score1</td>\n",
       "      <td>float64</td>\n",
       "      <td>81594</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>69588</td>\n",
       "      <td>12006</td>\n",
       "      <td>0.852857</td>\n",
       "      <td>652752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>enrichment_tqa_score2</td>\n",
       "      <td>float64</td>\n",
       "      <td>81594</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>257</td>\n",
       "      <td>81337</td>\n",
       "      <td>0.003150</td>\n",
       "      <td>652752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>enrichment_tqa_score_final</td>\n",
       "      <td>float64</td>\n",
       "      <td>81594</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>71948</td>\n",
       "      <td>9646</td>\n",
       "      <td>0.881781</td>\n",
       "      <td>652752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>enrichment_pct_deviation_rating</td>\n",
       "      <td>float64</td>\n",
       "      <td>81594</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5</td>\n",
       "      <td>81589</td>\n",
       "      <td>0.000061</td>\n",
       "      <td>652752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>enrichment_pct_deviation_review_length</td>\n",
       "      <td>float64</td>\n",
       "      <td>81594</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>425</td>\n",
       "      <td>81169</td>\n",
       "      <td>0.005209</td>\n",
       "      <td>652752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>enrichment_pct_deviation_sentiment</td>\n",
       "      <td>float64</td>\n",
       "      <td>0</td>\n",
       "      <td>81594</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>81594</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>652752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>enrichment_pct_deviation_tqa_score_final</td>\n",
       "      <td>float64</td>\n",
       "      <td>81594</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>71948</td>\n",
       "      <td>9646</td>\n",
       "      <td>0.881781</td>\n",
       "      <td>652752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>category</td>\n",
       "      <td>category</td>\n",
       "      <td>81594</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>14</td>\n",
       "      <td>81580</td>\n",
       "      <td>0.000172</td>\n",
       "      <td>83093</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      Column        DataType  Complete   Null  \\\n",
       "0                                         id          object     81594      0   \n",
       "1                                     app_id          object     81594      0   \n",
       "2                                   app_name          object     81594      0   \n",
       "3                                category_id          object     81594      0   \n",
       "4                                     author          object     81594      0   \n",
       "5                                     rating           int16     81594      0   \n",
       "6                                    content          object     81594      0   \n",
       "7                                   vote_sum           int64     81594      0   \n",
       "8                                 vote_count           int64     81594      0   \n",
       "9                                       date  datetime64[us]     81594      0   \n",
       "10                enrichment_meta_review_age           int32     81594      0   \n",
       "11             enrichment_meta_review_length           int32     81594      0   \n",
       "12                      enrichment_sentiment         float64     81594      0   \n",
       "13                     enrichment_tqa_score1         float64     81594      0   \n",
       "14                     enrichment_tqa_score2         float64     81594      0   \n",
       "15                enrichment_tqa_score_final         float64     81594      0   \n",
       "16           enrichment_pct_deviation_rating         float64     81594      0   \n",
       "17    enrichment_pct_deviation_review_length         float64     81594      0   \n",
       "18        enrichment_pct_deviation_sentiment         float64         0  81594   \n",
       "19  enrichment_pct_deviation_tqa_score_final         float64     81594      0   \n",
       "20                                  category        category     81594      0   \n",
       "\n",
       "    Completeness  Unique  Duplicate  Uniqueness  Size (Bytes)  \n",
       "0            1.0   81594          0    1.000000       5472144  \n",
       "1            1.0    8944      72650    0.109616       5423467  \n",
       "2            1.0    8940      72654    0.109567       6609661  \n",
       "3            1.0      14      81580    0.000172       4977234  \n",
       "4            1.0   81399        195    0.997610       6282738  \n",
       "5            1.0       5      81589    0.000061        163188  \n",
       "6            1.0   76737       4857    0.940474      18655099  \n",
       "7            1.0      59      81535    0.000723        652752  \n",
       "8            1.0      73      81521    0.000895        652752  \n",
       "9            1.0   81533         61    0.999252        652752  \n",
       "10           1.0    1342      80252    0.016447        326376  \n",
       "11           1.0     425      81169    0.005209        326376  \n",
       "12           1.0       1      81593    0.000012        652752  \n",
       "13           1.0   69588      12006    0.852857        652752  \n",
       "14           1.0     257      81337    0.003150        652752  \n",
       "15           1.0   71948       9646    0.881781        652752  \n",
       "16           1.0       5      81589    0.000061        652752  \n",
       "17           1.0     425      81169    0.005209        652752  \n",
       "18           0.0       0      81594    0.000000        652752  \n",
       "19           1.0   71948       9646    0.881781        652752  \n",
       "20           1.0      14      81580    0.000172         83093  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analyzer.info(df=df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The AppVoCAI captures over 22 million reviews from nearly 16 million users. These reviews span some 36,377 apps across 14 categories., providing a diverse range of insights into user experiences. The dataset contains 12 features and spans from July 10, 2008, the date the appstore launched, through early September of 2023."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rating Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analyzer.distplot(df=df, x=\"rating\", title=\"Rating Distribution Analysis\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The distribution of ratings across the dataset shows a noticeable skew toward higher ratings. While the minimum rating is 1, the majority of the reviews are concentrated around the higher end of the scale—half of the ratings are 5, as reflected in the 50th, 75th, and maximum percentiles, all being 5. This suggests that users are more likely to give positive ratings, though there is still a portion of the dataset with moderate to lower ratings, as indicated by the lower 25th percentile.\n",
    "\n",
    "The KDE and violin plots further emphasize this trend, visually highlighting the density of high ratings and the thinner distribution in the lower range and a concentration of reviews toward the maximum rating."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Review Length Analysis\n",
    "Review length offers key insights into the potential depth and richness of app analyzer. **Longer reviews** often contain more detailed feedback, making them valuable for advanced sentiment and aspect-based analysis, while **shorter reviews** may offer limited but frequent surface-level sentiments. Understanding the distribution of review lengths helps identify patterns in user engagement and guides decisions on data processing—such as handling outliers or segmenting reviews for further analysis. By analyzing review length, we gain a clearer picture of the dataset’s complexity and can better tailor modeling approaches to extract meaningful insights.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analyzer.distplot(\n",
    "    df=df, x=\"eda_review_length\", title=\"Review Length Distribution Analysis\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Several observations are prominent:\n",
    "\n",
    "- **Skewed Distribution**: The large difference between the mean (32.42 words) and the median (20 words) suggests a right-skewed distribution, with a small number of very long reviews pulling up the mean. The maximum review length of 2,624 words reinforces the presence of these outliers.\n",
    "  \n",
    "- **Prevalence of Short Reviews**: The 25th percentile of 8 words and the high concentration of reviews below the 42-word mark (75th percentile) indicate that a significant portion of reviews are very short, possibly affecting their informativeness. These short reviews may not provide detailed insights and could be less valuable for deeper sentiment or aspect analysis.\n",
    "  \n",
    "- **Variation in Review Length**: With a standard deviation of 41.03, there's substantial variability in review lengths. This variability means that different types of analyses, such as summarization or sentiment extraction, may need to account for review length, as longer reviews might contain more nuanced opinions or multiple aspects.\n",
    "\n",
    "The accompanying histogram and violin plots show the concentration of shorter reviews and highlight the long tail of very lengthy reviews, illustrating the spread and density of review lengths."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vote Count and Vote Sum\n",
    "The dataset includes two important metrics for evaluating the interaction with app reviews: **vote count** and **vote sum**.\n",
    "\n",
    "- **Vote Count** reflects the total number of votes a review has received. This primarily measures engagement, indicating how many users interacted with the review. A high vote count shows that the review attracted attention, but it does not necessarily reflect the quality or usefulness of the review.\n",
    "\n",
    "- **Vote Sum** aggregates the net value of all votes, providing a clearer indication of the review’s **informativeness**. A higher vote sum suggests that users found the review helpful or insightful, making it a stronger indicator of the review's contribution to understanding the app’s performance or issues. However, while a high vote sum may imply some level of agreement with the review, this cannot be assumed. Further **sentiment analysis** would be required to determine whether users generally agree with the sentiments expressed in the review.\n",
    "\n",
    "In this context, **vote sum** serves as a valuable metric for identifying reviews that provide meaningful or detailed insights, while **vote count** highlights the level of engagement or visibility.\n",
    "\n",
    "#### Vote Count Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analyzer.distplot(df=df, x=\"vote_count\", title=\"Vote Count Distribution Analysis\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The statistics for **vote count** offer some key insights into how reviews are interacted with by users:\n",
    "\n",
    "- **Heavily Skewed Distribution**: With a median of 0 and a 75th percentile also at 0, the majority of reviews receive no votes at all. This highlights that only a small fraction of reviews are being engaged with by the community. The fact that the mean is 0.155, significantly inflated by the few reviews with a large number of votes, further emphasizes the skewed nature of the distribution.\n",
    "\n",
    "- **High Variability**: The standard deviation of 5.93, combined with a maximum vote count of 5,928, indicates that while most reviews receive little to no interaction, a few outliers receive significant attention. These outliers likely represent highly influential or visible reviews that may play a critical role in shaping user opinions.\n",
    "\n",
    "Let's take a look at the top 10 vote count distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analyzer.freqdist(df=df, x=\"vote_count\", topn=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These additional statistics for **vote count** reinforce the earlier observation of a highly skewed distribution, providing even more clarity on the nature of engagement:\n",
    "\n",
    "- **Overwhelming Majority of Reviews Receive No Votes**: With 94.10% of reviews having 0 votes, it’s clear that most reviews are not engaged with at all. This suggests that user engagement is concentrated on a small subset of reviews, making it important to carefully examine the minority of reviews that do receive votes for their potential influence.\n",
    "\n",
    "- **Sharp Drop-off After 1 Vote**: Only 4.52% of reviews receive 1 vote, and the percentage of reviews receiving 2 or more votes rapidly diminishes. This suggests that even a single vote marks a review as somewhat exceptional in terms of visibility or user engagement.\n",
    "\n",
    "- **Long Tail of Rarely Voted Reviews**: The small percentages for reviews receiving 2 or more votes illustrate the presence of a long tail, with very few reviews accumulating significant votes. This is consistent with the earlier finding of a few highly voted outliers driving the mean up, despite the majority receiving no interaction.\n",
    "\n",
    "- **Implications for Analysis**: Overall, these percentages highlight the fact that engagement is sparse and highly concentrated, which may affect the way vote counts are used as a signal in analysis. Given that a vast majority of reviews have no votes, the vote count metric alone may not be useful in distinguishing most analyzer. Rather, the reviews that do receive votes, especially those with more than 1 or 2 votes, indicate greater visibility, and possibly influence or importance. \n",
    "\n",
    "Another, perhaps better indicator of influence is vote sum."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Vote Sum Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analyzer.distplot(df=df, x=\"vote_sum\", title=\"Vote Sum Distribution Analysis\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analyzer.freqdist(df=df, x=\"vote_sum\", topn=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The **vote sum** statistics and distribution provide further insight into the overall interaction with app reviews:\n",
    "\n",
    "##### Vote Sum Statistics:\n",
    "- **Sparse Engagement**: With a mean of 0.10436 and a standard deviation of 3.55, the vast majority of reviews have little to no cumulative voting activity. The skewed nature of the distribution is again evident, with the 25th, 50th (median), and 75th percentiles all at 0, showing that most reviews receive no meaningful voting interaction.\n",
    "  \n",
    "- **High Variability**: The maximum vote sum of 2,804 illustrates that a small subset of reviews receives significant positive feedback, suggesting that these reviews are particularly informative or impactful. However, such high vote sums are extremely rare.\n",
    "\n",
    "##### Vote Sum Distribution:\n",
    "- **96.17% of Reviews Have No Vote Sum**: The vast majority of reviews do not receive any vote sum, reinforcing the earlier observation that user engagement is concentrated on a very small subset of analyzer. This high percentage of zero vote sums indicates that only a small portion of reviews is seen as helpful or relevant by the community.\n",
    "\n",
    "- **A Small Fraction of Reviews Stand Out**: Only 3.61% of reviews receive a vote sum of 1, with progressively fewer reviews receiving higher vote sums. The rapid decline in percentage for higher vote sums shows that informative reviews (as inferred by their vote sum) are exceedingly rare. \n",
    "\n",
    "- **Implications**: Since vote sum reflects perceived informativeness, the small number of reviews with a non-zero vote sum suggests that only a handful of reviews are considered highly useful by readers. For analysis, this could mean that reviews with high vote sums might be prioritized for deeper insight extraction, while the overwhelming majority of reviews with no votes may be of lower priority or less informative.\n",
    "\n",
    "This sparse engagement, combined with the presence of outliers, suggests that **vote sum** is a valuable but rare indicator of review quality and potential influence."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Review Date Analysis\n",
    "The review date analysis focuses on understanding temporal trends in user feedback. It examines when reviews were submitted to uncover patterns, peaks in user engagement, and potential seasonal trends over time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analyzer.distplot(df=df, y=\"date\", title=\"Review Date Analysis\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The **review date** statistics provide insights into the temporal distribution of app reviews:\n",
    "\n",
    "1. **Time Span**: The reviews cover a period from **January 1, 2021, to September 3, 2023**—spanning nearly three years. This period is recent enough to capture the current landscape while also offering insight into year-over-year changes.\n",
    "\n",
    "2. **Concentration**: The data shows a slight concentration around **2022**, with both the median and mean review dates falling in mid-2022. This suggests an increase in reviews during that time, possibly reflecting app updates, feature releases, or shifts in user engagement during this period.\n",
    "\n",
    "3. **Recency**: The 75th percentile date is **January 25, 2023**, indicating that 25% of reviews were added since 2023. The latest data point is **September 2023**, meaning the dataset is fairly up-to-date, although missing 2024 data. \n",
    "\n",
    "These trends suggest that the majority of the dataset's insights will come from the most recent years, where review activity is highest."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### App Review Frequency Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analyzer.freqdistplot(\n",
    "    df=df, x=\"app_name\", title=\"App Review Frequency Distribution Analysis\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's examine the most reviewed apps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analyzer.freqplot(df=df, y=\"app_name\", topn=20, title=\"Most Frequently Reviewed Apps\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The **app review frequency** statistics provide insights into the distribution of reviews across different apps:\n",
    "\n",
    "- **Highly Skewed Distribution**: The mean of 178 reviews per app is heavily skewed by a small number of apps with extremely high review counts, as indicated by the large standard deviation (2,612 reviews) and a maximum of 381,236 analyzer. This suggests that while a few apps receive a vast number of reviews, the majority have far fewer.\n",
    "\n",
    "- **Highly Popular Apps**: The 75th percentile (41 reviews) shows that only a quarter of the apps receive over 40 analyzer. The chart clearly shows that a small number of apps dominate the review space. YouTube and Bible, with 351,236 and 138,251 reviews respectively, alone account for over 30% of all reviews in the dataset. These apps, along with a few others like MyFitnessPal, Messenger, and Instagram, capture a large portion of user engagement, further emphasizing the skewed distribution of analyzer.\n",
    "\n",
    "- **Most Apps Have Few Reviews**: The 25th percentile is 4 reviews, and the median is just 11, meaning that half of the apps have fewer than 12 analyzer. This implies that many apps in the dataset receive relatively low engagement, while a small subset dominates the review count.\n",
    "  \n",
    "- **Significant Engagement Drop-off**: After the top five apps, the number of reviews per app drops significantly, although the apps in the mid-tier, such as DoorDash, Uper Eats, and Instagram, still have review counts ranging from around 52,000 to 95,000. These apps, while popular, don't reach the same scale of review activity as the top few.\n",
    "\n",
    "- **Long Tail of Reviews**: Despite the presence of some apps with hundreds of thousands of reviews, there’s a steep drop-off in review counts as you move further down the list, indicating that the vast majority of apps have far fewer reviews, aligning with the earlier statistical findings.\n",
    "\n",
    "- **Distribution Insights**: The visualization makes it clear that just a small fraction of apps dominate user attention and feedback, while a large number of apps are relatively underrepresented in terms of review volume. This confirms that any analysis of user feedback must account for the dominance of a few apps to avoid skewing insights based on the behavior of a minority of apps.\n",
    "\n",
    "These statistics highlight the unequal distribution of reviews across apps, with a few very popular apps skewing the overall average, while most apps remain relatively under-reviewed. This distribution suggests that analyses of highly reviewed apps may yield different insights than those focused on less reviewed apps, and both groups may need to be treated separately to avoid overrepresentation of popular apps in general trends."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Review Author Frequency Analysis\n",
    "The analysis of review author stats sheds light on user engagement patterns and the diversity of perspectives in the dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analyzer.freqdistplot(df=df, x=\"author\", title=\"Review Author Frequency Analysis\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The **review author statistics** show that contributions are dominated by single-review authors, with a small group of frequent contributors influencing the mean and variance. Here’s a refined summary:\n",
    "\n",
    "1. **Predominantly Single Contributions**:\n",
    "   - The 25th, 50th (median), and 75th percentiles are all **1**, indicating that the vast majority of authors contribute only **one review**. This reflects common user behavior, where most users provide feedback infrequently and only on specific apps.\n",
    "\n",
    "2. **Low Mean with Limited Variability**:\n",
    "   - The mean of **1.16 reviews per author** is slightly above one, reflecting a small but notable group of users contributing multiple analyzer. However, with a standard deviation of **0.6**, variation in author activity is limited, with most authors contributing close to one review.\n",
    "\n",
    "3. **Outliers**:\n",
    "   - The maximum of **86 reviews** by a single author represents a distinct outlier and highlights a few highly active users who engage frequently. These power users may influence the overall dataset, especially in areas requiring deeper engagement or consistent feedback.\n",
    "\n",
    "4. **Implications for Analysis**:\n",
    "   - Since most authors provide only one review, analysis focused on individual contributions will capture typical user feedback, while tracking frequent contributors might reveal valuable insights across multiple apps. This distribution highlights a long-tail effect, where a few prolific reviewers stand out against the many single-review authors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Category Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reviews by Category Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analyzer.freqplot(df=df, y=\"category\", title=\"Reviews by Category Analysis\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The **Review Count by Category** analysis offers a nuanced view of user engagement across different app categories:\n",
    "\n",
    "1. **Skewed Distribution**:\n",
    "   - Review counts are highly skewed, with certain categories receiving vastly more reviews than others. Categories like **Health & Fitness** and **Utilities** have a large share of reviews, while **Finance** stands out as an outlier with significantly fewer analyzer.\n",
    "\n",
    "2. **Top Categories**:\n",
    "   - The highest-reviewed categories, such as **Health & Fitness**, **Utilities**, and **Social Networking**, account for a substantial portion of overall analyzer. These likely include apps with broad appeal, drawing consistent engagement.\n",
    "\n",
    "3. **Moderate and Low-Volume Categories**:\n",
    "   - Categories like **Business**, **Education**, **Reference**, and **Productivity** have moderate review counts, suggesting stable but more niche engagement.\n",
    "   - **Finance** is a unique low-volume category, with just under 40,000 reviews, possibly due to the utilitarian nature of finance apps, which may see less frequent user feedback.\n",
    "\n",
    "4. **Summary Statistics**:\n",
    "   - The mean review count is **421,575**, but with a high standard deviation (256,054), indicating significant variability.\n",
    "   - The median (418,121) and 75th percentile (510,229) confirm that only a few categories dominate, while others have fewer interactions.\n",
    "\n",
    "5. **Implications for Analysis**:\n",
    "   - This skewed distribution suggests that high-volume categories will likely drive overarching trends. For a balanced analysis, it may be useful to separate insights by review volume, ensuring that high-engagement categories don’t overshadow more niche ones, such as **Finance** or **Medical**. \n",
    "\n",
    "Overall, the variability across categories underscores differences in engagement levels, likely influenced by the specific functions and appeal of each app category."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Category Rating Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analyzer.assocplot(df=df, x=\"rating\", y=\"category\", title=\"Category Rating Analysis\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yes, I can see the chart you shared! Here’s a summary of insights based on the **Category Rating Analysis**:\n",
    "\n",
    "1. **High-Rated Categories**:\n",
    "   - **Book** and **Reference** categories have the highest average ratings. This might indicate that apps in these categories consistently meet or exceed user expectations, possibly due to their straightforward functionality (e.g., reference materials or reading).\n",
    "\n",
    "2. **Lower-Rated Categories**:\n",
    "   - **Finance**, **Business**, and **Utilities** have comparatively lower average ratings, which could suggest user dissatisfaction with aspects such as complexity, reliability, or usability. For instance, financial apps might face high user expectations and receive lower ratings if issues arise.\n",
    "\n",
    "3. **Relatively Uniform Ratings**:\n",
    "   - Categories like **Education**, **Entertainment**, **Health & Fitness**, and **Productivity** have more uniform ratings, showing stable but slightly lower user satisfaction than top-rated categories.\n",
    "\n",
    "4. **Narrow Rating Ranges**:\n",
    "   - Categories such as **Medical**, **Lifestyle**, and **Social Networking** show narrower rating distributions, indicating that user experiences within these categories may be more consistent, either positively or negatively.\n",
    "\n",
    "5. **Contextual Factors**:\n",
    "   - The variance in ratings by category suggests that app purpose affects user expectations. For example, critical-function apps (like Finance or Medical) might receive harsher ratings due to higher expectations, whereas leisure-oriented categories (like Book and Entertainment) tend to receive more favorable ratings.\n",
    "\n",
    "The chart reveals that ratings differ significantly by category, with some (like Book and Reference) performing well, while others (like Finance and Business) face more challenges in meeting user expectations. This provides valuable context for understanding user satisfaction across app types."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Category Review Length Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analyzer.assocplot(\n",
    "    df=df, x=\"eda_review_length\", y=\"category\", title=\"Category Review Length Analysis\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here’s an updated analysis of the **Category Review Length Analysis** chart based on the provided image:\n",
    "\n",
    "1. **Longer Reviews in Certain Categories**:\n",
    "   - Categories like **Health & Fitness**, **Reference**, and **Productivity** have slightly longer average review lengths, indicating that users in these areas tend to leave more detailed feedback. This may be due to the functional or critical nature of these apps, where users feel the need to share detailed experiences or provide specific feedback related to usability and functionality.\n",
    "\n",
    "2. **Moderate to Consistent Review Lengths Across Most Categories**:\n",
    "   - Many categories, including **Education**, **Entertainment**, **Medical**, and **Photo & Video**, show review lengths that are relatively consistent and moderate. These categories generally stay within a similar range, suggesting that users provide moderate levels of detail in their feedback.\n",
    "\n",
    "3. **Shorter Reviews in Other Categories**:\n",
    "   - **Social Networking** and **Utilities** have shorter average review lengths. This could indicate that users leave more concise feedback in these categories, possibly because these apps are more familiar and don’t require extensive explanation.\n",
    "\n",
    "4. **Finance and Business**:\n",
    "   - Similar to the previous observation, **Finance** and **Business** show moderate review lengths, where users might be motivated to share specific issues or experiences but keep their feedback relatively concise. This could reflect a balance between the complexity of these apps and the tendency of users to give focused feedback on usability or reliability.\n",
    "\n",
    "5. **Insights for Analysis**:\n",
    "   - Longer reviews in categories like Health & Fitness and Productivity might provide richer insights, as they could contain multiple aspects, detailed complaints, or suggestions. Shorter reviews, while less detailed, might still reveal high-level sentiment trends, especially in categories with simpler or more familiar apps.\n",
    "\n",
    "Review length generally aligns with the complexity or importance of the app category, with Health & Fitness, Reference, and Productivity attracting slightly longer reviews, while more casual categories like Social Networking and Utilities attract shorter, to-the-point feedback. This consistency provides a foundation for targeted analysis, as longer reviews may hold richer insights for in-depth analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Category Vote Count Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analyzer.assocplot(\n",
    "    df=df, x=\"vote_count\", y=\"category\", title=\"Category Vote Count Analysis\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Several points are notable:\n",
    "\n",
    "1. **High Engagement in Social Networking**:\n",
    "   - The **Social Networking** category has the highest average vote count, suggesting strong user engagement with reviews in this category. This may reflect the social nature of these apps, where users rely more on feedback from others to guide their choices or confirm app quality.\n",
    "\n",
    "2. **Moderate Engagement Across Other Categories**:\n",
    "   - Categories such as **Education**, **Entertainment**, and **Productivity** show moderate vote counts, indicating that users engage fairly actively with reviews in these areas. These categories often have apps that people use frequently, leading to consistent interaction with reviews to help inform decisions.\n",
    "\n",
    "3. **Lower Engagement in Categories like Food & Drink and Medical**:\n",
    "   - Categories such as **Food & Drink** and **Medical** have relatively lower vote counts, suggesting that users engage less with reviews in these areas. This might indicate that users feel less need to validate reviews, possibly due to more personal or situational preferences for these apps.\n",
    "\n",
    "4. **Broadly Consistent Vote Counts Across Most Categories**:\n",
    "   - Despite some differences, most categories fall within a similar range, suggesting that user engagement with reviews doesn’t vary drastically. This points to an overall steady interaction level across categories, although some (like Social Networking) clearly stand out.\n",
    "\n",
    "The chart shows that categories like **Social Networking** see high review engagement, likely due to the inherently social aspect of these apps. Meanwhile, **Food & Drink** and **Medical** apps tend to receive lower engagement on reviews, perhaps reflecting a more personal or straightforward user experience where fewer people feel compelled to interact with feedback."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Category Vote Sum Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analyzer.assocplot(\n",
    "    df=df, x=\"vote_sum\", y=\"category\", title=\"Category Vote Sum Analysis\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `vote-sum` analysis reinforces that from `vpte_count`:\n",
    "\n",
    "- **Productivity Leads Again**: Similar to vote count, the **Productivity** category also has the highest vote sum. This reinforces the idea that reviews in this category are seen as particularly informative or helpful, attracting positive feedback from users. Users may rely heavily on reviews to assess the effectiveness and functionality of productivity apps.\n",
    "\n",
    "- **Business, Education, and Social Networking Show Strong Vote Sums**: These categories also rank relatively high in vote sum, suggesting that reviews in these areas are both engaged with and considered valuable. This likely reflects the importance of these apps in users' daily activities and the need for detailed feedback.\n",
    "\n",
    "- **Lower Vote Sum in Food & Drink and Photo & Video**: These categories, similar to their lower vote count, also have lower vote sums, suggesting that reviews in these areas are not considered as informative or critical. Users may engage less with reviews in these categories or feel less inclined to rate them as helpful.\n",
    "\n",
    "In summary:\n",
    "- **Productivity Apps Stand Out**: Across both vote count and vote sum, **Productivity** apps clearly dominate, with users actively engaging with and valuing reviews in this category. This suggests that users place high importance on the quality and effectiveness of productivity tools, leading to more detailed and impactful analyzer.\n",
    "  \n",
    "- **Moderate to Low Engagement in Casual Categories**: Categories like **Photo & Video** and **Food & Drink** have lower vote counts and sums, indicating that users may engage with these apps more casually, leading to fewer and less impactful analyzer. \n",
    "\n",
    "This analysis shows that engagement with reviews varies significantly by category, with **Productivity** leading in both vote count and sum, while more casual app categories like **Food & Drink** and **Photo & Video** see lower engagement."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AppVoCAI Dataset: Random Sample\n",
    "This section presents a random sample of five reviews in table format, followed by a detailed analysis of each. We'll examine both qualitative aspects, like sentiment and key topics, and quantitative data, such as rating and vote count. By analyzing these reviews, we aim to obtain an indication of the types of insights we might uncover in the broader dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = df.sample(n=5, random_state=27)\n",
    "samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The random sample of 5 observations include a mix of highly rated apps, as well as lower ratings, with a range of review lengths, all of which reflect different user experiences. However, a common feature across the sample is the absence of votes (both vote count and vote sum are zero), reinforcing either a low level of engagement with individual reviews or that votes are not a common interaction on these apps.\n",
    "\n",
    "The reviews span a significant time range, from as early as 2011 to as recent as 2023, showcasing both historical and recent user sentiments. Review lengths vary from concise (7 words) to more detailed feedback (31 words), which highlights the difference in how users express their opinions depending on the app and personal style.\n",
    "\n",
    "Overall, the sample reflects the broader patterns that may emerge in the dataset: varied user ratings, relatively short reviews, and minimal engagement in terms of votes. This suggests that future analysis may need to pay close attention to factors like review length, category-specific trends, and potential changes in engagement over time, especially for reviews that go unnoticed in terms of user votes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Spectrum TV Review Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "printer = Printer()\n",
    "printer.print_dataframe_as_dict(\n",
    "    df=samples, list_index=0, title=samples[\"app_name\"].values[0], text_col=\"content\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This review provides insights into **qualitative** and **quantitative** aspects, highlighting user frustration with technical performance.\n",
    "\n",
    "---\n",
    "\n",
    "##### **Qualitative Analysis**:\n",
    "\n",
    "- **Content and Context**:\n",
    "  - The review describes two main issues:\n",
    "    1. **Streaming Quality**: The user is dissatisfied with the app's performance, noting issues with video quality (\"fuzzes out the pic\") and buffering. They compare Spectrum TV unfavorably to other streaming apps, implying that their internet connection is not the problem, but rather the app itself.\n",
    "    2. **Audio Compatibility**: The user reports a specific audio issue on Apple TV, where sound fails when switching to the Spectrum app, though it works fine on other apps.\n",
    "\n",
    "- **Sentiment**:\n",
    "  - The sentiment is negative, with a rating of 2 stars. The language reflects significant frustration, particularly with phrases like \"terrible job\" and \"Do better spectrum.\"\n",
    "\n",
    "- **Tone/Emotion**:\n",
    "  - The tone conveys disappointment and frustration. Phrases like \"Do better spectrum\" emphasize the user's dissatisfaction and expectation for improvement.\n",
    "\n",
    "- **Key Topics**:\n",
    "  - Key topics include **streaming quality** (buffering and picture clarity) and **device compatibility** (sound issues on Apple TV). Both are critical technical aspects that impact user experience.\n",
    "\n",
    "- **Clarity**:\n",
    "  - The review is clear and detailed. At 81 words, it provides enough context to understand the user’s specific issues without ambiguity.\n",
    "\n",
    "---\n",
    "\n",
    "##### **Quantitative Analysis**:\n",
    "\n",
    "- **Length**:\n",
    "  - At 81 words, this review is moderately long, suggesting the user is invested enough to describe multiple issues rather than simply leaving a brief complaint.\n",
    "\n",
    "- **Rating**:\n",
    "  - The 2-star rating signals clear dissatisfaction, though it isn't the lowest rating, possibly indicating that the user sees potential in the app if improvements are made.\n",
    "\n",
    "- **Vote Count/Engagement**:\n",
    "  - The review has no votes (`vote_count = 0`, `vote_sum = 0`), which may suggest it hasn't gained visibility or that other users have not prioritized these issues.\n",
    "\n",
    "- **Entropy/Complexity**:\n",
    "  - The review includes specific technical details, which could contribute to moderate entropy. Words like \"buffering,\" \"streaming data,\" and \"Apple TV\" add to the complexity, likely making it more informative for developers seeking feedback on technical issues.\n",
    "\n",
    "---\n",
    "\n",
    "##### Summary:\n",
    "This review highlights technical performance concerns with **Spectrum TV**, specifically around streaming quality and compatibility with Apple TV audio. The detailed feedback may reflect a user looking for constructive improvements rather than merely venting. The lack of engagement may indicate these issues are not widely experienced or that the review hasn't reached enough users. This type of review could be valuable for identifying recurring technical problems across similar analyzer. Further analysis of streaming-related complaints could reveal if these are common issues with Spectrum TV."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Instagram Review Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "printer.print_dataframe_as_dict(\n",
    "    df=samples, list_index=1, title=samples[\"app_name\"].values[1], text_col=\"content\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This review of **Instagram** indicates some frustration:\n",
    "\n",
    "---\n",
    "\n",
    "##### **Qualitative Analysis**:\n",
    "\n",
    "- **Content and Context**:\n",
    "  - The user expresses dissatisfaction with the presence of **suggested posts and ads** in their feed, which appears to be overwhelming their personal content. This is a common concern among users who prefer an unfiltered experience on social media.\n",
    "  - The strong reaction (\"On the verge of deleting account\") indicates the user may abandon the app if these issues persist, which points to a significant risk for user retention.\n",
    "\n",
    "- **Sentiment**:\n",
    "  - The sentiment is highly negative, as reflected by the 1-star rating and phrases like \"SICK of it!!!\" and \"Would not recommend!!!!\"\n",
    "\n",
    "- **Tone/Emotion**:\n",
    "  - The tone conveys frustration and annoyance, with the use of capital letters and multiple exclamation marks intensifying the sense of anger. This suggests a user who is close to leaving the app over these issues.\n",
    "\n",
    "- **Key Topics**:\n",
    "  - The main topics are **advertising** and **content curation**. The user is specifically unhappy with the prevalence of ads and suggested posts, which they perceive as intrusive to their Instagram experience.\n",
    "\n",
    "- **Clarity**:\n",
    "  - The review is clear and direct. Despite its brevity (26 words), it conveys strong feelings and specific grievances, making it easy to understand the user's complaints.\n",
    "\n",
    "---\n",
    "\n",
    "##### **Quantitative Analysis**:\n",
    "\n",
    "- **Length**:\n",
    "  - With only 26 words, this is a short review, likely indicating that the user was focused on expressing dissatisfaction without detailing the underlying issues or offering solutions.\n",
    "\n",
    "- **Rating**:\n",
    "  - The 1-star rating underscores extreme dissatisfaction, aligning with the content of the review, which is highly critical of Instagram’s ad-heavy content.\n",
    "\n",
    "- **Vote Count/Engagement**:\n",
    "  - This review has no votes (`vote_count = 0`, `vote_sum = 0`), which may indicate limited visibility or that others haven’t prioritized this complaint, even if they share similar frustrations.\n",
    "\n",
    "- **Entropy/Complexity**:\n",
    "  - Given the short length and use of strong emotional language, the review likely has low entropy (predictability), with common words reflecting a straightforward expression of frustration rather than a nuanced or complex opinion.\n",
    "\n",
    "---\n",
    "\n",
    "##### Summary:\n",
    "This review highlights significant dissatisfaction with Instagram’s reliance on **ads and suggested posts**, which the user finds intrusive and overwhelming. The short, emotional tone suggests that the user is on the verge of abandoning the app, potentially signaling a retention risk for Instagram. Although this review hasn't gained engagement from other users, analyzing similar reviews could determine if this frustration is a widespread issue. Overall, this review points to key areas of user dissatisfaction, particularly for users seeking a more personalized and less commercialized experience on the platform."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Move! Coach Review Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "printer.print_dataframe_as_dict(\n",
    "    df=samples, list_index=2, title=samples[\"app_name\"].values[2], text_col=\"content\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This review of **MOVE! Coach** focuses on the app’s usability and functionality.\n",
    "\n",
    "---\n",
    "\n",
    "##### **Qualitative Analysis**:\n",
    "\n",
    "- **Content and Context**:\n",
    "  - The user is frustrated with the app's **usability** and **lack of functionality**, specifically regarding the inability to log meals and exercises. They describe spending considerable time navigating the app's manuals, videos, and sections, only to find limited functionality (specifically, the option to add weight but not other health metrics).\n",
    "  - This suggests a potential mismatch between user expectations and the app's features, as well as possible shortcomings in the app’s user interface and navigation.\n",
    "\n",
    "- **Sentiment**:\n",
    "  - The sentiment is clearly negative, with a 1-star rating and language that reflects frustration. Phrases like \"Super frustrating\" emphasize the user’s disappointment and dissatisfaction with the app's usability.\n",
    "\n",
    "- **Tone/Emotion**:\n",
    "  - The tone conveys frustration and disappointment, as the user feels let down by the app's lack of key features. This sentiment is intensified by the fact that the user put in considerable effort to understand the app's functionality.\n",
    "\n",
    "- **Key Topics**:\n",
    "  - Key topics include **feature accessibility** (finding features to log meals and exercises) and **usability** (difficulty navigating the app). These are critical areas in health and fitness apps where users expect ease of use and comprehensive functionality.\n",
    "\n",
    "- **Clarity**:\n",
    "  - The review is relatively clear, though there are some minor grammatical errors (\"I doesn’t an hour\"), likely stemming from user frustration or haste. However, the core message of dissatisfaction with the app's lack of functionality is conveyed effectively.\n",
    "\n",
    "---\n",
    "\n",
    "##### **Quantitative Analysis**:\n",
    "\n",
    "- **Length**:\n",
    "  - With 37 words, this review is brief but provides enough context to understand the user’s main issues, especially around app functionality.\n",
    "\n",
    "- **Rating**:\n",
    "  - The 1-star rating reinforces the user's strong dissatisfaction with the app. The rating aligns with the critical nature of the review content.\n",
    "\n",
    "- **Vote Count/Engagement**:\n",
    "  - This review has no votes (`vote_count = 0`, `vote_sum = 0`), which may indicate it hasn’t gained visibility or resonance with other users. However, the issues raised may still be relevant for product improvement.\n",
    "\n",
    "- **Entropy/Complexity**:\n",
    "  - The review likely has low entropy, as it uses common words and phrases to convey frustration. The straightforward language indicates immediate concerns without nuanced discussion.\n",
    "\n",
    "---\n",
    "\n",
    "##### Summary:\n",
    "This review highlights significant usability issues with **MOVE! Coach**, focusing on the user's inability to find essential features such as meal and exercise logging. The frustration expressed reflects unmet expectations for a health and fitness app, where users anticipate easy access to comprehensive tracking features. The lack of engagement from other users may suggest that this experience is either unique to this user or not widely shared. However, if similar feedback is found in other reviews, it could indicate broader usability issues that may warrant improvement."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pump Log App Review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "printer.print_dataframe_as_dict(\n",
    "    df=samples, list_index=3, title=samples[\"app_name\"].values[3], text_col=\"content\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This review of **Pump Log** provides insights into the app's effectiveness and emotional support for users, as well as value for cost.\n",
    "\n",
    "---\n",
    "\n",
    "##### **Qualitative Analysis**:\n",
    "\n",
    "- **Content and Context**:\n",
    "  - The review expresses strong satisfaction with the app’s role in supporting breastfeeding mothers. The user mentions that the app helped them persevere during challenging moments (\"This app kept me going when I felt I couldn’t anymore\"), indicating that the app provides not just functionality, but also emotional support and motivation.\n",
    "  - The user also highlights the **value for cost**, noting that the extended options are \"worth every bit\" of the small charge. This speaks to the perceived value and effectiveness of the paid features.\n",
    "\n",
    "- **Sentiment**:\n",
    "  - The sentiment is highly positive, with a 5-star rating. The language used, such as \"10/10 recommend\" and \"Worth every bit,\" conveys strong endorsement and satisfaction.\n",
    "\n",
    "- **Tone/Emotion**:\n",
    "  - The tone is enthusiastic and supportive. The user’s experience with the app is deeply personal, and they express gratitude, indicating that the app has had a meaningful impact on their breastfeeding journey.\n",
    "\n",
    "- **Key Topics**:\n",
    "  - Key topics include **recommendation** (highly recommending the app to other mothers) and **value for cost** (justifying the cost of extended options). The app’s supportive nature and functionality for \"milk making mamas\" are emphasized.\n",
    "\n",
    "- **Clarity**:\n",
    "  - The review is clear and concise. It provides specific praise for the app’s motivational support and value without any ambiguity.\n",
    "\n",
    "---\n",
    "\n",
    "##### **Quantitative Analysis**:\n",
    "\n",
    "- **Length**:\n",
    "  - At 33 words, the review is short but impactful, providing both a recommendation and specific reasons for the user’s satisfaction with the app.\n",
    "\n",
    "- **Rating**:\n",
    "  - The 5-star rating aligns with the review's positive tone and enthusiastic language, showing that the user finds the app exceptionally valuable.\n",
    "\n",
    "- **Vote Count/Engagement**:\n",
    "  - This review has no votes (`vote_count = 0`, `vote_sum = 0`), indicating that it hasn’t gained visibility or engagement from other users. However, its highly positive tone could resonate if promoted to a larger audience.\n",
    "\n",
    "- **Entropy/Complexity**:\n",
    "  - Given its brevity and straightforward language, the review likely has low entropy, using simple words to convey strong endorsement without much complexity.\n",
    "\n",
    "---\n",
    "\n",
    "##### Summary:\n",
    "This review highlights the effectiveness of **Pump Log** in supporting breastfeeding mothers, both functionally and emotionally. The user’s enthusiastic recommendation and praise for the app’s value indicate a high level of satisfaction, particularly with the app’s role in motivating users during challenging times. Despite the lack of engagement, the review provides valuable insight into how this app meets specific user needs in a meaningful way. Analyzing similar reviews could reveal if this level of emotional impact is common among users of this app."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### MyFitnessPal: Calorie Counter App Review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "printer.print_dataframe_as_dict(\n",
    "    df=samples, list_index=4, title=samples[\"app_name\"].values[4], text_col=\"content\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This review of **Pluto TV - Live TV and Movies** offers insights into user discovery and initial impressions of app content.\n",
    "\n",
    "---\n",
    "\n",
    "##### **Qualitative Analysis**:\n",
    "\n",
    "- **Content and Context**:\n",
    "  - The review reflects a positive initial discovery experience. The user recently found **Pluto TV** and is pleasantly surprised by the wide range of available TV shows, expressing appreciation for the app’s content library.\n",
    "  - The user’s phrase, \"I am amazed that you have so many,\" highlights satisfaction with the app’s offerings, suggesting that Pluto TV provides a breadth of content that appeals to new users.\n",
    "\n",
    "- **Sentiment**:\n",
    "  - The sentiment is very positive, as indicated by the 5-star rating and the words \"amazed\" and \"thank you,\" which show the user's satisfaction and gratitude.\n",
    "\n",
    "- **Tone/Emotion**:\n",
    "  - The tone is enthusiastic and appreciative. The user's surprise at the content selection conveys excitement and a positive first impression.\n",
    "\n",
    "- **Key Topics**:\n",
    "  - Key topics include **content variety** (large selection of TV shows) and **user discovery** (newly finding the app). This feedback highlights the importance of content diversity in attracting and retaining new users for entertainment apps.\n",
    "\n",
    "- **Clarity**:\n",
    "  - The review is clear and concise. Although brief, it communicates both the user’s initial impression and appreciation effectively.\n",
    "\n",
    "---\n",
    "\n",
    "##### **Quantitative Analysis**:\n",
    "\n",
    "- **Length**:\n",
    "  - At 29 words, the review is short, focusing on the user’s initial excitement about discovering the app’s content without providing additional detail.\n",
    "\n",
    "- **Rating**:\n",
    "  - The 5-star rating aligns with the enthusiastic tone, showing that the user’s initial experience with the app was very positive.\n",
    "\n",
    "- **Vote Count/Engagement**:\n",
    "  - This review has no votes (`vote_count = 0`, `vote_sum = 0`), suggesting that it hasn’t gained visibility or engagement from other users. However, the positive tone could be influential if shared with prospective users.\n",
    "\n",
    "- **Entropy/Complexity**:\n",
    "  - The review likely has low entropy due to its straightforward language and short length, focusing on simple expressions of amazement and gratitude.\n",
    "\n",
    "---\n",
    "\n",
    "##### Summary:\n",
    "This review reflects a highly positive initial experience with **Pluto TV**, focusing on the breadth of available content. The user's excitement at discovering the variety of TV shows highlights an important value proposition for the app in attracting new users. While the review lacks engagement from others, it underscores the impact of a diverse content library on first-time users. Further analysis of similar reviews could help identify if content variety is a recurring theme that appeals to new Pluto TV users."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Summary and Key Insights\n",
    "The dataset consists of 5.9 million observations, including approximately 5 million unique authors, 33,000 apps, and 14 categories, spanning from January 2021 to September 2023. It contains 12 features, providing a comprehensive overview of app reviews across multiple years and categories.\n",
    "\n",
    "Our analysis included:\n",
    "- **Structural Analysis**: We examined the dataset's structure, including data types, completeness, and uniqueness.\n",
    "- **Distribution and Frequency Analyses**: Focused on ratings, review lengths, and vote patterns.\n",
    "- **Random Sample Review Analysis**: We performed qualitative and quantitative analysis on randomly selected reviews to extract user sentiment and behavioral patterns.\n",
    "\n",
    "### Key Observations:\n",
    "1. **Duplicate IDs and Content**: Both duplicate review IDs and duplicate content will need to be addressed during data cleaning to ensure dataset integrity.\n",
    "2. **Ratings Distribution**: The rating distribution is highly skewed towards higher ratings, with a majority of reviews rated on the upper end of the scale.\n",
    "3. **Review Lengths**: Review lengths are right-skewed, with a small number of very long analyzer. Zero-length reviews should be removed as they provide no valuable information.\n",
    "4. **Vote Count and Vote Sum**: These features are sparse, indicating that very few reviews receive engagement (votes), limiting their utility as indicators of review quality or influence.\n",
    "5. **Review Timeline**: Reviews span from 2008 through 2023, with the highest concentration in 2020 and 2021, suggesting a spike in user feedback during this period.\n",
    "6. **App Review Frequencies**: App review frequencies are also highly skewed, with a few apps receiving a disproportionately large number of reviews, indicating varying levels of user engagement across different apps.\n",
    "7. **Author Behavior**: The vast majority of authors have written only one review, limiting the ability to track user behavior over time but offering insights into one-time interactions with apps.\n",
    "8. **Category Insights**: Health & Fitness, Utilities, and Social Networking apps have garnered the highest number of reviews, indicating strong user engagement in these categories.\n",
    "\n",
    "These findings provide a solid foundation for further analysis and highlight key areas for data cleaning and exploration.\n",
    "\n",
    "Next, we conduct data cleaning to prepare the dataset for downstream modeling. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "appvocai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
