{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": [
     "remove-cell"
    ]
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import os\n",
    "\n",
    "if \"jbook\" in os.getcwd():\n",
    "    os.chdir(os.path.abspath(os.path.join(\"../..\")))\n",
    "FORCE = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Quality Analysis (TQA) for Aspect-Based Sentiment Analysis (ABSA)\n",
    "---\n",
    "In **Aspect-Based Sentiment Analysis (ABSA)**, the primary goal is to extract sentiment for specific aspects within a text, such as products, services, or features. To ensure accurate sentiment extraction, the text must be of sufficient quality. Text quality directly influences the effectiveness of ABSA models, and assessing text quality is crucial to improve aspect-level sentiment predictions.\n",
    "\n",
    "The **Text Quality Analysis (TQA)** process evaluates various features of the text that may affect ABSA performance. It focuses on syntactic and lexical features that help determine the relevance, richness, and clarity of the content in relation to specific aspects.\n",
    "\n",
    "Key **requirements for ABSA-based text quality** are:\n",
    "\n",
    "- **Aspect Identification**: Clear identification of aspects (e.g., product features or services).\n",
    "- **Aspect-Verb Pairing**: The relationship between aspects and verbs (actions related to aspects).\n",
    "- **Text Coherence and Complexity**: Well-formed sentences with a manageable level of complexity.\n",
    "- **Lexical Density and Content Richness**: The degree to which the content reflects substantive, content-rich words.\n",
    "\n",
    "These requirements are captured by **syntactic measures** like noun phrases, verb phrases, aspect-verb pairs, and additional features like review length, lexical density, and dependency depth. Together, these features inform the quality of text in the context of ABSA tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Measures of Text Quality and Their Weights\n",
    "---\n",
    "The following **syntactic features** and their **weights** quantify the quality of a given text for ABSA. Each measure contributes to the overall **Text Quality Analysis (TQA)** score, which is a weighted sum of these features.\n",
    "\n",
    "$$\n",
    "\\text{TQA Score}=\\sum_{i} \\left( \\text{Measure Score}_i \\times \\text{Weight}_i \\right)\n",
    "$$\n",
    "\n",
    "Here’s the run-through of each measure, its weight, and its impact on the overall TQA score:\n",
    "\n",
    "- **Aspect-Verb Pairs**: This measure identifies the relationship between **aspects** (e.g., product features) and **verbs** (actions related to those aspects). A higher number of aspect-verb pairs indicates that the text is highly relevant to ABSA, making it the most heavily weighted feature in TQA with a weight of **4**.    \n",
    "- **Noun Phrases**: Noun phrases help identify **key entities** and aspects in the text. The weight of **2.5** reflects the importance of rich, aspect-relevant content in generating accurate sentiment scores.    \n",
    "- **Verb Phrases**: Verb phrases identify the **actions or states** related to aspects. This has a weight of **2**, highlighting the importance of these phrases for understanding sentiment.    \n",
    "- **Adjective Count**: Adjectives capture **descriptive sentiment**, reflecting the **quality and intensity** of the sentiments expressed. It is weighted at **1.5**, indicating its moderate to high importance in sentiment analysis.    \n",
    "- **Lexical Density**: This measure quantifies the amount of **content-rich vocabulary** used in the text. High lexical density indicates that the text contains more **substantive content**, making it more informative for sentiment analysis. It is weighted at **1.5**.    \n",
    "- **Noun Count**: The count of **nouns** provides insights into the **syntactic structure** and **content** of the text. It is weighted at **1**, reflecting its importance in the analysis of textual richness.    \n",
    "- **Verb Count**: The count of **verbs** helps capture the **action-oriented components** of the text. Like the noun count, it is weighted at **1**.    \n",
    "- **Review Length**: Longer reviews generally provide more context for sentiment analysis, but excessive length can introduce noise. It is weighted at **1**, reflecting its moderate importance in sentiment prediction.    \n",
    "- **Dependency Depth**: This measure indicates the **complexity** of sentence structure. Although sentence complexity can affect sentiment extraction, it plays a secondary role in ABSA and is weighted at **1**.    \n",
    "- **Adverb Count**: Adverbs modify verbs or adjectives, helping capture nuances in sentiment. With a weight of **0.75**, it plays a supportive role in sentiment analysis.    \n",
    "- **Adverbial Phrases**: These phrases provide additional **modification** of actions, aspects, and sentiments. They are weighted at **0.5**, as they are considered less important than noun and verb phrases in ABSA tasks.\n",
    "\n",
    "**Summary of Weights:**\n",
    "\n",
    "| Measure           | Weight |\n",
    "|-------------------|--------|\n",
    "| Aspect-Verb Pairs | 4      |\n",
    "| Noun Phrases      | 2.5    |\n",
    "| Verb Phrases      | 2      |\n",
    "| Adjective Count   | 1.5    |\n",
    "| Lexical Density   | 1.5    |\n",
    "| Noun Count        | 1      |\n",
    "| Verb Count        | 1      |\n",
    "| Review Length     | 1      |\n",
    "| Dependency Depth  | 1      |\n",
    "| Adverb Count      | 0.75   |\n",
    "| Adverbial Phrases | 0.5    |\n",
    "\n",
    "## Text Quality Analysis Pipeline\n",
    "With that, the text quality analysis (TQA) processing pipeline computes these text quality metrics at scale.\n",
    "\n",
    "The pipeline leverages:     \n",
    "- Dask for distributed data processing, enabling efficient computation over large text datasets.\n",
    "- spaCy for NLP tasks, including dependency parsing and part-of-speech (POS) tagging.\n",
    "\n",
    "The pipeline follows these steps:    \n",
    "- Dataset Configuration: Define the source and target dataset configurations.\n",
    "- Pipeline Construction: Instantiate the TQAStageBuilder and configure it for Dask processing.\n",
    "- Execution: Run the TQAStage, applying text analysis and feature extraction.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "hide-cell"
    ]
   },
   "source": [
    "### Import Libraries\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": [
     "hide-cell"
    ]
   },
   "outputs": [],
   "source": [
    "\n",
    "from genailab.setup import auto_wire_container\n",
    "from genailab.core.dtypes import DFType\n",
    "from genailab.infra.utils.file.fileset import FileFormat\n",
    "from genailab.asset.dataset.config import DatasetConfig\n",
    "from genailab.flow.dataprep.tqa.builder import TQAStageBuilder\n",
    "from genailab.asset.dataset.config import DatasetConfig\n",
    "from genailab.core.flow import PhaseDef, StageDef\n",
    "\n",
    "\n",
    "# Wire container\n",
    "container = auto_wire_container()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the Source and Target Dataset Configurations\n",
    "---\n",
    "The source dataset represents the cleaned text data, while the target dataset will store the extracted text quality features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Source Dataset Configuration\n",
    "source_config = DatasetConfig(\n",
    "    phase=PhaseDef.DATAPREP,\n",
    "    stage=StageDef.CLEAN,\n",
    "    name=\"review\",\n",
    "    file_format=FileFormat.PARQUET,\n",
    "    asset_type=\"dataset\",\n",
    "    dftype=DFType.PANDAS,\n",
    ")\n",
    "\n",
    "# Target Dataset Configuration\n",
    "target_config = DatasetConfig(\n",
    "    phase=PhaseDef.DATAPREP,\n",
    "    stage=StageDef.TQA,\n",
    "    name=\"review\",\n",
    "    file_format=FileFormat.PARQUET,\n",
    "    asset_type=\"dataset\",\n",
    "    dftype=DFType.PANDAS,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Construct the TQA Pipeline\n",
    "---\n",
    "We use the TQAStageBuilder to configure a Dask-powered text quality analysis pipeline with:\n",
    "\n",
    "- Normalization enabled (ensures robust feature scaling).\n",
    "- Batch processing (improves efficiency for large datasets)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "stage = (\n",
    "    TQAStageBuilder()\n",
    "        .with_dask(normalized=True, batched=True)\n",
    "        .build(source_config=source_config, target_config=target_config))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run the Pipeline\n",
    "---\n",
    "Once the pipeline is built, we execute it to compute text quality features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "# ============================================================================== #\n",
      "#             Text Quality Analysis Stage Sat, 08 Feb 2025 05:49:40              #\n",
      "# ============================================================================== #\n",
      "\n",
      "____________________________________________________________________________\n",
      "Text Quality Analysis Stage             05:49:40    05:54:51    5.0 minutes and 10.77 seconds\n",
      "\n",
      "\n",
      "# ============================================================================ #\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dataset = stage.run(force=FORCE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validate the Dataset\n",
    "---\n",
    "Let's ensure that the text quality measures have been added and the dataset is in the repository."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dataset Profile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Column</th>\n",
       "      <th>DataType</th>\n",
       "      <th>Complete</th>\n",
       "      <th>Null</th>\n",
       "      <th>Completeness</th>\n",
       "      <th>Unique</th>\n",
       "      <th>Duplicate</th>\n",
       "      <th>Uniqueness</th>\n",
       "      <th>Size (Bytes)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>id</td>\n",
       "      <td>string[python]</td>\n",
       "      <td>4939</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4939</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>331387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>app_id</td>\n",
       "      <td>string[python]</td>\n",
       "      <td>4939</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1930</td>\n",
       "      <td>3009</td>\n",
       "      <td>0.390767</td>\n",
       "      <td>328454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>app_name</td>\n",
       "      <td>string[python]</td>\n",
       "      <td>4939</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1930</td>\n",
       "      <td>3009</td>\n",
       "      <td>0.390767</td>\n",
       "      <td>394959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>category_id</td>\n",
       "      <td>string[python]</td>\n",
       "      <td>4939</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>14</td>\n",
       "      <td>4925</td>\n",
       "      <td>0.002835</td>\n",
       "      <td>301279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>author</td>\n",
       "      <td>string[python]</td>\n",
       "      <td>4939</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4937</td>\n",
       "      <td>2</td>\n",
       "      <td>0.999595</td>\n",
       "      <td>380303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>rating</td>\n",
       "      <td>Int64</td>\n",
       "      <td>4939</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5</td>\n",
       "      <td>4934</td>\n",
       "      <td>0.001012</td>\n",
       "      <td>44451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>content</td>\n",
       "      <td>string[python]</td>\n",
       "      <td>4939</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4936</td>\n",
       "      <td>3</td>\n",
       "      <td>0.999393</td>\n",
       "      <td>1237730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>vote_sum</td>\n",
       "      <td>Int64</td>\n",
       "      <td>4939</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>14</td>\n",
       "      <td>4925</td>\n",
       "      <td>0.002835</td>\n",
       "      <td>44451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>vote_count</td>\n",
       "      <td>Int64</td>\n",
       "      <td>4939</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>18</td>\n",
       "      <td>4921</td>\n",
       "      <td>0.003644</td>\n",
       "      <td>44451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>date</td>\n",
       "      <td>datetime64[ns]</td>\n",
       "      <td>4939</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4939</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>39512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>category</td>\n",
       "      <td>string[python]</td>\n",
       "      <td>4939</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>14</td>\n",
       "      <td>4925</td>\n",
       "      <td>0.002835</td>\n",
       "      <td>338139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>noun_count</td>\n",
       "      <td>Float64</td>\n",
       "      <td>4939</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>66</td>\n",
       "      <td>4873</td>\n",
       "      <td>0.013363</td>\n",
       "      <td>44451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>verb_count</td>\n",
       "      <td>Float64</td>\n",
       "      <td>4939</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>55</td>\n",
       "      <td>4884</td>\n",
       "      <td>0.011136</td>\n",
       "      <td>44451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>adjective_count</td>\n",
       "      <td>Float64</td>\n",
       "      <td>4939</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>30</td>\n",
       "      <td>4909</td>\n",
       "      <td>0.006074</td>\n",
       "      <td>44451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>adverb_count</td>\n",
       "      <td>Float64</td>\n",
       "      <td>4939</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>30</td>\n",
       "      <td>4909</td>\n",
       "      <td>0.006074</td>\n",
       "      <td>44451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>aspect_verb_pairs</td>\n",
       "      <td>Float64</td>\n",
       "      <td>4939</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>31</td>\n",
       "      <td>4908</td>\n",
       "      <td>0.006277</td>\n",
       "      <td>44451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>noun_phrases</td>\n",
       "      <td>Float64</td>\n",
       "      <td>4939</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>52</td>\n",
       "      <td>4887</td>\n",
       "      <td>0.010528</td>\n",
       "      <td>44451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>verb_phrases</td>\n",
       "      <td>Float64</td>\n",
       "      <td>4939</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>54</td>\n",
       "      <td>4885</td>\n",
       "      <td>0.010933</td>\n",
       "      <td>44451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>adverbial_phrases</td>\n",
       "      <td>Float64</td>\n",
       "      <td>4939</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8</td>\n",
       "      <td>4931</td>\n",
       "      <td>0.001620</td>\n",
       "      <td>44451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>review_length</td>\n",
       "      <td>Float64</td>\n",
       "      <td>4939</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>216</td>\n",
       "      <td>4723</td>\n",
       "      <td>0.043734</td>\n",
       "      <td>44451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>lexical_density</td>\n",
       "      <td>Float64</td>\n",
       "      <td>4939</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>797</td>\n",
       "      <td>4142</td>\n",
       "      <td>0.161369</td>\n",
       "      <td>44451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>dependency_depth</td>\n",
       "      <td>Float64</td>\n",
       "      <td>4939</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>187</td>\n",
       "      <td>4752</td>\n",
       "      <td>0.037862</td>\n",
       "      <td>44451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>tqa_score</td>\n",
       "      <td>Float64</td>\n",
       "      <td>4939</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4820</td>\n",
       "      <td>119</td>\n",
       "      <td>0.975906</td>\n",
       "      <td>44451</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Column        DataType  Complete  Null  Completeness  Unique  \\\n",
       "0                  id  string[python]      4939     0           1.0    4939   \n",
       "1              app_id  string[python]      4939     0           1.0    1930   \n",
       "2            app_name  string[python]      4939     0           1.0    1930   \n",
       "3         category_id  string[python]      4939     0           1.0      14   \n",
       "4              author  string[python]      4939     0           1.0    4937   \n",
       "5              rating           Int64      4939     0           1.0       5   \n",
       "6             content  string[python]      4939     0           1.0    4936   \n",
       "7            vote_sum           Int64      4939     0           1.0      14   \n",
       "8          vote_count           Int64      4939     0           1.0      18   \n",
       "9                date  datetime64[ns]      4939     0           1.0    4939   \n",
       "10           category  string[python]      4939     0           1.0      14   \n",
       "11         noun_count         Float64      4939     0           1.0      66   \n",
       "12         verb_count         Float64      4939     0           1.0      55   \n",
       "13    adjective_count         Float64      4939     0           1.0      30   \n",
       "14       adverb_count         Float64      4939     0           1.0      30   \n",
       "15  aspect_verb_pairs         Float64      4939     0           1.0      31   \n",
       "16       noun_phrases         Float64      4939     0           1.0      52   \n",
       "17       verb_phrases         Float64      4939     0           1.0      54   \n",
       "18  adverbial_phrases         Float64      4939     0           1.0       8   \n",
       "19      review_length         Float64      4939     0           1.0     216   \n",
       "20    lexical_density         Float64      4939     0           1.0     797   \n",
       "21   dependency_depth         Float64      4939     0           1.0     187   \n",
       "22          tqa_score         Float64      4939     0           1.0    4820   \n",
       "\n",
       "    Duplicate  Uniqueness  Size (Bytes)  \n",
       "0           0    1.000000        331387  \n",
       "1        3009    0.390767        328454  \n",
       "2        3009    0.390767        394959  \n",
       "3        4925    0.002835        301279  \n",
       "4           2    0.999595        380303  \n",
       "5        4934    0.001012         44451  \n",
       "6           3    0.999393       1237730  \n",
       "7        4925    0.002835         44451  \n",
       "8        4921    0.003644         44451  \n",
       "9           0    1.000000         39512  \n",
       "10       4925    0.002835        338139  \n",
       "11       4873    0.013363         44451  \n",
       "12       4884    0.011136         44451  \n",
       "13       4909    0.006074         44451  \n",
       "14       4909    0.006074         44451  \n",
       "15       4908    0.006277         44451  \n",
       "16       4887    0.010528         44451  \n",
       "17       4885    0.010933         44451  \n",
       "18       4931    0.001620         44451  \n",
       "19       4723    0.043734         44451  \n",
       "20       4142    0.161369         44451  \n",
       "21       4752    0.037862         44451  \n",
       "22        119    0.975906         44451  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.profile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dataset Sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>app_id</th>\n",
       "      <th>app_name</th>\n",
       "      <th>category_id</th>\n",
       "      <th>author</th>\n",
       "      <th>rating</th>\n",
       "      <th>content</th>\n",
       "      <th>vote_sum</th>\n",
       "      <th>vote_count</th>\n",
       "      <th>date</th>\n",
       "      <th>...</th>\n",
       "      <th>adjective_count</th>\n",
       "      <th>adverb_count</th>\n",
       "      <th>aspect_verb_pairs</th>\n",
       "      <th>noun_phrases</th>\n",
       "      <th>verb_phrases</th>\n",
       "      <th>adverbial_phrases</th>\n",
       "      <th>review_length</th>\n",
       "      <th>lexical_density</th>\n",
       "      <th>dependency_depth</th>\n",
       "      <th>tqa_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10019409512</td>\n",
       "      <td>1380362212</td>\n",
       "      <td>GALATEA: Novels &amp; Audiobooks</td>\n",
       "      <td>6018</td>\n",
       "      <td>c011c66aae3e668b150e</td>\n",
       "      <td>5</td>\n",
       "      <td>i love it but the chapter and waiting hours fo...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2023-06-10 15:09:00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.639057</td>\n",
       "      <td>3.675326</td>\n",
       "      <td>2.70805</td>\n",
       "      <td>16.176484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10027124164</td>\n",
       "      <td>1380362212</td>\n",
       "      <td>GALATEA: Novels &amp; Audiobooks</td>\n",
       "      <td>6018</td>\n",
       "      <td>5a2741393dd20358b609</td>\n",
       "      <td>5</td>\n",
       "      <td>i like the books that i have read so far if th...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2023-06-12 20:14:00</td>\n",
       "      <td>...</td>\n",
       "      <td>1.386294</td>\n",
       "      <td>1.098612</td>\n",
       "      <td>1.609438</td>\n",
       "      <td>2.079442</td>\n",
       "      <td>2.302585</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>3.912023</td>\n",
       "      <td>3.683251</td>\n",
       "      <td>3.931826</td>\n",
       "      <td>37.360035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10036938913</td>\n",
       "      <td>1076402606</td>\n",
       "      <td>Libby, by OverDrive</td>\n",
       "      <td>6018</td>\n",
       "      <td>46117640263dddac9294</td>\n",
       "      <td>5</td>\n",
       "      <td>i have read dozens upon dozens of books after ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2023-06-15 17:01:00</td>\n",
       "      <td>...</td>\n",
       "      <td>1.94591</td>\n",
       "      <td>1.098612</td>\n",
       "      <td>1.386294</td>\n",
       "      <td>1.609438</td>\n",
       "      <td>2.079442</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>3.850148</td>\n",
       "      <td>3.795001</td>\n",
       "      <td>3.850148</td>\n",
       "      <td>35.486515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10047764706</td>\n",
       "      <td>1076402606</td>\n",
       "      <td>Libby, by OverDrive</td>\n",
       "      <td>6018</td>\n",
       "      <td>a0e95f8868233439444d</td>\n",
       "      <td>5</td>\n",
       "      <td>happy with the app i use it primarily for audi...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2023-06-18 19:40:00</td>\n",
       "      <td>...</td>\n",
       "      <td>1.609438</td>\n",
       "      <td>1.386294</td>\n",
       "      <td>1.098612</td>\n",
       "      <td>1.94591</td>\n",
       "      <td>1.386294</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>3.555348</td>\n",
       "      <td>3.987894</td>\n",
       "      <td>3.583519</td>\n",
       "      <td>32.536492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10064456025</td>\n",
       "      <td>1535748732</td>\n",
       "      <td>Storyroom - Webnovel &amp; Story</td>\n",
       "      <td>6018</td>\n",
       "      <td>bb43c451a876165c2abf</td>\n",
       "      <td>1</td>\n",
       "      <td>im going to be honest the books are really gre...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2023-06-23 15:23:00</td>\n",
       "      <td>...</td>\n",
       "      <td>2.197225</td>\n",
       "      <td>1.609438</td>\n",
       "      <td>1.609438</td>\n",
       "      <td>2.302585</td>\n",
       "      <td>2.639057</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.418841</td>\n",
       "      <td>3.804492</td>\n",
       "      <td>4.477337</td>\n",
       "      <td>41.925267</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            id      app_id                      app_name category_id  \\\n",
       "0  10019409512  1380362212  GALATEA: Novels & Audiobooks        6018   \n",
       "1  10027124164  1380362212  GALATEA: Novels & Audiobooks        6018   \n",
       "2  10036938913  1076402606           Libby, by OverDrive        6018   \n",
       "3  10047764706  1076402606           Libby, by OverDrive        6018   \n",
       "4  10064456025  1535748732  Storyroom - Webnovel & Story        6018   \n",
       "\n",
       "                 author rating  \\\n",
       "0  c011c66aae3e668b150e      5   \n",
       "1  5a2741393dd20358b609      5   \n",
       "2  46117640263dddac9294      5   \n",
       "3  a0e95f8868233439444d      5   \n",
       "4  bb43c451a876165c2abf      1   \n",
       "\n",
       "                                             content vote_sum vote_count  \\\n",
       "0  i love it but the chapter and waiting hours fo...        0          0   \n",
       "1  i like the books that i have read so far if th...        0          0   \n",
       "2  i have read dozens upon dozens of books after ...        0          0   \n",
       "3  happy with the app i use it primarily for audi...        0          0   \n",
       "4  im going to be honest the books are really gre...        0          0   \n",
       "\n",
       "                 date  ... adjective_count adverb_count aspect_verb_pairs  \\\n",
       "0 2023-06-10 15:09:00  ...             0.0          0.0               0.0   \n",
       "1 2023-06-12 20:14:00  ...        1.386294     1.098612          1.609438   \n",
       "2 2023-06-15 17:01:00  ...         1.94591     1.098612          1.386294   \n",
       "3 2023-06-18 19:40:00  ...        1.609438     1.386294          1.098612   \n",
       "4 2023-06-23 15:23:00  ...        2.197225     1.609438          1.609438   \n",
       "\n",
       "  noun_phrases verb_phrases adverbial_phrases review_length lexical_density  \\\n",
       "0     0.693147     0.693147               0.0      2.639057        3.675326   \n",
       "1     2.079442     2.302585          0.693147      3.912023        3.683251   \n",
       "2     1.609438     2.079442          0.693147      3.850148        3.795001   \n",
       "3      1.94591     1.386294          0.693147      3.555348        3.987894   \n",
       "4     2.302585     2.639057               0.0      4.418841        3.804492   \n",
       "\n",
       "  dependency_depth  tqa_score  \n",
       "0          2.70805  16.176484  \n",
       "1         3.931826  37.360035  \n",
       "2         3.850148  35.486515  \n",
       "3         3.583519  32.536492  \n",
       "4         4.477337  41.925267  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.dataframe.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dataset Repository"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "repo = container.io.repo()\n",
    "ds = repo.get(asset_id=dataset.asset_id)\n",
    "assert ds == dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great! Now that we've confirmed the dataset has been successfully processed, we have a set of **text quality analysis** metrics that we can use for instance selection during the feature engineering stage.\n",
    "Next, we transition to **sentiment analysis at the review level**. In this phase, we will analyze the overall **sentiment** of each review."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "genai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
