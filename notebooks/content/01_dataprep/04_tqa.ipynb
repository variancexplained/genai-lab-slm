{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": [
     "remove-cell"
    ]
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import os\n",
    "\n",
    "if \"jbook\" in os.getcwd():\n",
    "    os.chdir(os.path.abspath(os.path.join(\"../..\")))\n",
    "FORCE = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Quality Analysis (TQA) for Aspect-Based Sentiment Analysis (ABSA)\n",
    "---\n",
    "In **Aspect-Based Sentiment Analysis (ABSA)**, the primary goal is to extract sentiment for specific aspects within a text, such as products, services, or features. To ensure accurate sentiment extraction, the text must be of sufficient quality. Text quality directly influences the effectiveness of ABSA models, and assessing text quality is crucial to improve aspect-level sentiment predictions.\n",
    "\n",
    "The **Text Quality Analysis (TQA)** process evaluates various features of the text that may affect ABSA performance. It focuses on syntactic and lexical features that help determine the relevance, richness, and clarity of the content in relation to specific aspects.\n",
    "\n",
    "Key **requirements for ABSA-based text quality** are:\n",
    "\n",
    "- **Aspect Identification**: Clear identification of aspects (e.g., product features or services).\n",
    "- **Aspect-Verb Pairing**: The relationship between aspects and verbs (actions related to aspects).\n",
    "- **Text Coherence and Complexity**: Well-formed sentences with a manageable level of complexity.\n",
    "- **Lexical Density and Content Richness**: The degree to which the content reflects substantive, content-rich words.\n",
    "\n",
    "These requirements are captured by **syntactic measures** like noun phrases, verb phrases, aspect-verb pairs, and additional features like review length, lexical density, and dependency depth. Together, these features inform the quality of text in the context of ABSA tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Measures of Text Quality and Their Weights\n",
    "---\n",
    "The following **syntactic features** and their **weights** quantify the quality of a given text for ABSA. Each measure contributes to the overall **Text Quality Analysis (TQA)** score, which is a weighted sum of these features.\n",
    "\n",
    "$$\n",
    "\\text{TQA Score}=\\sum_{i} \\left( \\text{Measure Score}_i \\times \\text{Weight}_i \\right)\n",
    "$$\n",
    "\n",
    "Here’s the run-through of each measure, its weight, and its impact on the overall TQA score:\n",
    "\n",
    "- **Aspect-Verb Pairs**: This measure identifies the relationship between **aspects** (e.g., product features) and **verbs** (actions related to those aspects). A higher number of aspect-verb pairs indicates that the text is highly relevant to ABSA, making it the most heavily weighted feature in TQA with a weight of **4**.    \n",
    "- **Noun Phrases**: Noun phrases help identify **key entities** and aspects in the text. The weight of **2.5** reflects the importance of rich, aspect-relevant content in generating accurate sentiment scores.    \n",
    "- **Verb Phrases**: Verb phrases identify the **actions or states** related to aspects. This has a weight of **2**, highlighting the importance of these phrases for understanding sentiment.    \n",
    "- **Adjective Count**: Adjectives capture **descriptive sentiment**, reflecting the **quality and intensity** of the sentiments expressed. It is weighted at **1.5**, indicating its moderate to high importance in sentiment analysis.    \n",
    "- **Lexical Density**: This measure quantifies the amount of **content-rich vocabulary** used in the text. High lexical density indicates that the text contains more **substantive content**, making it more informative for sentiment analysis. It is weighted at **1.5**.    \n",
    "- **Noun Count**: The count of **nouns** provides insights into the **syntactic structure** and **content** of the text. It is weighted at **1**, reflecting its importance in the analysis of textual richness.    \n",
    "- **Verb Count**: The count of **verbs** helps capture the **action-oriented components** of the text. Like the noun count, it is weighted at **1**.    \n",
    "- **Review Length**: Longer reviews generally provide more context for sentiment analysis, but excessive length can introduce noise. It is weighted at **1**, reflecting its moderate importance in sentiment prediction.    \n",
    "- **Dependency Depth**: This measure indicates the **complexity** of sentence structure. Although sentence complexity can affect sentiment extraction, it plays a secondary role in ABSA and is weighted at **1**.    \n",
    "- **Adverb Count**: Adverbs modify verbs or adjectives, helping capture nuances in sentiment. With a weight of **0.75**, it plays a supportive role in sentiment analysis.    \n",
    "- **Adverbial Phrases**: These phrases provide additional **modification** of actions, aspects, and sentiments. They are weighted at **0.5**, as they are considered less important than noun and verb phrases in ABSA tasks.\n",
    "\n",
    "**Summary of Weights:**\n",
    "\n",
    "| Measure           | Weight |\n",
    "|-------------------|--------|\n",
    "| Aspect-Verb Pairs | 4      |\n",
    "| Noun Phrases      | 2.5    |\n",
    "| Verb Phrases      | 2      |\n",
    "| Adjective Count   | 1.5    |\n",
    "| Lexical Density   | 1.5    |\n",
    "| Noun Count        | 1      |\n",
    "| Verb Count        | 1      |\n",
    "| Review Length     | 1      |\n",
    "| Dependency Depth  | 1      |\n",
    "| Adverb Count      | 0.75   |\n",
    "| Adverbial Phrases | 0.5    |\n",
    "\n",
    "## Text Quality Analysis Pipeline\n",
    "With that, the text quality analysis (TQA) processing pipeline computes these text quality metrics at scale.\n",
    "\n",
    "The pipeline leverages:     \n",
    "- Dask for distributed data processing, enabling efficient computation over large text datasets.\n",
    "- spaCy for NLP tasks, including dependency parsing and part-of-speech (POS) tagging.\n",
    "\n",
    "The pipeline follows these steps:    \n",
    "- Dataset Configuration: Define the source and target dataset configurations.\n",
    "- Pipeline Construction: Instantiate the TQAStageBuilder and configure it for Dask processing.\n",
    "- Execution: Run the TQAStage, applying text analysis and feature extraction.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "hide-cell"
    ]
   },
   "source": [
    "### Import Libraries\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": [
     "hide-cell"
    ]
   },
   "outputs": [],
   "source": [
    "\n",
    "from genailab.setup import auto_wire_container\n",
    "from genailab.core.dtypes import DFType\n",
    "from genailab.infra.utils.file.fileset import FileFormat\n",
    "from genailab.asset.dataset.config import DatasetConfig\n",
    "from genailab.flow.dataprep.tqa.builder import TQAStageBuilder\n",
    "from genailab.asset.dataset.config import DatasetConfig\n",
    "from genailab.core.flow import PhaseDef, StageDef\n",
    "\n",
    "\n",
    "# Wire container\n",
    "container = auto_wire_container()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the Source and Target Dataset Configurations\n",
    "---\n",
    "The source dataset represents the cleaned text data, while the target dataset will store the extracted text quality features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Source Dataset Configuration\n",
    "source_config = DatasetConfig(\n",
    "    phase=PhaseDef.DATAPREP,\n",
    "    stage=StageDef.CLEAN,\n",
    "    name=\"review\",\n",
    "    file_format=FileFormat.PARQUET,\n",
    "    asset_type=\"dataset\",\n",
    "    dftype=DFType.PANDAS,\n",
    ")\n",
    "\n",
    "# Target Dataset Configuration\n",
    "target_config = DatasetConfig(\n",
    "    phase=PhaseDef.DATAPREP,\n",
    "    stage=StageDef.TQA,\n",
    "    name=\"review\",\n",
    "    file_format=FileFormat.PARQUET,\n",
    "    asset_type=\"dataset\",\n",
    "    dftype=DFType.PANDAS,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Construct the TQA Pipeline\n",
    "---\n",
    "We use the TQAStageBuilder to configure a Dask-powered text quality analysis pipeline with:\n",
    "\n",
    "- Normalization enabled (ensures robust feature scaling).\n",
    "- Batch processing (improves efficiency for large datasets)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "stage = (\n",
    "    TQAStageBuilder()\n",
    "        .with_dask(normalized=True, batched=True)\n",
    "        .build(source_config=source_config, target_config=target_config))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run the Pipeline\n",
    "---\n",
    "Once the pipeline is built, we execute it to compute text quality features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "# ============================================================================== #\n",
      "#             Text Quality Analysis Stage Mon, 03 Feb 2025 06:02:54              #\n",
      "# ============================================================================== #\n",
      "\n",
      "____________________________________________________________________________\n",
      "Text Quality Analysis Stage             06:02:54    06:08:16    5.0 minutes and 21.39 seconds\n",
      "\n",
      "\n",
      "# ============================================================================ #\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dataset = stage.run(force=FORCE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validate the Dataset\n",
    "---\n",
    "Let's ensure that the text quality measures have been added and the dataset is in the repository."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dataset Profile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Column</th>\n",
       "      <th>DataType</th>\n",
       "      <th>Complete</th>\n",
       "      <th>Null</th>\n",
       "      <th>Completeness</th>\n",
       "      <th>Unique</th>\n",
       "      <th>Duplicate</th>\n",
       "      <th>Uniqueness</th>\n",
       "      <th>Size (Bytes)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>id</td>\n",
       "      <td>string[python]</td>\n",
       "      <td>4812</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4812</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>322866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>app_id</td>\n",
       "      <td>string[python]</td>\n",
       "      <td>4812</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1866</td>\n",
       "      <td>2946</td>\n",
       "      <td>0.387781</td>\n",
       "      <td>320011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>app_name</td>\n",
       "      <td>string[python]</td>\n",
       "      <td>4812</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1866</td>\n",
       "      <td>2946</td>\n",
       "      <td>0.387781</td>\n",
       "      <td>384993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>category_id</td>\n",
       "      <td>string[python]</td>\n",
       "      <td>4812</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>14</td>\n",
       "      <td>4798</td>\n",
       "      <td>0.002909</td>\n",
       "      <td>293532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>author</td>\n",
       "      <td>string[python]</td>\n",
       "      <td>4812</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4811</td>\n",
       "      <td>1</td>\n",
       "      <td>0.999792</td>\n",
       "      <td>370524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>rating</td>\n",
       "      <td>Int64</td>\n",
       "      <td>4812</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5</td>\n",
       "      <td>4807</td>\n",
       "      <td>0.001039</td>\n",
       "      <td>43308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>content</td>\n",
       "      <td>string[python]</td>\n",
       "      <td>4812</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4809</td>\n",
       "      <td>3</td>\n",
       "      <td>0.999377</td>\n",
       "      <td>1198458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>vote_sum</td>\n",
       "      <td>Int64</td>\n",
       "      <td>4812</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>13</td>\n",
       "      <td>4799</td>\n",
       "      <td>0.002702</td>\n",
       "      <td>43308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>vote_count</td>\n",
       "      <td>Int64</td>\n",
       "      <td>4812</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>17</td>\n",
       "      <td>4795</td>\n",
       "      <td>0.003533</td>\n",
       "      <td>43308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>date</td>\n",
       "      <td>datetime64[ns, UTC]</td>\n",
       "      <td>4812</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4812</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>38496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>category</td>\n",
       "      <td>string[python]</td>\n",
       "      <td>4812</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>14</td>\n",
       "      <td>4798</td>\n",
       "      <td>0.002909</td>\n",
       "      <td>329434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>noun_count</td>\n",
       "      <td>Float64</td>\n",
       "      <td>4812</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>66</td>\n",
       "      <td>4746</td>\n",
       "      <td>0.013716</td>\n",
       "      <td>43308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>verb_count</td>\n",
       "      <td>Float64</td>\n",
       "      <td>4812</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>56</td>\n",
       "      <td>4756</td>\n",
       "      <td>0.011638</td>\n",
       "      <td>43308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>adjective_count</td>\n",
       "      <td>Float64</td>\n",
       "      <td>4812</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>29</td>\n",
       "      <td>4783</td>\n",
       "      <td>0.006027</td>\n",
       "      <td>43308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>adverb_count</td>\n",
       "      <td>Float64</td>\n",
       "      <td>4812</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>29</td>\n",
       "      <td>4783</td>\n",
       "      <td>0.006027</td>\n",
       "      <td>43308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>aspect_verb_pairs</td>\n",
       "      <td>Float64</td>\n",
       "      <td>4812</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>29</td>\n",
       "      <td>4783</td>\n",
       "      <td>0.006027</td>\n",
       "      <td>43308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>noun_phrases</td>\n",
       "      <td>Float64</td>\n",
       "      <td>4812</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>51</td>\n",
       "      <td>4761</td>\n",
       "      <td>0.010599</td>\n",
       "      <td>43308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>verb_phrases</td>\n",
       "      <td>Float64</td>\n",
       "      <td>4812</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>54</td>\n",
       "      <td>4758</td>\n",
       "      <td>0.011222</td>\n",
       "      <td>43308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>adverbial_phrases</td>\n",
       "      <td>Float64</td>\n",
       "      <td>4812</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8</td>\n",
       "      <td>4804</td>\n",
       "      <td>0.001663</td>\n",
       "      <td>43308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>review_length</td>\n",
       "      <td>Float64</td>\n",
       "      <td>4812</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>207</td>\n",
       "      <td>4605</td>\n",
       "      <td>0.043017</td>\n",
       "      <td>43308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>lexical_density</td>\n",
       "      <td>Float64</td>\n",
       "      <td>4812</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>776</td>\n",
       "      <td>4036</td>\n",
       "      <td>0.161264</td>\n",
       "      <td>43308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>dependency_depth</td>\n",
       "      <td>Float64</td>\n",
       "      <td>4812</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>182</td>\n",
       "      <td>4630</td>\n",
       "      <td>0.037822</td>\n",
       "      <td>43308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>tqa_score</td>\n",
       "      <td>Float64</td>\n",
       "      <td>4812</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4701</td>\n",
       "      <td>111</td>\n",
       "      <td>0.976933</td>\n",
       "      <td>43308</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Column             DataType  Complete  Null  Completeness  \\\n",
       "0                  id       string[python]      4812     0           1.0   \n",
       "1              app_id       string[python]      4812     0           1.0   \n",
       "2            app_name       string[python]      4812     0           1.0   \n",
       "3         category_id       string[python]      4812     0           1.0   \n",
       "4              author       string[python]      4812     0           1.0   \n",
       "5              rating                Int64      4812     0           1.0   \n",
       "6             content       string[python]      4812     0           1.0   \n",
       "7            vote_sum                Int64      4812     0           1.0   \n",
       "8          vote_count                Int64      4812     0           1.0   \n",
       "9                date  datetime64[ns, UTC]      4812     0           1.0   \n",
       "10           category       string[python]      4812     0           1.0   \n",
       "11         noun_count              Float64      4812     0           1.0   \n",
       "12         verb_count              Float64      4812     0           1.0   \n",
       "13    adjective_count              Float64      4812     0           1.0   \n",
       "14       adverb_count              Float64      4812     0           1.0   \n",
       "15  aspect_verb_pairs              Float64      4812     0           1.0   \n",
       "16       noun_phrases              Float64      4812     0           1.0   \n",
       "17       verb_phrases              Float64      4812     0           1.0   \n",
       "18  adverbial_phrases              Float64      4812     0           1.0   \n",
       "19      review_length              Float64      4812     0           1.0   \n",
       "20    lexical_density              Float64      4812     0           1.0   \n",
       "21   dependency_depth              Float64      4812     0           1.0   \n",
       "22          tqa_score              Float64      4812     0           1.0   \n",
       "\n",
       "    Unique  Duplicate  Uniqueness  Size (Bytes)  \n",
       "0     4812          0    1.000000        322866  \n",
       "1     1866       2946    0.387781        320011  \n",
       "2     1866       2946    0.387781        384993  \n",
       "3       14       4798    0.002909        293532  \n",
       "4     4811          1    0.999792        370524  \n",
       "5        5       4807    0.001039         43308  \n",
       "6     4809          3    0.999377       1198458  \n",
       "7       13       4799    0.002702         43308  \n",
       "8       17       4795    0.003533         43308  \n",
       "9     4812          0    1.000000         38496  \n",
       "10      14       4798    0.002909        329434  \n",
       "11      66       4746    0.013716         43308  \n",
       "12      56       4756    0.011638         43308  \n",
       "13      29       4783    0.006027         43308  \n",
       "14      29       4783    0.006027         43308  \n",
       "15      29       4783    0.006027         43308  \n",
       "16      51       4761    0.010599         43308  \n",
       "17      54       4758    0.011222         43308  \n",
       "18       8       4804    0.001663         43308  \n",
       "19     207       4605    0.043017         43308  \n",
       "20     776       4036    0.161264         43308  \n",
       "21     182       4630    0.037822         43308  \n",
       "22    4701        111    0.976933         43308  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.profile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dataset Sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>app_id</th>\n",
       "      <th>app_name</th>\n",
       "      <th>category_id</th>\n",
       "      <th>author</th>\n",
       "      <th>rating</th>\n",
       "      <th>content</th>\n",
       "      <th>vote_sum</th>\n",
       "      <th>vote_count</th>\n",
       "      <th>date</th>\n",
       "      <th>...</th>\n",
       "      <th>adjective_count</th>\n",
       "      <th>adverb_count</th>\n",
       "      <th>aspect_verb_pairs</th>\n",
       "      <th>noun_phrases</th>\n",
       "      <th>verb_phrases</th>\n",
       "      <th>adverbial_phrases</th>\n",
       "      <th>review_length</th>\n",
       "      <th>lexical_density</th>\n",
       "      <th>dependency_depth</th>\n",
       "      <th>tqa_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10019409512</td>\n",
       "      <td>1380362212</td>\n",
       "      <td>GALATEA: Novels &amp; Audiobooks</td>\n",
       "      <td>6018</td>\n",
       "      <td>c011c66aae3e668b150e</td>\n",
       "      <td>5</td>\n",
       "      <td>i love it but the chapter and waiting hours fo...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2023-06-10 15:09:00+00:00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.639057</td>\n",
       "      <td>3.675326</td>\n",
       "      <td>2.70805</td>\n",
       "      <td>16.176484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10027124164</td>\n",
       "      <td>1380362212</td>\n",
       "      <td>GALATEA: Novels &amp; Audiobooks</td>\n",
       "      <td>6018</td>\n",
       "      <td>5a2741393dd20358b609</td>\n",
       "      <td>5</td>\n",
       "      <td>i like the books that i have read so far if th...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2023-06-12 20:14:00+00:00</td>\n",
       "      <td>...</td>\n",
       "      <td>1.386294</td>\n",
       "      <td>1.098612</td>\n",
       "      <td>1.609438</td>\n",
       "      <td>2.079442</td>\n",
       "      <td>2.302585</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>3.912023</td>\n",
       "      <td>3.683251</td>\n",
       "      <td>3.931826</td>\n",
       "      <td>37.360035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10036938913</td>\n",
       "      <td>1076402606</td>\n",
       "      <td>Libby, by OverDrive</td>\n",
       "      <td>6018</td>\n",
       "      <td>46117640263dddac9294</td>\n",
       "      <td>5</td>\n",
       "      <td>i have read dozens upon dozens of books after ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2023-06-15 17:01:00+00:00</td>\n",
       "      <td>...</td>\n",
       "      <td>1.94591</td>\n",
       "      <td>1.098612</td>\n",
       "      <td>1.386294</td>\n",
       "      <td>1.609438</td>\n",
       "      <td>2.079442</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>3.850148</td>\n",
       "      <td>3.795001</td>\n",
       "      <td>3.850148</td>\n",
       "      <td>35.486515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10047764706</td>\n",
       "      <td>1076402606</td>\n",
       "      <td>Libby, by OverDrive</td>\n",
       "      <td>6018</td>\n",
       "      <td>a0e95f8868233439444d</td>\n",
       "      <td>5</td>\n",
       "      <td>happy with the app i use it primarily for audi...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2023-06-18 19:40:00+00:00</td>\n",
       "      <td>...</td>\n",
       "      <td>1.609438</td>\n",
       "      <td>1.386294</td>\n",
       "      <td>1.098612</td>\n",
       "      <td>1.94591</td>\n",
       "      <td>1.386294</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>3.555348</td>\n",
       "      <td>3.987894</td>\n",
       "      <td>3.583519</td>\n",
       "      <td>32.536492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10064456025</td>\n",
       "      <td>1535748732</td>\n",
       "      <td>Storyroom - Webnovel &amp; Story</td>\n",
       "      <td>6018</td>\n",
       "      <td>bb43c451a876165c2abf</td>\n",
       "      <td>1</td>\n",
       "      <td>im going to be honest the books are really gre...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2023-06-23 15:23:00+00:00</td>\n",
       "      <td>...</td>\n",
       "      <td>2.197225</td>\n",
       "      <td>1.609438</td>\n",
       "      <td>1.609438</td>\n",
       "      <td>2.302585</td>\n",
       "      <td>2.639057</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.418841</td>\n",
       "      <td>3.804492</td>\n",
       "      <td>4.477337</td>\n",
       "      <td>41.925267</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            id      app_id                      app_name category_id  \\\n",
       "0  10019409512  1380362212  GALATEA: Novels & Audiobooks        6018   \n",
       "1  10027124164  1380362212  GALATEA: Novels & Audiobooks        6018   \n",
       "2  10036938913  1076402606           Libby, by OverDrive        6018   \n",
       "3  10047764706  1076402606           Libby, by OverDrive        6018   \n",
       "4  10064456025  1535748732  Storyroom - Webnovel & Story        6018   \n",
       "\n",
       "                 author rating  \\\n",
       "0  c011c66aae3e668b150e      5   \n",
       "1  5a2741393dd20358b609      5   \n",
       "2  46117640263dddac9294      5   \n",
       "3  a0e95f8868233439444d      5   \n",
       "4  bb43c451a876165c2abf      1   \n",
       "\n",
       "                                             content vote_sum vote_count  \\\n",
       "0  i love it but the chapter and waiting hours fo...        0          0   \n",
       "1  i like the books that i have read so far if th...        0          0   \n",
       "2  i have read dozens upon dozens of books after ...        0          0   \n",
       "3  happy with the app i use it primarily for audi...        0          0   \n",
       "4  im going to be honest the books are really gre...        0          0   \n",
       "\n",
       "                       date  ... adjective_count adverb_count  \\\n",
       "0 2023-06-10 15:09:00+00:00  ...             0.0          0.0   \n",
       "1 2023-06-12 20:14:00+00:00  ...        1.386294     1.098612   \n",
       "2 2023-06-15 17:01:00+00:00  ...         1.94591     1.098612   \n",
       "3 2023-06-18 19:40:00+00:00  ...        1.609438     1.386294   \n",
       "4 2023-06-23 15:23:00+00:00  ...        2.197225     1.609438   \n",
       "\n",
       "  aspect_verb_pairs noun_phrases verb_phrases adverbial_phrases review_length  \\\n",
       "0               0.0     0.693147     0.693147               0.0      2.639057   \n",
       "1          1.609438     2.079442     2.302585          0.693147      3.912023   \n",
       "2          1.386294     1.609438     2.079442          0.693147      3.850148   \n",
       "3          1.098612      1.94591     1.386294          0.693147      3.555348   \n",
       "4          1.609438     2.302585     2.639057               0.0      4.418841   \n",
       "\n",
       "  lexical_density dependency_depth  tqa_score  \n",
       "0        3.675326          2.70805  16.176484  \n",
       "1        3.683251         3.931826  37.360035  \n",
       "2        3.795001         3.850148  35.486515  \n",
       "3        3.987894         3.583519  32.536492  \n",
       "4        3.804492         4.477337  41.925267  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.dataframe.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dataset Repository"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "repo = container.io.repo()\n",
    "ds = repo.get(asset_id=dataset.asset_id)\n",
    "assert ds == dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great! Now that we've confirmed the dataset has been successfully processed, we have a set of **text quality analysis** metrics that we can use for instance selection during the feature engineering stage.\n",
    "Next, we transition to **sentiment analysis at the review level**. In this phase, we will analyze the overall **sentiment** of each review."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "genai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
