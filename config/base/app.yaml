#!/usr/bin/env python3
# -*- coding:utf-8 -*-
# ================================================================================================ #
# Project    : AppVoCAI-Discover                                                                   #
# Version    : 0.1.0                                                                               #
# Python     : 3.10.14                                                                             #
# Filename   : /config/base/app.yaml                                                               #
# ------------------------------------------------------------------------------------------------ #
# Author     : John James                                                                          #
# Email      : john@variancexplained.com                                                           #
# URL        : https://github.com/variancexplained/appvocai-discover                               #
# ------------------------------------------------------------------------------------------------ #
# Created    : Monday September 9th 2024 11:24:51 am                                               #
# Modified   : Thursday January 23rd 2025 01:23:07 am                                              #
# ------------------------------------------------------------------------------------------------ #
# License    : MIT License                                                                         #
# Copyright  : (c) 2024 John James                                                                 #
# ================================================================================================ #
# ------------------------------------------------------------------------------------------------ #
#                                           SETUP                                                  #
# ------------------------------------------------------------------------------------------------ #
setup:
  dataset:
    phase: dataprep
    stage: raw
    name: review
    filepath: data/stage/prod/reviews
    dftype: pandas
    file_format: parquet
# ------------------------------------------------------------------------------------------------ #
#                                          LOGGING                                                 #
# ------------------------------------------------------------------------------------------------ #
logging:
  disable_existing_loggers: false
  formatters:
    console:
      datefmt: '%m/%d/%Y %I:%M:%S %p'
      format: '[%(asctime)s] [%(levelname)s] [%(name)s] [%(funcName)s] : %(message)s'
    file:
      datefmt: '%m/%d/%Y %I:%M:%S %p'
      format: '[%(asctime)s] [%(levelname)s] [%(name)s] [%(module)s] [%(funcName)s]
        : %(message)s'
  handlers:
    console:
      class: logging.StreamHandler
      formatter: console
      level: INFO # Default, possibly overridden in environment config
      stream: ext://sys.stderr
    file:
      backupCount: 0
      class: logging.handlers.TimedRotatingFileHandler
      filename: TBD # Override in environment specific configurations
      formatter: file
      interval: 1
      level: DEBUG # Default, possibly overridden in environment config
      when: midnight
  loggers:
    py4j:  # Add this block to suppress py4j logging
      level: ERROR
      handlers:
        - console
        - file
      propagate: false  # Prevent py4j logs from being propagated to the root logger
  root:
    handlers:
    - console
    - file
    level: DEBUG # Default, possibly overridden in environment config
  version: 1
# ------------------------------------------------------------------------------------------------ #
#                                DATA PROCESSING ENGINE                                            #
# ------------------------------------------------------------------------------------------------ #
spark:
  memory: "96g"
  retries: 3
  parquet_block_size: 1073741824 # 1 GB Default
# ------------------------------------------------------------------------------------------------ #
#                                       IO CONFIG                                                  #
# ------------------------------------------------------------------------------------------------ #
io:
  format: parquet
  pandas:
    csv:
      read_kwargs:
        dtype:
          id: string
          app_id: string
          app_name: string
          category_id: category
          category: category
          author: string
          rating: int16
          content: string
          vote_count: int64
          vote_sum: int64
        encoding: utf-8
        index_col: False
        lineterminator: "\n"
        parse_dates:
         - date
      write_kwargs:
        index: False
        mode: x
    parquet:
      read_kwargs:
        engine: pyarrow
      write_kwargs:
        engine: pyarrow
        compression: snappy
        index: False
        existing_data_behavior: delete_matching
        row_group_size: 1073741824 # 1 GB
        partition_cols:
          - category
  spark:
    csv:
      read_kwargs:
        encoding: UTF-8
        header: True
        inferSchema: True
      write_kwargs:
        header: True
        mode: error
    parquet:
      read_kwargs:
        encoding: UTF-8
        header: True
        inferSchema: True
      write_kwargs:
        mode: error
        partitionBy:
          - category
  sparknlp:
    csv:
      read_kwargs:
        encoding: UTF-8
        header: True
        inferSchema: True
      write_kwargs:
        header: True
        mode: error
    parquet:
      read_kwargs:
        encoding: UTF-8
        header: True
        inferSchema: True
      write_kwargs:
        mode: error
        partitionBy:
          - category

# ------------------------------------------------------------------------------------------------ #
#                                      OPERATORS                                                   #
# ------------------------------------------------------------------------------------------------ #
ops:
  convert:
    to_pandas_threshold: 1073741824  # 1 GB
    to_spark_threshold: 10737418240 # 10 GB

# ------------------------------------------------------------------------------------------------ #
#                                         DQA                                                      #
# ------------------------------------------------------------------------------------------------ #
dqa:
  dqs:
    weights:
      completeness: 0.25
      validity: 0.25
      relevance: 0.2
      uniqueness: 0.15
      privacy: 0.15
  completeness:
    weights:
      row: 0.7
      category: 0.3
    columns:
      category: category
  validity:
    weights:
      rating: 0.2
      category: 0.1
      review: 0.6
      date: 0.1
    columns:
      rating_validity: dqa_validity_invalid_rating
      category_validity: dqa_validity_invalid_category
      date_validity: dqa_validity_invalid_review_date
      review_validity:
      - dqa_validity_contains_ctrl_chars
      - dqa_validity_contains_accents
      - dqa_validity_contains_html_chars
      - dqa_validity_contains_excess_whitespace
      - dqa_validity_contains_irrelevant_special_chars
      - dqa_validity_contains_excess_special_chars
      - dqa_validity_contains_elongation
      - dqa_validity_contains_excess_sequence_repetition
      - dqa_validity_contains_excess_word_repetition
      - dqa_validity_contains_excess_phrase_repetition
  relevance:
    weights:
      language: 0.4
      review_length: 0.6
    columns:
      language:
      - dqa_relevance_contains_non_english_app_name
      - dqa_relevance_contains_non_english_text
      review_length: dqa_relevance_short_review
  uniqueness:
    weights:
      row: 0.3
      review_id: 0.2
      review: 0.5
    columns:
      row: dqa_uniqueness_duplicate_row
      review_id:  dqa_uniqueness_duplicate_review_id
      review: dqa_uniqueness_duplicate_review
  privacy:
    columns:
      - dqa_privacy_contains_url
      - dqa_privacy_contains_email
      - dqa_privacy_contains_phone







