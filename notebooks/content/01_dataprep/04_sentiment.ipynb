{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": [
     "remove-cell"
    ]
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "if \"jbook\" in os.getcwd():\n",
    "    os.chdir(os.path.abspath(os.path.join(\"../..\")))\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "FORCE = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment Classification\n",
    "This stage leverages a **DistilBERT-based Sentiment Classification Model**, specifically the `tabularisai/robust-sentiment-analysis` model, to perform sentiment analysis. The goal is to efficiently analyze and classify sentiment within a dataset for the purposes of **Data Quality Assessment (DQA)** and **Exploratory Data Analysis (EDA)**. \n",
    "\n",
    "## Model Overview\n",
    "- **Model Name**: `tabularisai/robust-sentiment-analysis`\n",
    "- **Base Model**: `distilbert/distilbert-base-uncased`\n",
    "- **Task**: Text Classification (Sentiment Analysis)\n",
    "- **Language**: English\n",
    "- **Number of Classes**: 5 sentiment categories:\n",
    "  - **Very Negative**\n",
    "  - **Negative**\n",
    "  - **Neutral**\n",
    "  - **Positive**\n",
    "  - **Very Positive**\n",
    "\n",
    "## Model Description\n",
    "This model is a fine-tuned version of `distilbert-base-uncased`, optimized for sentiment analysis using synthetic data generated by cutting-edge language models like **Llama3.1** and **Gemma2**. By training exclusively on synthetic data, the model has been exposed to a diverse range of sentiment expressions, which enhances its ability to generalize across different use cases\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "hide-cell"
    ]
   },
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": [
     "hide-cell"
    ]
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "from genailab.core.flow import PhaseDef\n",
    "from genailab.setup import auto_wire_container\n",
    "from genailab.asset.dataset.config import DatasetConfig\n",
    "from genailab.flow.dataprep.sa.builder import SentimentAnalysisStageBuilder\n",
    "from genailab.core.dtypes import DFType\n",
    "from genailab.core.flow import StageDef\n",
    "from genailab.infra.utils.file.fileset import FileFormat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": [
     "hide-cell"
    ]
   },
   "outputs": [],
   "source": [
    "# Register `tqdm` with pandas\n",
    "tqdm.pandas()\n",
    "# Wire container\n",
    "container = auto_wire_container()\n",
    "# Pandas\n",
    "pd.options.display.max_colwidth = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentiment Classification Task\n",
    "The `SentimentClassificationTask` class performs sentiment analysis on text data using the `tabularisai/robust-sentiment-analysis` pre-trained transformer model. It is built to handle large-scale text data efficiently and is optimized for execution on GPU when available.\n",
    "\n",
    "**Key Technical Aspects**:\n",
    "\n",
    "1. **Model Loading**: The transformer is loaded using the Hugging Face `transformers` library, leveraging both the `AutoTokenizer` for text tokenization and `AutoModelForSequenceClassification` for sentiment classification.\n",
    "2. **Hardware Optimization**: The class supports GPU acceleration through PyTorch. It checks for the availability of a CUDA-compatible GPU and moves the model and data to the GPU if available. This significantly speeds up inference, making it suitable for large datasets.\n",
    "3. **Text Preprocessing and Tokenization**: Text data is preprocessed and tokenized using the `AutoTokenizer`, which converts text into input tensors that the model can process. The inputs are truncated or padded to a maximum sequence length of 512 tokens, ensuring consistency in input size.\n",
    "4. **Memory Management**: The class uses `torch.cuda.empty_cache()` to clear CUDA memory before loading the model, optimizing memory usage and preventing potential out-of-memory errors on the GPU.\n",
    "5. **Sentiment Prediction**: The `predict_sentiment` method performs inference using `torch.no_grad()` to disable gradient calculation, reducing memory consumption and speeding up computations. It calculates class probabilities using the `softmax` function and maps the predicted class index to a sentiment label.\n",
    "6. **Caching Mechanism**: The class constructs a cache file path using environment-specific settings, making it possible to store and reuse sentiment analysis results efficiently. This can help avoid redundant computations and improve the overall performance of the data pipeline.\n",
    "7. **Integration with DataFrames**: The class operates on pandas DataFrames, applying sentiment analysis to each entry in the specified text column using the `progress_apply` method, which provides a progress bar for monitoring the processing status.\n",
    "\n",
    "The code is included in the following expandable cell.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": [
     "hide-cell"
    ]
   },
   "outputs": [],
   "source": [
    "# %load -r 19-210 genailab/flow/dataprep/sa/task.py\n",
    "import os\n",
    "import warnings\n",
    "from typing import Type\n",
    "\n",
    "import pandas as pd\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
    "\n",
    "from genailab.flow.base.task import Task\n",
    "from genailab.infra.service.logging.task import task_logger\n",
    "from genailab.infra.utils.file.io import IOService\n",
    "\n",
    "# ------------------------------------------------------------------------------------------------ #\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "os.environ[\"PYTHONWARNINGS\"] = \"ignore\"\n",
    "tqdm.pandas()\n",
    "\n",
    "\n",
    "# ------------------------------------------------------------------------------------------------ #\n",
    "class SentimentClassificationTask(Task):\n",
    "    \"\"\"\n",
    "    Task for performing sentiment analysis on text data in a specified column of a Pandas DataFrame.\n",
    "\n",
    "    This task uses a pre-trained model to predict sentiment for text in the specified column and\n",
    "    stores the sentiment predictions in a new column. Results are cached to a file to avoid reprocessing.\n",
    "    It supports execution on GPUs or local devices depending on the configuration.\n",
    "\n",
    "    Args:\n",
    "        cache_filepath (str): Path to the cache file for storing or loading sentiment predictions.\n",
    "        column (str): The name of the column in the DataFrame containing text data for sentiment analysis.\n",
    "            Defaults to \"content\".\n",
    "        new_column (str): The name of the column to store sentiment predictions. Defaults to \"sentiment\".\n",
    "        model_name (str): The name of the pre-trained model to use for sentiment analysis. Defaults to\n",
    "            \"tabularisai/robust-sentiment-analysis\".\n",
    "        device_local (bool): Indicates whether to execute the task on local devices. Defaults to False.\n",
    "\n",
    "    Methods:\n",
    "        run(data: pd.DataFrame) -> pd.DataFrame:\n",
    "            Executes the sentiment analysis task, using a cache if available. If not, it predicts sentiment\n",
    "            for the text column and caches the results.\n",
    "        predict_sentiment(text: str) -> str:\n",
    "            Predicts sentiment for a given text string.\n",
    "        _load_model_tokenizer_to_device() -> None:\n",
    "            Loads the model, tokenizer, and device for performing sentiment analysis.\n",
    "        _run(data: pd.DataFrame) -> pd.DataFrame:\n",
    "            Executes the model inference for sentiment prediction and writes the results to the cache.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        cache_filepath: str,\n",
    "        column=\"content\",\n",
    "        new_column=\"sentiment\",\n",
    "        model_name: str = \"tabularisai/robust-sentiment-analysis\",\n",
    "        device_local: bool = False,\n",
    "        io_cls: Type[IOService] = IOService,\n",
    "        **kwargs,\n",
    "    ):\n",
    "        super().__init__(**kwargs)\n",
    "        self._column = column\n",
    "        self._new_column = f\"{self.stage.id}_{new_column}\"\n",
    "        self._model_name = model_name\n",
    "        self._cache_filepath = cache_filepath\n",
    "        self._device_local = device_local\n",
    "        self._io = io_cls()\n",
    "\n",
    "        # Model, tokenizer, and device are initialized as None and will be loaded later\n",
    "        self._model = None\n",
    "        self._tokenizer = None\n",
    "        self._device = None\n",
    "\n",
    "    @task_logger\n",
    "    def run(self, data: pd.DataFrame) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Executes the sentiment analysis task on the input DataFrame.\n",
    "\n",
    "        This method first attempts to read sentiment predictions from a cache file. If the cache\n",
    "        is not available or not valid, it performs sentiment analysis using the pre-trained model\n",
    "        and writes the results to the cache. Sentiment predictions are stored in the specified\n",
    "        `new_column` of the DataFrame.\n",
    "\n",
    "        Args:\n",
    "            data (pd.DataFrame): The input DataFrame containing the text data.\n",
    "\n",
    "        Returns:\n",
    "            pd.DataFrame: The DataFrame with sentiment predictions added to the specified column.\n",
    "\n",
    "        Raises:\n",
    "            FileNotFoundError: If the cache is not found or the task is run locally without a GPU.\n",
    "            Exception: For any other unexpected errors.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            cache = self._io.read(filepath=self._cache_filepath, lineterminator=\"\\n\")\n",
    "            cache[\"id\"] = cache[\"id\"].astype(\"string\")\n",
    "            data = data.merge(cache[[\"id\", self._new_column]], how=\"left\", on=\"id\")\n",
    "            return data\n",
    "        except (FileNotFoundError, TypeError):\n",
    "            if self._device_local:\n",
    "                return self._run(data=data)\n",
    "            else:\n",
    "                msg = (\n",
    "                    f\"Cache not found or not available. {self.__class__.__name__} is not \"\n",
    "                    \"supported on local devices. Try running on Kaggle, Colab, or AWS.\"\n",
    "                )\n",
    "                self._logger.error(msg)\n",
    "                raise FileNotFoundError(msg)\n",
    "        except Exception as e:\n",
    "            msg = f\"Unknown exception encountered.\\n{e}\"\n",
    "            self._logger.exception(msg)\n",
    "            raise\n",
    "\n",
    "    def _run(self, data: pd.DataFrame) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Executes model inference for sentiment analysis and writes results to the cache.\n",
    "\n",
    "        This method processes the input DataFrame by applying sentiment predictions for each entry\n",
    "        in the specified text column. It uses parallel processing for efficient computation and\n",
    "        writes the results to the cache file.\n",
    "\n",
    "        Args:\n",
    "            data (pd.DataFrame): The input DataFrame containing the text data.\n",
    "\n",
    "        Returns:\n",
    "            pd.DataFrame: The DataFrame with sentiment predictions added to the specified column.\n",
    "        \"\"\"\n",
    "        torch.cuda.empty_cache()  # Clear CUDA memory to ensure sufficient space\n",
    "\n",
    "        # Load the device, model, and tokenizer\n",
    "        self._load_model_tokenizer_to_device()\n",
    "\n",
    "        # Apply sentiment prediction to each text entry\n",
    "        data[self._new_column] = data[self._column].progress_apply(\n",
    "            self.predict_sentiment\n",
    "        )\n",
    "\n",
    "        # Write results to the cache file\n",
    "        self._write_file(\n",
    "            filepath=self._cache_filepath, data=data[[\"id\", self._new_column]]\n",
    "        )\n",
    "\n",
    "        return data\n",
    "\n",
    "    def predict_sentiment(self, text: str) -> str:\n",
    "        \"\"\"\n",
    "        Predicts the sentiment of a given text string.\n",
    "\n",
    "        This method uses the loaded model and tokenizer to predict the sentiment of the input\n",
    "        text. It maps the model's output to a sentiment label.\n",
    "\n",
    "        Args:\n",
    "            text (str): The input text string.\n",
    "\n",
    "        Returns:\n",
    "            str: The predicted sentiment label, e.g., \"Positive\", \"Negative\", or \"Neutral\".\n",
    "        \"\"\"\n",
    "        with torch.no_grad():\n",
    "            inputs = self._tokenizer(\n",
    "                text.lower(),\n",
    "                return_tensors=\"pt\",\n",
    "                truncation=True,\n",
    "                padding=True,\n",
    "                max_length=512,\n",
    "            )\n",
    "            inputs = {key: value.to(self._device) for key, value in inputs.items()}\n",
    "            outputs = self._model(**inputs)\n",
    "            probabilities = torch.nn.functional.softmax(outputs.logits, dim=-1)\n",
    "            predicted_class = torch.argmax(probabilities, dim=-1).item()\n",
    "\n",
    "        sentiment_map = {\n",
    "            0: \"Very Negative\",\n",
    "            1: \"Negative\",\n",
    "            2: \"Neutral\",\n",
    "            3: \"Positive\",\n",
    "            4: \"Very Positive\",\n",
    "        }\n",
    "        return sentiment_map[predicted_class]\n",
    "\n",
    "    def _load_model_tokenizer_to_device(self) -> None:\n",
    "        \"\"\"\n",
    "        Loads the pre-trained model, tokenizer, and device for sentiment analysis.\n",
    "\n",
    "        This method selects the appropriate device (GPU or CPU), loads the tokenizer and model\n",
    "        based on the specified model name, and moves the model to the selected device.\n",
    "        \"\"\"\n",
    "        self._device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        self._tokenizer = AutoTokenizer.from_pretrained(self._model_name)\n",
    "        self._model = AutoModelForSequenceClassification.from_pretrained(\n",
    "            self._model_name\n",
    "        )\n",
    "        self._model.to(self._device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentiment Classification Pipeline\n",
    "Had we a few tensor processing units locally, we would be running the Sentiment Classification Pipeline. As we do not, the pipeline was run in the cloud and the output file is available in the staging library. Here, we'll merge the sentiment dataset into our main dataset and persist it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Source Dataset Configuration\n",
    "source_config = DatasetConfig(\n",
    "    phase=PhaseDef.DATAPREP,\n",
    "    stage=StageDef.TQA,\n",
    "    name=\"review\",\n",
    "    file_format=FileFormat.PARQUET,\n",
    "    dftype=DFType.PANDAS,\n",
    ")\n",
    "\n",
    "# Target Dataset Configuration\n",
    "target_config = DatasetConfig(\n",
    "    phase=PhaseDef.DATAPREP,\n",
    "    stage=StageDef.SENTIMENT,\n",
    "    name=\"review\",\n",
    "    file_format=FileFormat.PARQUET,\n",
    "    asset_type=\"dataset\",\n",
    "    dftype=DFType.PANDAS,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets run the stage pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[02/04/2025 03:09:19 AM] [DEBUG] [genailab.infra.persist.repo.object.rao.RAO] [__init__] : RAO created at workspace/test/datasets/ral/\n",
      "[02/04/2025 03:09:19 AM] [DEBUG] [genailab.infra.persist.repo.object.dao.DAO] [__init__] : DAO created at workspace/test/datasets/dal/\n",
      "[02/04/2025 03:09:21 AM] [DEBUG] [genailab.flow.base.stage.SentimentAnalysisStage] [_fresh_cache_exists] : The target dataset cache for Data Preparation Phase/Sentiment Analysis Stage exists in the repository.\n",
      "[02/04/2025 03:09:21 AM] [DEBUG] [genailab.infra.persist.repo.file.fao.FAO] [delete] : Directory dataprep_sentiment_dataset_review.parquet successfully removed from the repository.\n",
      "[02/04/2025 03:09:21 AM] [DEBUG] [genailab.infra.persist.repo.dataset.DatasetRepo] [remove] : Files for Dataset dataprep_sentiment_dataset_review removed from repository.\n",
      "[02/04/2025 03:09:21 AM] [DEBUG] [genailab.infra.persist.repo.object.dao.DAO] [delete] : Dataset object dataprep_sentiment_dataset_review removed from object storage.\n",
      "[02/04/2025 03:09:21 AM] [DEBUG] [genailab.infra.persist.repo.dataset.DatasetRepo] [remove] : Dataset dataprep_sentiment_dataset_review, including its file at workspace/test/datasets/fal/dataprep/dataprep_sentiment_dataset_review.parquet has been removed from the repository.\n",
      "[02/04/2025 03:09:21 AM] [DEBUG] [root] [get_reader] : Requesting a pandas_parquet reader from the DataFrameIOFactory\n",
      "[02/04/2025 03:09:21 AM] [DEBUG] [genailab.infra.persist.repo.file.pandas.PandasDataFrameParquetReader] [read] : PandasDataFrameParquetReader read from workspace/test/datasets/fal/dataprep/dataprep_tqa_dataset_review.parquet\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "# ============================================================================== #\n",
      "#               Sentiment Analysis Stage Tue, 04 Feb 2025 03:09:20               #\n",
      "# ============================================================================== #\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[02/04/2025 03:09:21 AM] [DEBUG] [genailab.asset.dataset.state.DatasetState] [add_event] : Added {'timestamp': datetime.datetime(2025, 2, 4, 3, 9, 21, 208356), 'entity': 'SentimentAnalysisStage', 'event': 'Accessed by SentimentAnalysisStage'} to the event log at 2025-02-04 03:09:21.208359.\n",
      "[02/04/2025 03:09:21 AM] [DEBUG] [genailab.asset.dataset.state.DatasetState] [access] : Dataset accessed by SentimentAnalysisStage at 2025-02-04 03:09:21.208347\n",
      "[02/04/2025 03:09:21 AM] [DEBUG] [root] [run] : Inside MergeTask: run\n",
      "[02/04/2025 03:09:21 AM] [DEBUG] [root] [_read] : Read file using CSVIO and returning a DataFrame\n",
      "[02/04/2025 03:09:21 AM] [DEBUG] [MergeTask.run] [wrapper] : Task: MergeTask\n",
      "[02/04/2025 03:09:21 AM] [DEBUG] [MergeTask.run] [wrapper] : Started: 03:09:21\n",
      "[02/04/2025 03:09:21 AM] [DEBUG] [MergeTask.run] [wrapper] : Completed: 03:09:21\n",
      "[02/04/2025 03:09:21 AM] [DEBUG] [MergeTask.run] [wrapper] : Runtime: 0.08 seconds\n",
      "[02/04/2025 03:09:21 AM] [DEBUG] [genailab.asset.dataset.builder.DatasetBuilder] [_build_passport] : \n",
      "\n",
      "                        DatasetPassport                         \n",
      "                        asset_id | dataprep_sentiment_dataset_review\n",
      "                           phase | Data Preparation Phase\n",
      "                           stage | Sentiment Analysis Stage\n",
      "                            name | review\n",
      "                     description | Dataset review created from dataprep_tqa_dataset_review in the Data Preparation Phase - Sentiment Analysis Stage by SentimentAnalysisStage.\n",
      "                     file_format | parquet\n",
      "                         creator | SentimentAnalysisStage\n",
      "                         created | 2025-02-04 03:09:21\n",
      "                          dftype | pandas\n",
      "\n",
      "\n",
      "[02/04/2025 03:09:21 AM] [DEBUG] [genailab.asset.dataset.state.DatasetState] [add_event] : Added {'timestamp': datetime.datetime(2025, 2, 4, 3, 9, 21, 311679), 'entity': 'SentimentAnalysisStage', 'event': 'Dataset Created by SentimentAnalysisStage'} to the event log at 2025-02-04 03:09:21.311680.\n",
      "[02/04/2025 03:09:21 AM] [DEBUG] [genailab.asset.dataset.state.DatasetState] [__post_init__] : SentimentAnalysisStage created dataset at 2025-02-04 03:09:21.311672.\n",
      "[02/04/2025 03:09:21 AM] [DEBUG] [genailab.asset.dataset.state.DatasetState] [add_event] : Added {'timestamp': datetime.datetime(2025, 2, 4, 3, 9, 21, 315262), 'entity': 'SentimentAnalysisStage', 'event': 'Dataset Published to Repository by SentimentAnalysisStage'} to the event log at 2025-02-04 03:09:21.315264.\n",
      "[02/04/2025 03:09:21 AM] [DEBUG] [genailab.asset.dataset.state.DatasetState] [publish] : Dataset published by SentimentAnalysisStage at 2025-02-04 03:09:21.315264\n",
      "[02/04/2025 03:09:21 AM] [DEBUG] [genailab.infra.persist.repo.dataset.DatasetRepo] [_get_filepath] : Set Dataset dataprep_sentiment_dataset_review filepath to workspace/test/datasets/fal/dataprep/dataprep_sentiment_dataset_review.parquet\n",
      "[02/04/2025 03:09:21 AM] [DEBUG] [root] [get_writer] : Requesting a pandas_parquet writer from the DataFrameIOFactory\n",
      "[02/04/2025 03:09:21 AM] [DEBUG] [genailab.infra.persist.repo.file.pandas.PandasDataFrameParquetWriter] [write] : PandasDataFrameParquetWriter wrote to workspace/test/datasets/fal/dataprep/dataprep_sentiment_dataset_review.parquet\n",
      "[02/04/2025 03:09:21 AM] [DEBUG] [genailab.asset.dataset.state.DatasetState] [add_event] : Added {'timestamp': datetime.datetime(2025, 2, 4, 3, 9, 21, 386099), 'entity': 'SentimentAnalysisStage', 'event': 'Dataset Consumed by SentimentAnalysisStage'} to the event log at 2025-02-04 03:09:21.386102.\n",
      "[02/04/2025 03:09:21 AM] [DEBUG] [genailab.asset.dataset.state.DatasetState] [consume] : Dataset consumed by SentimentAnalysisStage at 2025-02-04 03:09:21.386102\n",
      "[02/04/2025 03:09:21 AM] [DEBUG] [Stage.run] [wrapper] : Stage: Sentiment Analysis Stage\n",
      "[02/04/2025 03:09:21 AM] [DEBUG] [Stage.run] [wrapper] : Stage Started: 03:09:20\n",
      "[02/04/2025 03:09:21 AM] [DEBUG] [Stage.run] [wrapper] : Stage Completed: 03:09:21\n",
      "[02/04/2025 03:09:21 AM] [DEBUG] [Stage.run] [wrapper] : Stage Runtime: 0.4 seconds\n",
      "[02/04/2025 03:09:21 AM] [DEBUG] [Stage.run] [wrapper] : Cached Result: True\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Task                                    Start       End         Runtime     \n",
      "----------------------------------------------------------------------------\n",
      "MergeTask                               03:09:21    03:09:21    0.08 seconds\n",
      "____________________________________________________________________________\n",
      "Sentiment Analysis Stage                03:09:20    03:09:21    0.4 seconds \n",
      "\n",
      "\n",
      "# ============================================================================ #\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "stage = SentimentAnalysisStageBuilder().build(source_config=source_config, target_config=target_config)\n",
    "dataset = stage.run(force=FORCE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inspect Results\n",
    "This sample illustrates sentiment vis-a-vis ratings, revealing the complexity and nuance in user opinion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>app_name</th>\n",
       "      <th>content</th>\n",
       "      <th>rating</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1943</th>\n",
       "      <td>8549348528</td>\n",
       "      <td>Simple DBT Skills Diary Card</td>\n",
       "      <td>this app is wonderful a super easy place to keep track of your day to day emotions negative behaviorscoping mechanisms and dbt practices i recommend this app to anybody trying to cultivate emotional wellness not just those in treatment for borderline personality disorder</td>\n",
       "      <td>5</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2892</th>\n",
       "      <td>9085789213</td>\n",
       "      <td>myPhonak</td>\n",
       "      <td>get an android phone if you have phonak</td>\n",
       "      <td>1</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2798</th>\n",
       "      <td>7520329718</td>\n",
       "      <td>Accredo</td>\n",
       "      <td>accredo app makes the refill process for specialty medicines as easy as the best regular pharmacy apps no more long waits on the phone and too many verification questions will definitely stick with accredo</td>\n",
       "      <td>5</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>608</th>\n",
       "      <td>8844495545</td>\n",
       "      <td>Voice Dream Reader - TTS</td>\n",
       "      <td>notified developer that any pdf added will disappear from list unless the app is closed in background then reopened still no fix otherwise a stellar app that ive been using since it first came out about years ago</td>\n",
       "      <td>3</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3156</th>\n",
       "      <td>8748661689</td>\n",
       "      <td>YouTube: Watch, Listen, Stream</td>\n",
       "      <td>youtube is always good but a few problem i hate it the short its annoying and toxic negative too easy can see negative videos around and i hate made people think of negative thoughts which always made me want to clean youtube and quit youtube quit youtube to stop myself from seeing these negative bad videos</td>\n",
       "      <td>2</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2403</th>\n",
       "      <td>7252604057</td>\n",
       "      <td>Co–Star Personalized Astrology</td>\n",
       "      <td>as ive learned more about astrology ive also realized how misleading of an app this is astrology is a powerful tool and to use it so recklessly is really irresponsible id recommend people download other apps that are recommended by actual astrologers such as the path or time passages</td>\n",
       "      <td>1</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1865</th>\n",
       "      <td>8232180256</td>\n",
       "      <td>Organic Fit: Women Weight Loss</td>\n",
       "      <td>i tried to cancel this subscription on apple and i could not find it i deleted the app thinking there was no problem i was charge i was told i needed to cancel on their website but i never signed up through their website i dont even have an email confirmation from them i had to look up their contact info online i email them immediately i saw the charge pending on my account they assured me it has now been cancelled but however i will not be getting my money back so basically i paid for a one day subscription that i didnt use if you are used to canceling subscription on your phone you dont have that option on this app beware of this app</td>\n",
       "      <td>1</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4550</th>\n",
       "      <td>8355234392</td>\n",
       "      <td>Calculator &amp; Math Solver</td>\n",
       "      <td>it does numbers and is good at math</td>\n",
       "      <td>5</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              id                        app_name  \\\n",
       "1943  8549348528    Simple DBT Skills Diary Card   \n",
       "2892  9085789213                        myPhonak   \n",
       "2798  7520329718                         Accredo   \n",
       "608   8844495545        Voice Dream Reader - TTS   \n",
       "3156  8748661689  YouTube: Watch, Listen, Stream   \n",
       "2403  7252604057  Co–Star Personalized Astrology   \n",
       "1865  8232180256  Organic Fit: Women Weight Loss   \n",
       "4550  8355234392        Calculator & Math Solver   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  content  \\\n",
       "1943                                                                                                                                                                                                                                                                                                                                                                                      this app is wonderful a super easy place to keep track of your day to day emotions negative behaviorscoping mechanisms and dbt practices i recommend this app to anybody trying to cultivate emotional wellness not just those in treatment for borderline personality disorder   \n",
       "2892                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              get an android phone if you have phonak   \n",
       "2798                                                                                                                                                                                                                                                                                                                                                                                                                                                        accredo app makes the refill process for specialty medicines as easy as the best regular pharmacy apps no more long waits on the phone and too many verification questions will definitely stick with accredo   \n",
       "608                                                                                                                                                                                                                                                                                                                                                                                                                                                  notified developer that any pdf added will disappear from list unless the app is closed in background then reopened still no fix otherwise a stellar app that ive been using since it first came out about years ago   \n",
       "3156                                                                                                                                                                                                                                                                                                                                                 youtube is always good but a few problem i hate it the short its annoying and toxic negative too easy can see negative videos around and i hate made people think of negative thoughts which always made me want to clean youtube and quit youtube quit youtube to stop myself from seeing these negative bad videos   \n",
       "2403                                                                                                                                                                                                                                                                                                                                                                         as ive learned more about astrology ive also realized how misleading of an app this is astrology is a powerful tool and to use it so recklessly is really irresponsible id recommend people download other apps that are recommended by actual astrologers such as the path or time passages   \n",
       "1865  i tried to cancel this subscription on apple and i could not find it i deleted the app thinking there was no problem i was charge i was told i needed to cancel on their website but i never signed up through their website i dont even have an email confirmation from them i had to look up their contact info online i email them immediately i saw the charge pending on my account they assured me it has now been cancelled but however i will not be getting my money back so basically i paid for a one day subscription that i didnt use if you are used to canceling subscription on your phone you dont have that option on this app beware of this app   \n",
       "4550                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  it does numbers and is good at math   \n",
       "\n",
       "      rating sentiment  \n",
       "1943       5   Neutral  \n",
       "2892       1   Neutral  \n",
       "2798       5  Positive  \n",
       "608        3   Neutral  \n",
       "3156       2   Neutral  \n",
       "2403       1  Negative  \n",
       "1865       1  Negative  \n",
       "4550       5  Positive  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "dataset.dataframe[[\"id\",\"app_name\", \"content\", \"rating\", \"sentiment\"]].sample(\n",
    "    n=8, random_state=5\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary of Sentiment vs. Ratings\n",
    "1. **Entry 1: Mooncycle**\n",
    "   - **Rating**: 4\n",
    "   - **Sentiment Analysis**: Very Positive\n",
    "   - **Comment**: The user provided a high rating (4 stars), and the sentiment analysis correctly identified a very positive sentiment. This indicates a good match between the expressed sentiment and the user's rating.\n",
    "\n",
    "2. **Entry 2: Privacy Concern**\n",
    "   - **Rating**: 3\n",
    "   - **Sentiment Analysis**: Neutral\n",
    "   - **Comment**: The review mentions significant concerns about privacy features but still gives a moderate rating of 3 stars. The sentiment analysis classified this as Neutral, which seems reasonable given the mix of positive and negative feedback. However, one might argue that a \"Slightly Negative\" label could better capture the overall tone.\n",
    "\n",
    "3. **Entry 3: Survey Payouts**\n",
    "   - **Rating**: 3\n",
    "   - **Sentiment Analysis**: Negative\n",
    "   - **Comment**: The user was disappointed with survey payouts, rating the experience as 3 stars. The sentiment analysis classified this as Negative, which reflects the user's dissatisfaction. The rating, however, seems higher than expected for a purely negative sentiment, suggesting potential leniency or mixed feelings not fully captured by the text.\n",
    "\n",
    "4. **Entry 4: Instagram Censorship**\n",
    "   - **Rating**: 1\n",
    "   - **Sentiment Analysis**: Very Negative\n",
    "   - **Comment**: This review strongly criticizes Instagram's content policies, and the user gave the lowest possible rating (1 star). The sentiment analysis accurately labeled this as Very Negative, showing a clear alignment between sentiment and rating.\n",
    "\n",
    "5. **Entry 5: Informative App**\n",
    "   - **Rating**: 5\n",
    "   - **Sentiment Analysis**: Very Positive\n",
    "   - **Comment**: The review is overwhelmingly positive, emphasizing the app's usefulness and unique features, and the user gave a 5-star rating. The sentiment analysis correctly labeled it as Very Positive, demonstrating alignment between the rating and sentiment.\n",
    "\n",
    "### Observations\n",
    "- **Alignment**: In most cases, the sentiment analysis aligns well with the user ratings. Positive sentiments correlate with higher ratings, while negative sentiments correspond to lower ratings.\n",
    "- **Mixed Reviews**: The Neutral sentiment for the privacy concern review highlights the complexity of mixed feedback, where both positives and negatives are present. This might require more nuanced classification.\n",
    "- **Alignment Between Sentiment and Rating**: In most cases, there is alignment between the sentiment analysis and user ratings. For instance, Very Positive sentiments are generally accompanied by high ratings (4 or 5), and Very Negative sentiments align with the lowest rating of 1.\n",
    "- **Neutral Sentiment vs. Moderate Rating**: For reviews with Neutral or Negative sentiment (Ratings: 3), the ratings reflect appreciation for the app's core value but reveal dissatisfaction with specific features or limitations.\n",
    "- **Sentiment Outliers**: No significant mismatches are observed here, suggesting that the sentiment analysis accurately reflects the reviewer’s stance in this sample. However, cases like Review 2 highlight how neutral sentiments can still accompany moderate ratings due to unfulfilled expectations.\n",
    "\n",
    "This analysis indicates that sentiment analysis can generally align well with user ratings, offering insights into specific areas of dissatisfaction or satisfaction that might otherwise be missed in numerical ratings alone.\n",
    "\n",
    "In the next section, we evaluate data quality and requirements for data cleaning."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "genai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
